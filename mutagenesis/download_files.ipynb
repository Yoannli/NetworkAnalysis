{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liyoa\\anaconda3\\envs\\sbna\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import traceback\n",
    "import paramiko\n",
    "\n",
    "# import from ../utils.py\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import dwl_pdb_file,  get_resolution, get_dbref_data, get_gene_name, calculate_sbna_and_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(\"../data_prep/Census_all_with_pdb.csv\")\n",
    "genes = genes[genes[\"Gene Symbol\"].isin([\"KRAS\", \"HRAS\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download PDB file 7Q9U. Status code: 404remaining))\n",
      "Downloading PDB file 8TXH for KRAS (0 structures remaining))\r"
     ]
    }
   ],
   "source": [
    "# count number of structures for all gene\n",
    "n_total = genes['n_structures'].sum()\n",
    "\n",
    "for _, row in genes.iterrows():\n",
    "    gene = row['Gene Symbol']\n",
    "    pdb_structures = ast.literal_eval(row['PDB Structures'])\n",
    "    for pdb_id in pdb_structures:\n",
    "        n_total -= 1\n",
    "        print(f\"Downloading PDB file {pdb_id} for {gene} ({n_total} structures remaining)\", end='\\r')\n",
    "        # check if the file already exists\n",
    "        if not os.path.exists(f'pdb_files/{pdb_id}.pdb'):\n",
    "            if not dwl_pdb_file(pdb_id): # returns True or False if the file was downloaded\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>...</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PDB Structures</th>\n",
       "      <th>n_structures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>HRAS</td>\n",
       "      <td>v-Ha-ras Harvey rat sarcoma viral oncogene hom...</td>\n",
       "      <td>3265.0</td>\n",
       "      <td>11:532243-535550</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11p15.5</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>infrequent sarcomas, rare other tumour types</td>\n",
       "      <td>...</td>\n",
       "      <td>E, L, M</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCDS7698.1,ENSG00000174775.16,HRAS1,NM_005343....</td>\n",
       "      <td>['121P', '1AA9', '1AGP', '1BKD', '1CLU', '1CRP...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>KRAS</td>\n",
       "      <td>v-Ki-ras2 Kirsten rat sarcoma 2 viral oncogene...</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>12:25209431-25250803</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatic, colorectal, lung, thyroid, AML, ot...</td>\n",
       "      <td>...</td>\n",
       "      <td>L, E, M, O</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCDS8703.1,ENSG00000133703.11,KRAS1,KRAS2,NM_0...</td>\n",
       "      <td>['1D8D', '1D8E', '1KZO', '1KZP', '1N4P', '1N4Q...</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gene Symbol                                               Name  \\\n",
       "318        HRAS  v-Ha-ras Harvey rat sarcoma viral oncogene hom...   \n",
       "366        KRAS  v-Ki-ras2 Kirsten rat sarcoma 2 viral oncogene...   \n",
       "\n",
       "     Entrez GeneId       Genome Location  Tier Hallmark Chr Band Somatic  \\\n",
       "318         3265.0      11:532243-535550     1      Yes  11p15.5     yes   \n",
       "366         3845.0  12:25209431-25250803     1      Yes  12p12.1     yes   \n",
       "\n",
       "    Germline                              Tumour Types(Somatic)  ...  \\\n",
       "318      yes       infrequent sarcomas, rare other tumour types  ...   \n",
       "366      NaN  pancreatic, colorectal, lung, thyroid, AML, ot...  ...   \n",
       "\n",
       "    Tissue Type Molecular Genetics Role in Cancer Mutation Types  \\\n",
       "318     E, L, M                Dom       oncogene            Mis   \n",
       "366  L, E, M, O                Dom       oncogene            Mis   \n",
       "\n",
       "    Translocation Partner Other Germline Mut Other Syndrome  \\\n",
       "318                   NaN                NaN            NaN   \n",
       "366                   NaN                NaN            NaN   \n",
       "\n",
       "                                              Synonyms  \\\n",
       "318  CCDS7698.1,ENSG00000174775.16,HRAS1,NM_005343....   \n",
       "366  CCDS8703.1,ENSG00000133703.11,KRAS1,KRAS2,NM_0...   \n",
       "\n",
       "                                        PDB Structures n_structures  \n",
       "318  ['121P', '1AA9', '1AGP', '1BKD', '1CLU', '1CRP...          228  \n",
       "366  ['1D8D', '1D8E', '1KZO', '1KZP', '1N4P', '1N4Q...          295  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_data = []\n",
    "uniprot_map = {}\n",
    "\n",
    "# count number of structures for all gene\n",
    "n_total = genes['n_structures'].sum()\n",
    "\n",
    "for _, row in genes.iterrows():\n",
    "    gene = row['Gene Symbol']\n",
    "    pdb_structures = ast.literal_eval(row['PDB Structures'])\n",
    "    for pdb_id in pdb_structures:\n",
    "        n_total -= 1\n",
    "        # check if the file already exists\n",
    "        if not os.path.exists(f'../pdb_files/{pdb_id}.pdb'):\n",
    "            continue\n",
    "        # read the file\n",
    "        resolution = get_resolution(pdb_id)\n",
    "        dbref = get_dbref_data(pdb_id)\n",
    "        for i in dbref:\n",
    "            chain = i['chain']\n",
    "            start = i['start']\n",
    "            end = i['end']\n",
    "            uniprot = i['uniprot']\n",
    "            if uniprot not in uniprot_map:\n",
    "                uniprot_map[uniprot] = get_gene_name(uniprot)\n",
    "            assoc_gene = uniprot_map[uniprot]\n",
    "            pdb_data.append([gene, row[\"Name\"], pdb_id, resolution, chain, start, end, uniprot, assoc_gene])\n",
    "\n",
    "pdb_data = pd.DataFrame(pdb_data, columns=['gene_symbol', 'gene_name', 'pdb_id', 'resolution', 'chain', 'seq_start', 'seq_end', 'uniprot_id', 'assoc_gene'])\n",
    "pdb_data.head()\n",
    "pdb_data['length'] = pdb_data['seq_end'] - pdb_data['seq_start'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort gene ascending, length descending and resolution ascneding\n",
    "pdb_data.sort_values(by=['gene_symbol', 'length', 'resolution', \"pdb_id\"], ascending=[True, False, True, True]).to_excel(\"best_pdbs_kras_hras.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen structures: \n",
    "* HRAS\t1IOZ A\n",
    "* KRAS\t7VVB A\n",
    "* TP53  1TSR A, B, C\n",
    "* EGFR  4UIP A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under the terms of the\n",
      "GNU General Public License versions 2 or 3.\n",
      "For more information about these matters see\n",
      "https://www.gnu.org/licenses/.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing 7T4J with chain A...\n",
      "Starting phenix.pdbtools\n",
      "on Sun Apr 28 21:25:29 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 7T4J.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain A\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"7T4J.pdb\"\n",
      "    }\n",
      "    default_model = \"7T4J.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain A\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 4681 size after: 2334\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 2.63 seconds\n",
      "wall clock time: 8.09 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Sun Apr 28 21:25:33 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 7T4J_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"7T4J_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"7T4J_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2334 size after: 2284\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.80 seconds\n",
      "wall clock time: 1.83 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are R28-1101A, EDO-1102A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 7T4J_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Sun Apr 28 21:26:59 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 7T4J_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"7T4J_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"7T4J_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 4681 size after: 4586\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.93 seconds\n",
      "wall clock time: 1.94 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are R28-1101B, R28-1101A, CIT-1102B, EDO-1102A, CIT-1103B\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 7T4J_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = data2Multimer[rownames(data1Multimer),]\n",
      "> data1MultimerZ = as.data.frame(apply(data1Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1MultimerZ) = rownames(data1Multimer)\n",
      "> data2MultimerZ = as.data.frame(apply(data2Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2MultimerZ) = rownames(data2Multimer)\n",
      "> colnames(data1MultimerZ) = paste(colnames(data1MultimerZ),\"MULTIMER\",sep=\"\")\n",
      "> colnames(data2MultimerZ) = paste(colnames(data2MultimerZ),\"MULTIMERCENTROIDSC\",sep=\"\")\n",
      "> data2MultimerZ = data2MultimerZ[rownames(data1MultimerZ),]\n",
      "> \n",
      "> #Add RSA\n",
      "> data1 = cbind(data2[,\"RSA\"],data1)\n",
      "> colnames(data1)[1]=\"RSA\"\n",
      "> dataZ = cbind(data1Z,data2Z)\n",
      "> \n",
      "> #Identify max NodeEdgeBetweennessSTRIDE_sidechain\n",
      "> acidsMonomer = c()\n",
      "> for (i in 1:length(rownames(dataZ))) {\n",
      "+     node = rownames(dataZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMonomer = c(acidsMonomer,node)\n",
      "+ }\n",
      "> \n",
      "> acidsMultimer = c()\n",
      "> for (i in 1:length(rownames(data1MultimerZ))) {\n",
      "+     node = rownames(data1MultimerZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMultimer = c(acidsMultimer,node)\n",
      "+ }\n",
      "> \n",
      "> allAcids = unique(c(acidsMonomer,acidsMultimer))\n",
      "> \n",
      "> #SecondOrderIntermodularDegree is the average of the multimer only\n",
      "> SecondOrderIntermodularDegree_ALL = (data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDE_sidechainMULTIMER\"]+data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMER\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMERCENTROIDSC\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeWALKTRAPMULTIMERCENTROIDSC\"])/4\n",
      "> SecondOrderIntermodularDegree_AVERAGE = tapply(SecondOrderIntermodularDegree_ALL,as.factor(acidsMultimer),mean)\n",
      "> SecondOrderIntermodularDegree_AVERAGE = SecondOrderIntermodularDegree_AVERAGE[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> SecondOrderIntermodularDegree_AVERAGE[missing] = (data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE_sidechain\"]+data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDECENTROIDSC\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeWALKTRAPCENTROIDSC\"])/4\n",
      "> names(SecondOrderIntermodularDegree_AVERAGE)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> \n",
      "> #NodeEdgeBetweenness is the max of the monomer/multimer\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER = (dataZ[,\"NodeEdgeBetweennessSTRIDE\"]+dataZ[,\"NodeEdgeBetweennessSTRIDE_sidechain\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER = (data1MultimerZ[,\"NodeEdgeBetweennessSTRIDEMULTIMER\"]+data1MultimerZ[,\"NodeEdgeBetweennessSTRIDE_sidechainMULTIMER\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_ALL = c(NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER,NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = tapply(NodeEdgeBetweennessSTRIDE_sidechain_ALL,as.factor(c(acidsMonomer,acidsMultimer)),max,na.rm=TRUE)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = NodeEdgeBetweennessSTRIDE_sidechain_MAX[allAcids]\n",
      "> \n",
      "> #Ligand is the min of the multimer only\n",
      "> LigandMULTIMERCENTROIDSC_ALL = data2MultimerZ[,\"LigandMULTIMERCENTROIDSC\"]\n",
      "> LigandMULTIMERCENTROIDSC_MIN = tapply(LigandMULTIMERCENTROIDSC_ALL,as.factor(acidsMultimer),min)\n",
      "> LigandMULTIMERCENTROIDSC_MIN = LigandMULTIMERCENTROIDSC_MIN[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> LigandMULTIMERCENTROIDSC_MIN[missing] = dataZ[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"LigandCENTROIDSC\"]\n",
      "> names(LigandMULTIMERCENTROIDSC_MIN)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> LigandMULTIMERCENTROIDSC_MIN[is.na(LigandMULTIMERCENTROIDSC_MIN)] = 0\n",
      "> \n",
      "> #RSA\n",
      "> RSA_ALL = c(data1[,\"RSA\"],data2Multimer[,\"RSA\"])\n",
      "> RSA_MIN = tapply(RSA_ALL,as.factor(c(acidsMonomer,acidsMultimer)),min,na.rm=TRUE)\n",
      "> RSA_MIN = RSA_MIN[allAcids]\n",
      "> \n",
      "> y = SecondOrderIntermodularDegree_AVERAGE+NodeEdgeBetweennessSTRIDE_sidechain_MAX-LigandMULTIMERCENTROIDSC_MIN\n",
      "> \n",
      "> out=cbind(names(y),y)\n",
      "> acidNumbers = sapply(out[,1],substring,4)\n",
      "> out = out[order(as.numeric(acidNumbers)),]\n",
      "> write.table(out,file=\"FinalSum\",sep=\"\\t\",quote=FALSE,row.names=FALSE,col.names=FALSE)\n",
      "> \n",
      "> # also write the 3 variables to a file\n",
      "> # Concatenating all three variables into a single data frame\n",
      "> result <- data.frame(\n",
      "+   Acid = names(SecondOrderIntermodularDegree_AVERAGE),\n",
      "+   SecondOrderIntermodularDegree_AVERAGE,\n",
      "+   NodeEdgeBetweennessSTRIDE_sidechain_MAX,\n",
      "+   LigandMULTIMERCENTROIDSC_MIN\n",
      "+ )\n",
      "> \n",
      "> # Writing the data frame to a file\n",
      "> write.table(result, file = \"FinalSum_Decomp\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n",
      "> \n",
      "\n",
      "*WARNING*: Residues LEU 747  and ASN 756  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues LEU 747  and ASN 756  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Res \"R28\" not in HETATM Connection Database. Hydrogens not added.\n",
      "\n",
      "Attaching package: â€˜igraphâ€™\n",
      "\n",
      "The following objects are masked from â€˜package:statsâ€™:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from â€˜package:baseâ€™:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: â€˜igraphâ€™\n",
      "\n",
      "The following objects are masked from â€˜package:statsâ€™:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from â€˜package:baseâ€™:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 1041 items\n",
      "Read 1041 items\n",
      "*WARNING*: Residues LEU 747  and ASN 756  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues LEU 747  and ASN 756  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 734  and LYS 739  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 734  and LYS 739  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues ARG 748  and LYS 754  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues ARG 748  and LYS 754  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Res \"R28\" not in HETATM Connection Database. Hydrogens not added.\n",
      "*WARNING*: Res \"R28\" not in HETATM Connection Database. Hydrogens not added.\n",
      "\n",
      "Attaching package: â€˜igraphâ€™\n",
      "\n",
      "The following objects are masked from â€˜package:statsâ€™:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from â€˜package:baseâ€™:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: â€˜igraphâ€™\n",
      "\n",
      "The following objects are masked from â€˜package:statsâ€™:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from â€˜package:baseâ€™:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 3369 items\n",
      "Read 3369 items\n",
      "\n",
      "SBNA results for 7T4J succesfully downloaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    calculate_sbna_and_download({\"7T4J\": [\"A\"]})\n",
    "except Exception as e:\n",
    "    print(f\"Failed to process {pdb_id} with error:\")\n",
    "    print(traceback.print_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
