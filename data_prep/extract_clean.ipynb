{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liyoa\\anaconda3\\envs\\sbna\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import paramiko # for ssh\n",
    "import traceback #  for error handling\n",
    "import ast\n",
    "import requests\n",
    "import re\n",
    "from Bio.SeqUtils import seq1\n",
    "\n",
    "# import from ../utils.py\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import get_pdb_ids, get_resolution, get_dbref_data, read_finalsum, read_finalsum_decomp, \\\n",
    "    read_finalsum_decomp, get_gene_name, get_uniprot_sequence, calculate_sbna_and_download, dwl_pdb_file, align_finalsum_with_uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>Tumour Types(Germline)</th>\n",
       "      <th>Cancer Syndrome</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>29974.0</td>\n",
       "      <td>10:50799421-50885675</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI1</td>\n",
       "      <td>abl-interactor 1</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>10:26746593-26860935</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>TSG, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>KMT2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1</td>\n",
       "      <td>v-abl Abelson murine leukemia viral oncogene h...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9:130713946-130885683</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9q34.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CML, ALL, T-ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T, Mis</td>\n",
       "      <td>BCR, ETV6, NUP214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABL2</td>\n",
       "      <td>c-abl oncogene 2, non-receptor tyrosine kinase</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1:179099327-179229601</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1q25.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>ETV6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABLL,ARG,CCDS30947.1,ENSG00000143322.19,NM_007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACKR3</td>\n",
       "      <td>atypical chemokine receptor 3</td>\n",
       "      <td>57007.0</td>\n",
       "      <td>2:236569641-236582358</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2q37.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lipoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>HMGA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCDS2516.1,CMKOR1,CXCR7,ENSG00000144476.5,GPR1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol                                               Name  \\\n",
       "0        A1CF                     APOBEC1 complementation factor   \n",
       "1        ABI1                                   abl-interactor 1   \n",
       "2        ABL1  v-abl Abelson murine leukemia viral oncogene h...   \n",
       "3        ABL2     c-abl oncogene 2, non-receptor tyrosine kinase   \n",
       "4       ACKR3                      atypical chemokine receptor 3   \n",
       "\n",
       "   Entrez GeneId        Genome Location  Tier Hallmark  Chr Band Somatic  \\\n",
       "0        29974.0   10:50799421-50885675     2      NaN  10q11.23     yes   \n",
       "1        10006.0   10:26746593-26860935     1      Yes   10p12.1     yes   \n",
       "2           25.0  9:130713946-130885683     1      Yes   9q34.12     yes   \n",
       "3           27.0  1:179099327-179229601     1      NaN    1q25.2     yes   \n",
       "4        57007.0  2:236569641-236582358     1      Yes    2q37.3     yes   \n",
       "\n",
       "  Germline Tumour Types(Somatic) Tumour Types(Germline) Cancer Syndrome  \\\n",
       "0      NaN              melanoma                    NaN             NaN   \n",
       "1      NaN                   AML                    NaN             NaN   \n",
       "2      NaN       CML, ALL, T-ALL                    NaN             NaN   \n",
       "3      NaN                   AML                    NaN             NaN   \n",
       "4      NaN                lipoma                    NaN             NaN   \n",
       "\n",
       "  Tissue Type Molecular Genetics    Role in Cancer Mutation Types  \\\n",
       "0           E                NaN          oncogene            Mis   \n",
       "1           L                Dom       TSG, fusion              T   \n",
       "2           L                Dom  oncogene, fusion         T, Mis   \n",
       "3           L                Dom  oncogene, fusion              T   \n",
       "4           M                Dom  oncogene, fusion              T   \n",
       "\n",
       "  Translocation Partner Other Germline Mut Other Syndrome  \\\n",
       "0                   NaN                NaN            NaN   \n",
       "1                 KMT2A                NaN            NaN   \n",
       "2     BCR, ETV6, NUP214                NaN            NaN   \n",
       "3                  ETV6                NaN            NaN   \n",
       "4                 HMGA2                NaN            NaN   \n",
       "\n",
       "                                            Synonyms  \n",
       "0  ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...  \n",
       "1  ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...  \n",
       "2  ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...  \n",
       "3  ABLL,ARG,CCDS30947.1,ENSG00000143322.19,NM_007...  \n",
       "4  CCDS2516.1,CMKOR1,CXCR7,ENSG00000144476.5,GPR1...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgc_data = pd.read_csv('Census_allTue Apr  9 04_58_38 2024.csv')\n",
    "cgc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get pdb ids for ACSL3 with status code 200\n",
      "Failed to get pdb ids for ACSL6 with status code 200\n",
      "Failed to get pdb ids for AFF3 with status code 200\n",
      "Failed to get pdb ids for AKAP9 with status code 200\n",
      "Failed to get pdb ids for ARHGEF10 with status code 200\n",
      "Failed to get pdb ids for ARHGEF10L with status code 200\n",
      "Failed to get pdb ids for ASPM with status code 200\n",
      "Failed to get pdb ids for ASXL2 with status code 200\n",
      "Failed to get pdb ids for ATF1 with status code 200\n",
      "Failed to get pdb ids for ATP2B3 with status code 200\n",
      "Failed to get pdb ids for BCL11B with status code 200\n",
      "Failed to get pdb ids for BCL2L12 with status code 200\n",
      "Failed to get pdb ids for BCL7A with status code 200\n",
      "Failed to get pdb ids for BMP5 with status code 200\n",
      "Failed to get pdb ids for BTG1 with status code 200\n",
      "Failed to get pdb ids for CARS with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for CBFA2T3 with status code 200\n",
      "Failed to get pdb ids for CCDC6 with status code 200\n",
      "Failed to get pdb ids for CCNB1IP1 with status code 200\n",
      "Failed to get pdb ids for CCR4 with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for CDH10 with status code 200\n",
      "Failed to get pdb ids for CDH11 with status code 200\n",
      "Failed to get pdb ids for CEP89 with status code 200\n",
      "Failed to get pdb ids for CHD2 with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for CHIC2 with status code 200\n",
      "Failed to get pdb ids for CHST11 with status code 200\n",
      "Failed to get pdb ids for CIITA with status code 200\n",
      "Failed to get pdb ids for CLTCL1 with status code 200\n",
      "Failed to get pdb ids for CNBD1 with status code 200\n",
      "Failed to get pdb ids for CNBP with status code 200\n",
      "Failed to get pdb ids for CNTRL with status code 200\n",
      "Failed to get pdb ids for CREB3L1 with status code 200\n",
      "Failed to get pdb ids for CREB3L2 with status code 200\n",
      "Failed to get pdb ids for CRTC3 with status code 200\n",
      "Failed to get pdb ids for CSMD3 with status code 200\n",
      "Failed to get pdb ids for CTNND2 with status code 200\n",
      "Failed to get pdb ids for CUX1 with status code 200\n",
      "Failed to get pdb ids for CYSLTR2 with status code 200\n",
      "Failed to get pdb ids for DCAF12L2 with status code 200\n",
      "Failed to get pdb ids for DDIT3 with status code 200\n",
      "Failed to get pdb ids for ECT2L with status code 200\n",
      "Failed to get pdb ids for ELF4 with status code 200\n",
      "Failed to get pdb ids for ELN with status code 200\n",
      "Failed to get pdb ids for ERC1 with status code 200\n",
      "Failed to get pdb ids for ETNK1 with status code 200\n",
      "Failed to get pdb ids for FAM131B with status code 200\n",
      "Failed to get pdb ids for FAM135B with status code 200\n",
      "Failed to get pdb ids for FAM47C with status code 200\n",
      "Failed to get pdb ids for FAT1 with status code 200\n",
      "Failed to get pdb ids for FAT3 with status code 200\n",
      "Failed to get pdb ids for FBLN2 with status code 200\n",
      "Failed to get pdb ids for FCRL4 with status code 200\n",
      "Failed to get pdb ids for FGFR1OP with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for FKBP9 with status code 200\n",
      "Failed to get pdb ids for FOXR1 with status code 200\n",
      "Failed to get pdb ids for GOLGA5 with status code 200\n",
      "Failed to get pdb ids for GPC5 with status code 200\n",
      "Failed to get pdb ids for HLF with status code 200\n",
      "Failed to get pdb ids for HMGA2 with status code 200\n",
      "Failed to get pdb ids for HMGN2P46 with error cannot convert float NaN to integer\n",
      "Failed to get pdb ids for HOXA11 with status code 200\n",
      "Failed to get pdb ids for HOXA9 with status code 200\n",
      "Failed to get pdb ids for HOXC11 with status code 200\n",
      "Failed to get pdb ids for HOXC13 with status code 200\n",
      "Failed to get pdb ids for HOXD11 with status code 200\n",
      "Failed to get pdb ids for HOXD13 with status code 200\n",
      "Failed to get pdb ids for IGH with error argument of type 'float' is not iterable\n",
      "Failed to get pdb ids for IGK with status code 200\n",
      "Failed to get pdb ids for IGL with error argument of type 'float' is not iterable\n",
      "Failed to get pdb ids for IKZF3 with status code 200\n",
      "Failed to get pdb ids for IRS4 with status code 200\n",
      "Failed to get pdb ids for ISX with status code 200\n",
      "Failed to get pdb ids for JAZF1 with status code 200\n",
      "Failed to get pdb ids for KCNJ5 with status code 200\n",
      "Failed to get pdb ids for KDSR with status code 200\n",
      "Failed to get pdb ids for KIAA1549 with status code 200\n",
      "Failed to get pdb ids for KLF6 with status code 200\n",
      "Failed to get pdb ids for KNSTRN with status code 200\n",
      "Failed to get pdb ids for KTN1 with status code 200\n",
      "Failed to get pdb ids for LEF1 with status code 200\n",
      "Failed to get pdb ids for LEPROTL1 with status code 200\n",
      "Failed to get pdb ids for LHFPL6 with status code 200\n",
      "Failed to get pdb ids for LMO1 with status code 200\n",
      "Failed to get pdb ids for LPP with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for LRIG3 with status code 200\n",
      "Failed to get pdb ids for LRP1B with status code 200\n",
      "Failed to get pdb ids for LYL1 with status code 200\n",
      "Failed to get pdb ids for LZTR1 with status code 200\n",
      "Failed to get pdb ids for MACC1 with status code 200\n",
      "Failed to get pdb ids for MAF with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for MAFB with status code 200\n",
      "Failed to get pdb ids for MALAT1 with error cannot convert float NaN to integer\n",
      "Failed to get pdb ids for MAML2 with status code 200\n",
      "Failed to get pdb ids for MAP3K13 with status code 200\n",
      "Failed to get pdb ids for MDS2 with error cannot convert float NaN to integer\n",
      "Failed to get pdb ids for MED12 with status code 200\n",
      "Failed to get pdb ids for MLLT11 with status code 200\n",
      "Failed to get pdb ids for MLLT6 with status code 200\n",
      "Failed to get pdb ids for MN1 with status code 200\n",
      "Failed to get pdb ids for MNX1 with status code 200\n",
      "Failed to get pdb ids for MUC4 with status code 200\n",
      "Failed to get pdb ids for MUC6 with status code 200\n",
      "Failed to get pdb ids for MYB with status code 200\n",
      "Failed to get pdb ids for MYCL with status code 200\n",
      "Failed to get pdb ids for MYH11 with status code 200\n",
      "Failed to get pdb ids for MYOD1 with status code 200\n",
      "Failed to get pdb ids for NAB2 with status code 200\n",
      "Failed to get pdb ids for NFIB with status code 200\n",
      "Failed to get pdb ids for NFKBIE with status code 200\n",
      "Failed to get pdb ids for NIN with status code 200\n",
      "Failed to get pdb ids for NKX2-1 with status code 200\n",
      "Failed to get pdb ids for NR4A3 with status code 200\n",
      "Failed to get pdb ids for NUTM2B with status code 200\n",
      "Failed to get pdb ids for NUTM2D with status code 200\n",
      "Failed to get pdb ids for OLIG2 with status code 200\n",
      "Failed to get pdb ids for P2RY8 with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for PAX7 with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for PDE4DIP with status code 200\n",
      "Failed to get pdb ids for PER1 with status code 200\n",
      "Failed to get pdb ids for PICALM with status code 200\n",
      "Failed to get pdb ids for PIK3CB with status code 200\n",
      "Failed to get pdb ids for PLAG1 with status code 200\n",
      "Failed to get pdb ids for PPFIBP1 with status code 200\n",
      "Failed to get pdb ids for PPM1D with status code 200\n",
      "Failed to get pdb ids for PPP6C with status code 200\n",
      "Failed to get pdb ids for PRCC with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for PRF1 with status code 200\n",
      "Failed to get pdb ids for PRKD1 with status code 200\n",
      "Failed to get pdb ids for PRPF40B with status code 200\n",
      "Failed to get pdb ids for PRRX1 with status code 200\n",
      "Failed to get pdb ids for PWWP2A with status code 200\n",
      "Failed to get pdb ids for REL with status code 200\n",
      "Failed to get pdb ids for RGPD3 with status code 200\n",
      "Failed to get pdb ids for RHOH with status code 200\n",
      "Failed to get pdb ids for RNF213 with status code 200\n",
      "Failed to get pdb ids for RSPO2 with status code 200\n",
      "Failed to get pdb ids for RSPO3 with status code 200\n",
      "Failed to get pdb ids for SETBP1 with status code 200\n",
      "Failed to get pdb ids for SETD1B with status code 200\n",
      "Failed to get pdb ids for SFRP4 with status code 200\n",
      "Failed to get pdb ids for SH2B3 with status code 200\n",
      "Failed to get pdb ids for SH3GL1 with status code 200\n",
      "Failed to get pdb ids for SHTN1 with status code 200\n",
      "Failed to get pdb ids for SIX2 with status code 200\n",
      "Failed to get pdb ids for SLC34A2 with status code 200\n",
      "Failed to get pdb ids for SLC45A3 with status code 200\n",
      "Failed to get pdb ids for SNX29 with status code 200\n",
      "Failed to get pdb ids for SOCS1 with status code 200\n",
      "Failed to get pdb ids for SOX21 with status code 200\n",
      "Failed to get pdb ids for SPECC1 with status code 200\n",
      "Failed to get pdb ids for SRGAP3 with status code 200\n",
      "Failed to get pdb ids for SS18L1 with status code 200\n",
      "Failed to get pdb ids for SSX1 with status code 200\n",
      "Failed to get pdb ids for SSX4 with status code 200\n",
      "Failed to get pdb ids for STRN with status code 200\n",
      "Failed to get pdb ids for TAL2 with status code 200\n",
      "Failed to get pdb ids for TFG with status code 200\n",
      "Failed to get pdb ids for TFPT with status code 200\n",
      "Failed to get pdb ids for THRAP3 with status code 200\n",
      "Failed to get pdb ids for TLX1 with error list indices must be integers or slices, not str\n",
      "Failed to get pdb ids for TLX3 with status code 200\n",
      "Failed to get pdb ids for TMEM127 with status code 200\n",
      "Failed to get pdb ids for TPM4 with status code 200\n",
      "Failed to get pdb ids for TRA with status code 200\n",
      "Failed to get pdb ids for TRAF7 with status code 200\n",
      "Failed to get pdb ids for TRB with error argument of type 'float' is not iterable\n",
      "Failed to get pdb ids for TRD with error argument of type 'float' is not iterable\n",
      "Failed to get pdb ids for TRIM27 with status code 200\n",
      "Failed to get pdb ids for TRIP11 with status code 200\n",
      "Failed to get pdb ids for USP44 with status code 200\n",
      "Failed to get pdb ids for USP6 with status code 200\n",
      "Failed to get pdb ids for VTI1A with status code 200\n",
      "Failed to get pdb ids for WDCP with status code 200\n",
      "Failed to get pdb ids for ZMYM2 with status code 200\n",
      "Failed to get pdb ids for ZMYM3 with status code 200\n",
      "Failed to get pdb ids for ZNF331 with status code 200\n",
      "Failed to get pdb ids for ZNF384 with status code 200\n",
      "Failed to get pdb ids for ZNF429 with status code 200\n",
      "Failed to get pdb ids for ZNF479 with status code 200\n",
      "Failed to get pdb ids for ZNF521 with status code 200\n",
      "Failed to get pdb ids for ZNRF3 with status code 200\n",
      "Failed to get pdb ids for ZRSR2 with status code 200\n"
     ]
    }
   ],
   "source": [
    "# add pdb structures to cgc_data\n",
    "pdb_structures = []\n",
    "count = 1\n",
    "for _, row in cgc_data.iterrows():\n",
    "    # print curent count, replace previous line    \n",
    "    gene_symbol = row['Gene Symbol']\n",
    "    entrez_gene_id = row['Entrez GeneId']\n",
    "    synonyms = row['Synonyms']\n",
    "    print(f\"Processing {count} of {len(cgc_data)} ({gene_symbol})\", end='\\r')\n",
    "    count += 1\n",
    "\n",
    "    try:\n",
    "        status, pdb = get_pdb_ids(gene_symbol, entrez_gene_id, synonyms)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get pdb ids for {gene_symbol} with error {e}\")\n",
    "        pdb_structures.append(None)\n",
    "        continue\n",
    "\n",
    "    if not pdb:\n",
    "        print(f\"Failed to get pdb ids for {gene_symbol} with status code {status}\")\n",
    "        pdb_structures.append(None)\n",
    "    else:\n",
    "        if type(pdb) == list:\n",
    "            pdb_structures.append(pdb)\n",
    "        else:\n",
    "            pdb_structures.append([pdb])\n",
    "\n",
    "cgc_data['PDB Structures'] = pdb_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>...</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PDB Structures</th>\n",
       "      <th>n_structures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>29974.0</td>\n",
       "      <td>10:50799421-50885675</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...</td>\n",
       "      <td>[2CPD]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI1</td>\n",
       "      <td>abl-interactor 1</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>10:26746593-26860935</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>TSG, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>KMT2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...</td>\n",
       "      <td>[7LXE]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1</td>\n",
       "      <td>v-abl Abelson murine leukemia viral oncogene h...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9:130713946-130885683</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9q34.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CML, ALL, T-ALL</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T, Mis</td>\n",
       "      <td>BCR, ETV6, NUP214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...</td>\n",
       "      <td>[1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol                                               Name  \\\n",
       "0        A1CF                     APOBEC1 complementation factor   \n",
       "1        ABI1                                   abl-interactor 1   \n",
       "2        ABL1  v-abl Abelson murine leukemia viral oncogene h...   \n",
       "\n",
       "   Entrez GeneId        Genome Location  Tier Hallmark  Chr Band Somatic  \\\n",
       "0        29974.0   10:50799421-50885675     2      NaN  10q11.23     yes   \n",
       "1        10006.0   10:26746593-26860935     1      Yes   10p12.1     yes   \n",
       "2           25.0  9:130713946-130885683     1      Yes   9q34.12     yes   \n",
       "\n",
       "  Germline Tumour Types(Somatic)  ... Tissue Type Molecular Genetics  \\\n",
       "0      NaN              melanoma  ...           E                NaN   \n",
       "1      NaN                   AML  ...           L                Dom   \n",
       "2      NaN       CML, ALL, T-ALL  ...           L                Dom   \n",
       "\n",
       "     Role in Cancer Mutation Types Translocation Partner Other Germline Mut  \\\n",
       "0          oncogene            Mis                   NaN                NaN   \n",
       "1       TSG, fusion              T                 KMT2A                NaN   \n",
       "2  oncogene, fusion         T, Mis     BCR, ETV6, NUP214                NaN   \n",
       "\n",
       "  Other Syndrome                                           Synonyms  \\\n",
       "0            NaN  ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...   \n",
       "1            NaN  ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...   \n",
       "2            NaN  ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...   \n",
       "\n",
       "                                      PDB Structures n_structures  \n",
       "0                                             [2CPD]            4  \n",
       "1                                             [7LXE]            4  \n",
       "2  [1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...           81  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgc_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>...</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PDB Structures</th>\n",
       "      <th>n_structures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>29974.0</td>\n",
       "      <td>10:50799421-50885675</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...</td>\n",
       "      <td>[2CPD]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI1</td>\n",
       "      <td>abl-interactor 1</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>10:26746593-26860935</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>TSG, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>KMT2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...</td>\n",
       "      <td>[7LXE]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1</td>\n",
       "      <td>v-abl Abelson murine leukemia viral oncogene h...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9:130713946-130885683</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9q34.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CML, ALL, T-ALL</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T, Mis</td>\n",
       "      <td>BCR, ETV6, NUP214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...</td>\n",
       "      <td>[1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol                                               Name  \\\n",
       "0        A1CF                     APOBEC1 complementation factor   \n",
       "1        ABI1                                   abl-interactor 1   \n",
       "2        ABL1  v-abl Abelson murine leukemia viral oncogene h...   \n",
       "\n",
       "   Entrez GeneId        Genome Location  Tier Hallmark  Chr Band Somatic  \\\n",
       "0        29974.0   10:50799421-50885675     2      NaN  10q11.23     yes   \n",
       "1        10006.0   10:26746593-26860935     1      Yes   10p12.1     yes   \n",
       "2           25.0  9:130713946-130885683     1      Yes   9q34.12     yes   \n",
       "\n",
       "  Germline Tumour Types(Somatic)  ... Tissue Type Molecular Genetics  \\\n",
       "0      NaN              melanoma  ...           E                NaN   \n",
       "1      NaN                   AML  ...           L                Dom   \n",
       "2      NaN       CML, ALL, T-ALL  ...           L                Dom   \n",
       "\n",
       "     Role in Cancer Mutation Types Translocation Partner Other Germline Mut  \\\n",
       "0          oncogene            Mis                   NaN                NaN   \n",
       "1       TSG, fusion              T                 KMT2A                NaN   \n",
       "2  oncogene, fusion         T, Mis     BCR, ETV6, NUP214                NaN   \n",
       "\n",
       "  Other Syndrome                                           Synonyms  \\\n",
       "0            NaN  ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...   \n",
       "1            NaN  ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...   \n",
       "2            NaN  ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...   \n",
       "\n",
       "                                      PDB Structures n_structures  \n",
       "0                                             [2CPD]            1  \n",
       "1                                             [7LXE]            1  \n",
       "2  [1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...           81  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of elements in each pdb_structure\n",
    "lens = []\n",
    "for i in pdb_structures:\n",
    "    # if value is list\n",
    "    if isinstance(i, list):\n",
    "        lens.append(len(i))\n",
    "    elif i is not None:\n",
    "        lens.append(1)\n",
    "    else:\n",
    "        lens.append(0)\n",
    "\n",
    "cgc_data['n_structures'] = lens\n",
    "cgc_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_data.to_csv('Census_all_with_pdb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_genes = [\"KRAS\", \"EGFR\", \"TP53\", \"HRAS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download PDB file 7Q9U. Status code: 404 remaining))\n",
      "Failed to get resolution for 7Q9U with error [Errno 2] No such file or directory: 'pdb_files/7Q9U.pdb'\n",
      "Downloading PDB file 8FG4 for HRAS (0 structures remaining)))\r"
     ]
    }
   ],
   "source": [
    "# download pdb files\n",
    "\n",
    "resolutions = defaultdict(dict)\n",
    "\n",
    "# count number of structures for all gene\n",
    "n_total = cgc_data[cgc_data['Gene Symbol'].isin(tmp_genes)][\"n_structures\"].sum()\n",
    "\n",
    "for gene in tmp_genes:\n",
    "    pdb_structures = cgc_data[cgc_data['Gene Symbol'] == gene]['PDB Structures'].values[0]\n",
    "    if pdb_structures:\n",
    "        for pdb_id in pdb_structures:\n",
    "            n_total -= 1\n",
    "            print(f\"Downloading PDB file {pdb_id} for {gene} ({n_total} structures remaining)\", end='\\r')\n",
    "            # check if the file already exists\n",
    "            if not os.path.exists(f'pdb_files/{pdb_id}.pdb'):\n",
    "                dwl_pdb_file(pdb_id)\n",
    "            resolution = get_resolution(pdb_id)\n",
    "            resolutions[gene][pdb_id] = resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 30 structures for Gene KRAS:\n",
      "PDB ID: 6P0Z, Resolution: 1.01\n",
      "PDB ID: 8ONV, Resolution: 1.01\n",
      "PDB ID: 8AZZ, Resolution: 1.02\n",
      "PDB ID: 4QL3, Resolution: 1.04\n",
      "PDB ID: 8AZX, Resolution: 1.04\n",
      "PDB ID: 8B00, Resolution: 1.04\n",
      "PDB ID: 8AZV, Resolution: 1.05\n",
      "PDB ID: 8AZY, Resolution: 1.09\n",
      "PDB ID: 8B78, Resolution: 1.11\n",
      "PDB ID: 8AFB, Resolution: 1.12\n",
      "PDB ID: 4TQA, Resolution: 1.13\n",
      "PDB ID: 4LDJ, Resolution: 1.15\n",
      "PDB ID: 6TAN, Resolution: 1.16\n",
      "PDB ID: 7O70, Resolution: 1.18\n",
      "PDB ID: 8EDY, Resolution: 1.18\n",
      "PDB ID: 8EER, Resolution: 1.18\n",
      "PDB ID: 4Q03, Resolution: 1.20\n",
      "PDB ID: 7R0N, Resolution: 1.20\n",
      "PDB ID: 8EBZ, Resolution: 1.20\n",
      "PDB ID: 8TXH, Resolution: 1.20\n",
      "PDB ID: 4OBE, Resolution: 1.24\n",
      "PDB ID: 6QUW, Resolution: 1.24\n",
      "PDB ID: 5XCO, Resolution: 1.25\n",
      "PDB ID: 7RT1, Resolution: 1.27\n",
      "PDB ID: 7T47, Resolution: 1.27\n",
      "PDB ID: 4LUC, Resolution: 1.29\n",
      "PDB ID: 4Q01, Resolution: 1.29\n",
      "PDB ID: 6B0V, Resolution: 1.29\n",
      "PDB ID: 7RT5, Resolution: 1.29\n",
      "PDB ID: 7RPZ, Resolution: 1.30\n",
      "\n",
      "Top 30 structures for Gene EGFR:\n",
      "PDB ID: 8A27, Resolution: 1.07\n",
      "PDB ID: 8A2D, Resolution: 1.11\n",
      "PDB ID: 5UG9, Resolution: 1.33\n",
      "PDB ID: 5HG8, Resolution: 1.42\n",
      "PDB ID: 8A2A, Resolution: 1.43\n",
      "PDB ID: 5UG8, Resolution: 1.46\n",
      "PDB ID: 3POZ, Resolution: 1.50\n",
      "PDB ID: 6TFV, Resolution: 1.50\n",
      "PDB ID: 6TG0, Resolution: 1.50\n",
      "PDB ID: 3VRP, Resolution: 1.52\n",
      "PDB ID: 5HG5, Resolution: 1.52\n",
      "PDB ID: 5CNO, Resolution: 1.55\n",
      "PDB ID: 5UGC, Resolution: 1.58\n",
      "PDB ID: 3G5Y, Resolution: 1.59\n",
      "PDB ID: 5U8L, Resolution: 1.60\n",
      "PDB ID: 6TG1, Resolution: 1.60\n",
      "PDB ID: 7SI1, Resolution: 1.60\n",
      "PDB ID: 8A2B, Resolution: 1.69\n",
      "PDB ID: 3W33, Resolution: 1.70\n",
      "PDB ID: 6TFY, Resolution: 1.70\n",
      "PDB ID: 4I22, Resolution: 1.71\n",
      "PDB ID: 6WXN, Resolution: 1.76\n",
      "PDB ID: 6V66, Resolution: 1.79\n",
      "PDB ID: 3P0Y, Resolution: 1.80\n",
      "PDB ID: 3W32, Resolution: 1.80\n",
      "PDB ID: 4I24, Resolution: 1.80\n",
      "PDB ID: 5GNK, Resolution: 1.80\n",
      "PDB ID: 6TFZ, Resolution: 1.80\n",
      "PDB ID: 5UGA, Resolution: 1.82\n",
      "PDB ID: 7JXQ, Resolution: 1.83\n",
      "\n",
      "Top 30 structures for Gene TP53:\n",
      "PDB ID: 3D06, Resolution: 1.20\n",
      "PDB ID: 5MHC, Resolution: 1.20\n",
      "PDB ID: 6GGC, Resolution: 1.24\n",
      "PDB ID: 6SHZ, Resolution: 1.24\n",
      "PDB ID: 4MZI, Resolution: 1.25\n",
      "PDB ID: 6GGE, Resolution: 1.25\n",
      "PDB ID: 3LW1, Resolution: 1.28\n",
      "PDB ID: 5O1E, Resolution: 1.30\n",
      "PDB ID: 6RL3, Resolution: 1.30\n",
      "PDB ID: 8E7A, Resolution: 1.30\n",
      "PDB ID: 5O1C, Resolution: 1.32\n",
      "PDB ID: 5O1H, Resolution: 1.32\n",
      "PDB ID: 6GGB, Resolution: 1.32\n",
      "PDB ID: 6GGF, Resolution: 1.32\n",
      "PDB ID: 7B4N, Resolution: 1.32\n",
      "PDB ID: 3ZME, Resolution: 1.35\n",
      "PDB ID: 5AOK, Resolution: 1.35\n",
      "PDB ID: 5G4N, Resolution: 1.35\n",
      "PDB ID: 5O1G, Resolution: 1.35\n",
      "PDB ID: 6V4F, Resolution: 1.35\n",
      "PDB ID: 5AB9, Resolution: 1.36\n",
      "PDB ID: 5O1D, Resolution: 1.36\n",
      "PDB ID: 8A92, Resolution: 1.37\n",
      "PDB ID: 5G4M, Resolution: 1.38\n",
      "PDB ID: 5O1F, Resolution: 1.38\n",
      "PDB ID: 7B4H, Resolution: 1.39\n",
      "PDB ID: 1YC5, Resolution: 1.40\n",
      "PDB ID: 3D08, Resolution: 1.40\n",
      "PDB ID: 5A7B, Resolution: 1.40\n",
      "PDB ID: 5O1I, Resolution: 1.40\n",
      "\n",
      "Top 30 structures for Gene HRAS:\n",
      "PDB ID: 2CE2, Resolution: 1.00\n",
      "PDB ID: 2EVW, Resolution: 1.05\n",
      "PDB ID: 2CLD, Resolution: 1.22\n",
      "PDB ID: 2CL6, Resolution: 1.24\n",
      "PDB ID: 2CL7, Resolution: 1.25\n",
      "PDB ID: 5WDQ, Resolution: 1.25\n",
      "PDB ID: 1CTQ, Resolution: 1.26\n",
      "PDB ID: 2CLC, Resolution: 1.30\n",
      "PDB ID: 3K8Y, Resolution: 1.30\n",
      "PDB ID: 3OIW, Resolution: 1.30\n",
      "PDB ID: 3TGP, Resolution: 1.31\n",
      "PDB ID: 3OIU, Resolution: 1.32\n",
      "PDB ID: 4DLR, Resolution: 1.32\n",
      "PDB ID: 8BWG, Resolution: 1.32\n",
      "PDB ID: 2RGB, Resolution: 1.35\n",
      "PDB ID: 5P21, Resolution: 1.35\n",
      "PDB ID: 5WDP, Resolution: 1.35\n",
      "PDB ID: 8CNJ, Resolution: 1.35\n",
      "PDB ID: 3I3S, Resolution: 1.36\n",
      "PDB ID: 2RGE, Resolution: 1.40\n",
      "PDB ID: 3RS0, Resolution: 1.40\n",
      "PDB ID: 5E95, Resolution: 1.40\n",
      "PDB ID: 3L8Z, Resolution: 1.44\n",
      "PDB ID: 2RGG, Resolution: 1.45\n",
      "PDB ID: 8CNN, Resolution: 1.48\n",
      "PDB ID: 2QUZ, Resolution: 1.49\n",
      "PDB ID: 8FG3, Resolution: 1.49\n",
      "PDB ID: 1ZW6, Resolution: 1.50\n",
      "PDB ID: 6MQT, Resolution: 1.50\n",
      "PDB ID: 821P, Resolution: 1.50\n"
     ]
    }
   ],
   "source": [
    "def sort_pdb_ids_by_resolution(gene_id):\n",
    "    pdb_resolutions = resolutions[gene_id]\n",
    "    sorted_pdb_ids = sorted(pdb_resolutions, key=lambda pdb_id: float('inf') if pdb_resolutions[pdb_id] is None else float(pdb_resolutions[pdb_id]))\n",
    "    sorted_resolutions = [(pdb_id, pdb_resolutions[pdb_id]) for pdb_id in sorted_pdb_ids]\n",
    "    return sorted_resolutions\n",
    "\n",
    "top_structures = dict()\n",
    "n = 30\n",
    "for gene_id in resolutions:\n",
    "    sorted_pdb_resolutions = sort_pdb_ids_by_resolution(gene_id)\n",
    "    print(f\"\\nTop {n} structures for Gene {gene_id}:\")\n",
    "    for pdb_id, resolution in sorted_pdb_resolutions[:n]:\n",
    "        print(f\"PDB ID: {pdb_id}, Resolution: {resolution}\")\n",
    "    top_structures[gene_id] = [i[0] for i in sorted_pdb_resolutions[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save top_structures to a file\n",
    "with open(f'top_{n}_structures.txt', 'w') as f:\n",
    "\tf.write(str(top_structures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KRAS': ['6P0Z',\n",
       "  '8ONV',\n",
       "  '8AZZ',\n",
       "  '4QL3',\n",
       "  '8AZX',\n",
       "  '8B00',\n",
       "  '8AZV',\n",
       "  '8AZY',\n",
       "  '8B78',\n",
       "  '8AFB',\n",
       "  '4TQA',\n",
       "  '4LDJ',\n",
       "  '6TAN',\n",
       "  '7O70',\n",
       "  '8EDY',\n",
       "  '8EER',\n",
       "  '4Q03',\n",
       "  '7R0N',\n",
       "  '8EBZ',\n",
       "  '8TXH',\n",
       "  '4OBE',\n",
       "  '6QUW',\n",
       "  '5XCO',\n",
       "  '7RT1',\n",
       "  '7T47',\n",
       "  '4LUC',\n",
       "  '4Q01',\n",
       "  '6B0V',\n",
       "  '7RT5',\n",
       "  '7RPZ'],\n",
       " 'EGFR': ['8A27',\n",
       "  '8A2D',\n",
       "  '5UG9',\n",
       "  '5HG8',\n",
       "  '8A2A',\n",
       "  '5UG8',\n",
       "  '3POZ',\n",
       "  '6TFV',\n",
       "  '6TG0',\n",
       "  '3VRP',\n",
       "  '5HG5',\n",
       "  '5CNO',\n",
       "  '5UGC',\n",
       "  '3G5Y',\n",
       "  '5U8L',\n",
       "  '6TG1',\n",
       "  '7SI1',\n",
       "  '8A2B',\n",
       "  '3W33',\n",
       "  '6TFY',\n",
       "  '4I22',\n",
       "  '6WXN',\n",
       "  '6V66',\n",
       "  '3P0Y',\n",
       "  '3W32',\n",
       "  '4I24',\n",
       "  '5GNK',\n",
       "  '6TFZ',\n",
       "  '5UGA',\n",
       "  '7JXQ'],\n",
       " 'TP53': ['3D06',\n",
       "  '5MHC',\n",
       "  '6GGC',\n",
       "  '6SHZ',\n",
       "  '4MZI',\n",
       "  '6GGE',\n",
       "  '3LW1',\n",
       "  '5O1E',\n",
       "  '6RL3',\n",
       "  '8E7A',\n",
       "  '5O1C',\n",
       "  '5O1H',\n",
       "  '6GGB',\n",
       "  '6GGF',\n",
       "  '7B4N',\n",
       "  '3ZME',\n",
       "  '5AOK',\n",
       "  '5G4N',\n",
       "  '5O1G',\n",
       "  '6V4F',\n",
       "  '5AB9',\n",
       "  '5O1D',\n",
       "  '8A92',\n",
       "  '5G4M',\n",
       "  '5O1F',\n",
       "  '7B4H',\n",
       "  '1YC5',\n",
       "  '3D08',\n",
       "  '5A7B',\n",
       "  '5O1I'],\n",
       " 'HRAS': ['2CE2',\n",
       "  '2EVW',\n",
       "  '2CLD',\n",
       "  '2CL6',\n",
       "  '2CL7',\n",
       "  '5WDQ',\n",
       "  '1CTQ',\n",
       "  '2CLC',\n",
       "  '3K8Y',\n",
       "  '3OIW',\n",
       "  '3TGP',\n",
       "  '3OIU',\n",
       "  '4DLR',\n",
       "  '8BWG',\n",
       "  '2RGB',\n",
       "  '5P21',\n",
       "  '5WDP',\n",
       "  '8CNJ',\n",
       "  '3I3S',\n",
       "  '2RGE',\n",
       "  '3RS0',\n",
       "  '5E95',\n",
       "  '3L8Z',\n",
       "  '2RGG',\n",
       "  '8CNN',\n",
       "  '2QUZ',\n",
       "  '8FG3',\n",
       "  '1ZW6',\n",
       "  '6MQT',\n",
       "  '821P']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read top_structures from file\n",
    "with open(f'top_30_structures.txt', 'r') as f:\n",
    "\ttop_structures = ast.literal_eval(f.read())\n",
    "top_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under the terms of the\n",
      "GNU General Public License versions 2 or 3.\n",
      "For more information about these matters see\n",
      "https://www.gnu.org/licenses/.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing 5CNO with chain X...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 19:56:54 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 5CNO.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain X\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"5CNO.pdb\"\n",
      "    }\n",
      "    default_model = \"5CNO.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain X\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 5579 size after: 84\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 4.24 seconds\n",
      "wall clock time: 6.19 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 19:56:57 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 5CNO_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"5CNO_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"5CNO_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 84 size after: 79\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.62 seconds\n",
      "wall clock time: 1.64 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "Removing duplicates from BFactor file\n",
      "Making 5CNO_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 19:57:12 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 5CNO_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"5CNO_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"5CNO_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 5579 size after: 5038\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 2.02 seconds\n",
      "wall clock time: 2.04 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are ANP-1001B, ANP-1001A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 5CNO_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "\n",
      "No hydrogen bonds found in 5CNO_monomer_nowaters.pdb\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yliy0004/ym65_scratch/yliy0004/NetworkAnalysis/pdb2edgeSC.py\", line 349, in <module>\n",
      "    if prevStruct == \"Coil\" or prevStruct == \"Bridge\":\n",
      "NameError: name 'prevStruct' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yliy0004/ym65_scratch/yliy0004/NetworkAnalysis/removeDuplicates-BFactor.py\", line 6, in <module>\n",
      "    file = open(sys.argv[1],'r')\n",
      "IOError: [Errno 2] No such file or directory: '5CNO_monomer_nowaters_Bfactor'\n",
      "mv: cannot stat ‘5CNO_monomer_nowaters_Bfactor_duplicatesRemoved’: No such file or directory\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_vdw' for reading (No such file or directory)\n",
      "grep: 5CNO_monomer_nowaters_vdw: No such file or directory\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_pipi2' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_pication2' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_disulf' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_saltBridges_Barlow' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_hb' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_metal' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_DNA' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `5CNO_monomer_nowaters_vdw2' for reading (No such file or directory)\n",
      "grep: 5CNO_monomer_nowaters_vdw2: No such file or directory\n",
      "cp: cannot stat ‘5CNO_monomer_nowaters_centroid*’: No such file or directory\n",
      "cp: cannot stat ‘5CNO_monomer_nowaters.rsa’: No such file or directory\n",
      "mv: cannot stat ‘5CNO_monomer_nowaters_centroidNetSC’: No such file or directory\n",
      "mv: cannot stat ‘5CNO_monomer_nowaters_centroidNetLigand’: No such file or directory\n",
      "cp: cannot stat ‘5CNO_monomer_nowaters_secondaryStructure2’: No such file or directory\n",
      "cp: cannot stat ‘5CNO_monomer_nowaters_Bfactor’: No such file or directory\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Error in read.table(args[3]) : no lines available in input\n",
      "Calls: as.matrix -> read.table\n",
      "Execution halted\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Error in file(file, \"r\") : cannot open the connection\n",
      "Calls: scan -> file\n",
      "In addition: Warning message:\n",
      "In file(file, \"r\") :\n",
      "  cannot open file '5CNO_monomer_nowaters_centroid_ligand': No such file or directory\n",
      "Execution halted\n",
      "*WARNING*: Residues GLU 725  and ALA 731  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 725  and ALA 731  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLY 839  and LYS 851  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLY 839  and LYS 851  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 725  and LYS 730  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 725  and LYS 730  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues LEU 838  and LYS 851  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues LEU 838  and LYS 851  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 2571 items\n",
      "Read 2571 items\n",
      "Error in file(file, \"rt\") : invalid 'description' argument\n",
      "Calls: read.table -> file\n",
      "Execution halted\n",
      "\n",
      "Final_sum file not found for 5CNO\n",
      "\n",
      "Processing 3P0Y with chain A...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:03:10 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3P0Y.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain A\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3P0Y.pdb\"\n",
      "    }\n",
      "    default_model = \"3P0Y.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain A\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 5590 size after: 1693\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 3.61 seconds\n",
      "wall clock time: 5.80 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:03:14 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3P0Y_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3P0Y_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"3P0Y_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 1693 size after: 1530\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.71 seconds\n",
      "wall clock time: 1.73 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are \n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 3P0Y_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:04:11 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3P0Y_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3P0Y_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"3P0Y_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 5590 size after: 4940\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 2.34 seconds\n",
      "wall clock time: 2.36 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are NAG-1B, NAG-1C, FUL-3C, NAG-1D, NAG-2C, NAG-2B, NAG-2D, GOL-401H\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Removing duplicates from BFactor file\n",
      "Making 3P0Y_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 0 items\n",
      "Read 0 items\n",
      "*WARNING*: Residues SER 128  and GLY 134  in chain  H appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues SER 128  and GLY 134  in chain  H appear unbonded \n",
      "            and will be treated as a chain break\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yliy0004/ym65_scratch/yliy0004/NetworkAnalysis/pdb2edgeSC.py\", line 882, in <module>\n",
      "    a = numpy.array([coords[\"-\".join(dA.split(\"-\")[0:2])+\"-HD21\"][0]-origin[0],coords[\"-\".join(dA.split(\"-\")[0:2])+\"-HD21\"][1]-origin[1],coords[\"-\".join(dA.split(\"-\")[0:2])+\"-HD21\"][2]-origin[2]])\n",
      "KeyError: 'ASN-420A-HD21'\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_vdw' for reading (No such file or directory)\n",
      "grep: 3P0Y_multimer_nowaters_vdw: No such file or directory\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_pipi2' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_pication2' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_disulf' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_hb' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_metal' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_DNA' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3P0Y_multimer_nowaters_vdw2' for reading (No such file or directory)\n",
      "grep: 3P0Y_multimer_nowaters_vdw2: No such file or directory\n",
      "cp: cannot stat ‘3P0Y_multimer_nowaters_centroid*’: No such file or directory\n",
      "mv: cannot stat ‘3P0Y_multimer_nowaters_centroidNetSC’: No such file or directory\n",
      "mv: cannot stat ‘3P0Y_multimer_nowaters_centroidNetLigand’: No such file or directory\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Error in file(file, \"r\") : cannot open the connection\n",
      "Calls: scan -> file\n",
      "In addition: Warning message:\n",
      "In file(file, \"r\") :\n",
      "  cannot open file '3P0Y_multimer_nowaters_centroid_ligand': No such file or directory\n",
      "Execution halted\n",
      "Error in file(file, \"rt\") : invalid 'description' argument\n",
      "Calls: read.table -> file\n",
      "Execution halted\n",
      "\n",
      "Final_sum file not found for 3P0Y\n",
      "\n",
      "Processing 7JXQ with chain C...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:05:39 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 7JXQ.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain C\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"7JXQ.pdb\"\n",
      "    }\n",
      "    default_model = \"7JXQ.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain C\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 10431 size after: 2625\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 3.87 seconds\n",
      "wall clock time: 5.84 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:05:43 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 7JXQ_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"7JXQ_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"7JXQ_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2625 size after: 2469\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.86 seconds\n",
      "wall clock time: 1.88 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are ANP-1103C, VNS-1102C\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 7JXQ_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:08:00 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 7JXQ_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"7JXQ_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"7JXQ_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 10431 size after: 9890\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 4.09 seconds\n",
      "wall clock time: 5.77 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are VNS-1102A, VNS-1103B, VNS-1102C, ANP-1103A, ANP-1102D, VNS-1103D, ANP-1103C, ANP-1102B\n",
      "Screening for atoms that are close.\n",
      "19434 atoms in total. Using slower low memory approach.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 7JXQ_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = data2Multimer[rownames(data1Multimer),]\n",
      "> data1MultimerZ = as.data.frame(apply(data1Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1MultimerZ) = rownames(data1Multimer)\n",
      "> data2MultimerZ = as.data.frame(apply(data2Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2MultimerZ) = rownames(data2Multimer)\n",
      "> colnames(data1MultimerZ) = paste(colnames(data1MultimerZ),\"MULTIMER\",sep=\"\")\n",
      "> colnames(data2MultimerZ) = paste(colnames(data2MultimerZ),\"MULTIMERCENTROIDSC\",sep=\"\")\n",
      "> data2MultimerZ = data2MultimerZ[rownames(data1MultimerZ),]\n",
      "> \n",
      "> #Add RSA\n",
      "> data1 = cbind(data2[,\"RSA\"],data1)\n",
      "> colnames(data1)[1]=\"RSA\"\n",
      "> dataZ = cbind(data1Z,data2Z)\n",
      "> \n",
      "> #Identify max NodeEdgeBetweennessSTRIDE_sidechain\n",
      "> acidsMonomer = c()\n",
      "> for (i in 1:length(rownames(dataZ))) {\n",
      "+     node = rownames(dataZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMonomer = c(acidsMonomer,node)\n",
      "+ }\n",
      "> \n",
      "> acidsMultimer = c()\n",
      "> for (i in 1:length(rownames(data1MultimerZ))) {\n",
      "+     node = rownames(data1MultimerZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMultimer = c(acidsMultimer,node)\n",
      "+ }\n",
      "> \n",
      "> allAcids = unique(c(acidsMonomer,acidsMultimer))\n",
      "> \n",
      "> #SecondOrderIntermodularDegree is the average of the multimer only\n",
      "> SecondOrderIntermodularDegree_ALL = (data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDE_sidechainMULTIMER\"]+data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMER\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMERCENTROIDSC\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeWALKTRAPMULTIMERCENTROIDSC\"])/4\n",
      "> SecondOrderIntermodularDegree_AVERAGE = tapply(SecondOrderIntermodularDegree_ALL,as.factor(acidsMultimer),mean)\n",
      "> SecondOrderIntermodularDegree_AVERAGE = SecondOrderIntermodularDegree_AVERAGE[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> SecondOrderIntermodularDegree_AVERAGE[missing] = (data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE_sidechain\"]+data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDECENTROIDSC\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeWALKTRAPCENTROIDSC\"])/4\n",
      "> names(SecondOrderIntermodularDegree_AVERAGE)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> \n",
      "> #NodeEdgeBetweenness is the max of the monomer/multimer\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER = (dataZ[,\"NodeEdgeBetweennessSTRIDE\"]+dataZ[,\"NodeEdgeBetweennessSTRIDE_sidechain\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER = (data1MultimerZ[,\"NodeEdgeBetweennessSTRIDEMULTIMER\"]+data1MultimerZ[,\"NodeEdgeBetweennessSTRIDE_sidechainMULTIMER\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_ALL = c(NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER,NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = tapply(NodeEdgeBetweennessSTRIDE_sidechain_ALL,as.factor(c(acidsMonomer,acidsMultimer)),max,na.rm=TRUE)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = NodeEdgeBetweennessSTRIDE_sidechain_MAX[allAcids]\n",
      "> \n",
      "> #Ligand is the min of the multimer only\n",
      "> LigandMULTIMERCENTROIDSC_ALL = data2MultimerZ[,\"LigandMULTIMERCENTROIDSC\"]\n",
      "> LigandMULTIMERCENTROIDSC_MIN = tapply(LigandMULTIMERCENTROIDSC_ALL,as.factor(acidsMultimer),min)\n",
      "> LigandMULTIMERCENTROIDSC_MIN = LigandMULTIMERCENTROIDSC_MIN[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> LigandMULTIMERCENTROIDSC_MIN[missing] = dataZ[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"LigandCENTROIDSC\"]\n",
      "> names(LigandMULTIMERCENTROIDSC_MIN)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> LigandMULTIMERCENTROIDSC_MIN[is.na(LigandMULTIMERCENTROIDSC_MIN)] = 0\n",
      "> \n",
      "> #RSA\n",
      "> RSA_ALL = c(data1[,\"RSA\"],data2Multimer[,\"RSA\"])\n",
      "> RSA_MIN = tapply(RSA_ALL,as.factor(c(acidsMonomer,acidsMultimer)),min,na.rm=TRUE)\n",
      "> RSA_MIN = RSA_MIN[allAcids]\n",
      "> \n",
      "> y = SecondOrderIntermodularDegree_AVERAGE+NodeEdgeBetweennessSTRIDE_sidechain_MAX-LigandMULTIMERCENTROIDSC_MIN\n",
      "> \n",
      "> out=cbind(names(y),y)\n",
      "> acidNumbers = sapply(out[,1],substring,4)\n",
      "> out = out[order(as.numeric(acidNumbers)),]\n",
      "> write.table(out,file=\"FinalSum\",sep=\"\\t\",quote=FALSE,row.names=FALSE,col.names=FALSE)\n",
      "> \n",
      "> # also write the 3 variables to a file\n",
      "> # Concatenating all three variables into a single data frame\n",
      "> result <- data.frame(\n",
      "+   Acid = names(SecondOrderIntermodularDegree_AVERAGE),\n",
      "+   SecondOrderIntermodularDegree_AVERAGE,\n",
      "+   NodeEdgeBetweennessSTRIDE_sidechain_MAX,\n",
      "+   LigandMULTIMERCENTROIDSC_MIN\n",
      "+ )\n",
      "> \n",
      "> # Writing the data frame to a file\n",
      "> write.table(result, file = \"FinalSum_Decomp\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n",
      "> \n",
      "\n",
      "*WARNING*: Residues GLU 865  and VAL 876  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 865  and VAL 876  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Res \"VNS\" not in HETATM Connection Database. Hydrogens not added.\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 1227 items\n",
      "Read 1227 items\n",
      "*WARNING*: Residues GLU 865  and VAL 876  in chain  D appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 865  and VAL 876  in chain  D appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues LEU 862  and LYS 875  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues LEU 862  and LYS 875  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues ALA 864  and LYS 875  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues ALA 864  and LYS 875  in chain  B appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 865  and VAL 876  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLU 865  and VAL 876  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "*WARNING*: Res \"VNS\" not in HETATM Connection Database. Hydrogens not added.\n",
      "*WARNING*: Res \"VNS\" not in HETATM Connection Database. Hydrogens not added.\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "*WARNING*: Res \"VNS\" not in HETATM Connection Database. Hydrogens not added.\n",
      "*WARNING*: Res \"VNS\" not in HETATM Connection Database. Hydrogens not added.\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HNB1 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN62 from ANP will be treated as hydrogen\n",
      "WARNING: atom HN61 from ANP will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 9510 items\n",
      "Read 9510 items\n",
      "\n",
      "SBNA results for 7JXQ succesfully downloaded\n",
      "\n",
      "Processing 3LW1 with chain P...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:36:42 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3LW1.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain P\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3LW1.pdb\"\n",
      "    }\n",
      "    default_model = \"3LW1.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain P\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2559 size after: 71\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 5.01 seconds\n",
      "wall clock time: 10.95 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:38:48 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3LW1_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3LW1_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"3LW1_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 71 size after: 59\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 4.83 seconds\n",
      "wall clock time: 14.30 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "Removing duplicates from BFactor file\n",
      "Making 3LW1_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:41:04 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3LW1_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3LW1_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"3LW1_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2559 size after: 2155\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 4.59 seconds\n",
      "wall clock time: 18.54 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are TPO-387P, GOL-253A, CL-252A, CSO-38A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 3LW1_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "\n",
      "No hydrogen bonds found in 3LW1_monomer_nowaters.pdb\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yliy0004/ym65_scratch/yliy0004/NetworkAnalysis/pdb2edgeSC.py\", line 349, in <module>\n",
      "    if prevStruct == \"Coil\" or prevStruct == \"Bridge\":\n",
      "NameError: name 'prevStruct' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yliy0004/ym65_scratch/yliy0004/NetworkAnalysis/removeDuplicates-BFactor.py\", line 6, in <module>\n",
      "    file = open(sys.argv[1],'r')\n",
      "IOError: [Errno 2] No such file or directory: '3LW1_monomer_nowaters_Bfactor'\n",
      "mv: cannot stat ‘3LW1_monomer_nowaters_Bfactor_duplicatesRemoved’: No such file or directory\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_vdw' for reading (No such file or directory)\n",
      "grep: 3LW1_monomer_nowaters_vdw: No such file or directory\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_pipi2' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_pication2' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_disulf' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_saltBridges_Barlow' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_hb' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_metal' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_DNA' for reading (No such file or directory)\n",
      "awk: fatal: cannot open file `3LW1_monomer_nowaters_vdw2' for reading (No such file or directory)\n",
      "grep: 3LW1_monomer_nowaters_vdw2: No such file or directory\n",
      "cp: cannot stat ‘3LW1_monomer_nowaters_centroid*’: No such file or directory\n",
      "cp: cannot stat ‘3LW1_monomer_nowaters.rsa’: No such file or directory\n",
      "mv: cannot stat ‘3LW1_monomer_nowaters_centroidNetSC’: No such file or directory\n",
      "mv: cannot stat ‘3LW1_monomer_nowaters_centroidNetLigand’: No such file or directory\n",
      "cp: cannot stat ‘3LW1_monomer_nowaters_secondaryStructure2’: No such file or directory\n",
      "cp: cannot stat ‘3LW1_monomer_nowaters_Bfactor’: No such file or directory\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Error in read.table(args[3]) : no lines available in input\n",
      "Calls: as.matrix -> read.table\n",
      "Execution halted\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Error in file(file, \"r\") : cannot open the connection\n",
      "Calls: scan -> file\n",
      "In addition: Warning message:\n",
      "In file(file, \"r\") :\n",
      "  cannot open file '3LW1_monomer_nowaters_centroid_ligand': No such file or directory\n",
      "Execution halted\n",
      "*WARNING*: Residues GLY 137  and ASP 139  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues GLY 137  and ASP 139  in chain  A appear unbonded \n",
      "            and will be treated as a chain break\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 1146 items\n",
      "Read 1146 items\n",
      "Error in file(file, \"rt\") : invalid 'description' argument\n",
      "Calls: read.table -> file\n",
      "Execution halted\n",
      "\n",
      "Final_sum file not found for 3LW1\n",
      "\n",
      "Processing 6GGF with chain A...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:42:59 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 6GGF.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain A\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"6GGF.pdb\"\n",
      "    }\n",
      "    default_model = \"6GGF.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain A\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 3624 size after: 1796\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 3.43 seconds\n",
      "wall clock time: 4.41 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:43:02 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 6GGF_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"6GGF_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"6GGF_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 1796 size after: 1568\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.77 seconds\n",
      "wall clock time: 1.80 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are EXQ-402A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 6GGF_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:43:41 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 6GGF_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"6GGF_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"6GGF_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 3624 size after: 3170\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.88 seconds\n",
      "wall clock time: 1.90 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are GOL-403B, EXQ-402B, EXQ-402A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 6GGF_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = data2Multimer[rownames(data1Multimer),]\n",
      "> data1MultimerZ = as.data.frame(apply(data1Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1MultimerZ) = rownames(data1Multimer)\n",
      "> data2MultimerZ = as.data.frame(apply(data2Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2MultimerZ) = rownames(data2Multimer)\n",
      "> colnames(data1MultimerZ) = paste(colnames(data1MultimerZ),\"MULTIMER\",sep=\"\")\n",
      "> colnames(data2MultimerZ) = paste(colnames(data2MultimerZ),\"MULTIMERCENTROIDSC\",sep=\"\")\n",
      "> data2MultimerZ = data2MultimerZ[rownames(data1MultimerZ),]\n",
      "> \n",
      "> #Add RSA\n",
      "> data1 = cbind(data2[,\"RSA\"],data1)\n",
      "> colnames(data1)[1]=\"RSA\"\n",
      "> dataZ = cbind(data1Z,data2Z)\n",
      "> \n",
      "> #Identify max NodeEdgeBetweennessSTRIDE_sidechain\n",
      "> acidsMonomer = c()\n",
      "> for (i in 1:length(rownames(dataZ))) {\n",
      "+     node = rownames(dataZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMonomer = c(acidsMonomer,node)\n",
      "+ }\n",
      "> \n",
      "> acidsMultimer = c()\n",
      "> for (i in 1:length(rownames(data1MultimerZ))) {\n",
      "+     node = rownames(data1MultimerZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMultimer = c(acidsMultimer,node)\n",
      "+ }\n",
      "> \n",
      "> allAcids = unique(c(acidsMonomer,acidsMultimer))\n",
      "> \n",
      "> #SecondOrderIntermodularDegree is the average of the multimer only\n",
      "> SecondOrderIntermodularDegree_ALL = (data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDE_sidechainMULTIMER\"]+data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMER\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMERCENTROIDSC\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeWALKTRAPMULTIMERCENTROIDSC\"])/4\n",
      "> SecondOrderIntermodularDegree_AVERAGE = tapply(SecondOrderIntermodularDegree_ALL,as.factor(acidsMultimer),mean)\n",
      "> SecondOrderIntermodularDegree_AVERAGE = SecondOrderIntermodularDegree_AVERAGE[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> SecondOrderIntermodularDegree_AVERAGE[missing] = (data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE_sidechain\"]+data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDECENTROIDSC\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeWALKTRAPCENTROIDSC\"])/4\n",
      "> names(SecondOrderIntermodularDegree_AVERAGE)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> \n",
      "> #NodeEdgeBetweenness is the max of the monomer/multimer\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER = (dataZ[,\"NodeEdgeBetweennessSTRIDE\"]+dataZ[,\"NodeEdgeBetweennessSTRIDE_sidechain\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER = (data1MultimerZ[,\"NodeEdgeBetweennessSTRIDEMULTIMER\"]+data1MultimerZ[,\"NodeEdgeBetweennessSTRIDE_sidechainMULTIMER\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_ALL = c(NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER,NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = tapply(NodeEdgeBetweennessSTRIDE_sidechain_ALL,as.factor(c(acidsMonomer,acidsMultimer)),max,na.rm=TRUE)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = NodeEdgeBetweennessSTRIDE_sidechain_MAX[allAcids]\n",
      "> \n",
      "> #Ligand is the min of the multimer only\n",
      "> LigandMULTIMERCENTROIDSC_ALL = data2MultimerZ[,\"LigandMULTIMERCENTROIDSC\"]\n",
      "> LigandMULTIMERCENTROIDSC_MIN = tapply(LigandMULTIMERCENTROIDSC_ALL,as.factor(acidsMultimer),min)\n",
      "> LigandMULTIMERCENTROIDSC_MIN = LigandMULTIMERCENTROIDSC_MIN[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> LigandMULTIMERCENTROIDSC_MIN[missing] = dataZ[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"LigandCENTROIDSC\"]\n",
      "> names(LigandMULTIMERCENTROIDSC_MIN)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> LigandMULTIMERCENTROIDSC_MIN[is.na(LigandMULTIMERCENTROIDSC_MIN)] = 0\n",
      "> \n",
      "> #RSA\n",
      "> RSA_ALL = c(data1[,\"RSA\"],data2Multimer[,\"RSA\"])\n",
      "> RSA_MIN = tapply(RSA_ALL,as.factor(c(acidsMonomer,acidsMultimer)),min,na.rm=TRUE)\n",
      "> RSA_MIN = RSA_MIN[allAcids]\n",
      "> \n",
      "> y = SecondOrderIntermodularDegree_AVERAGE+NodeEdgeBetweennessSTRIDE_sidechain_MAX-LigandMULTIMERCENTROIDSC_MIN\n",
      "> \n",
      "> out=cbind(names(y),y)\n",
      "> acidNumbers = sapply(out[,1],substring,4)\n",
      "> out = out[order(as.numeric(acidNumbers)),]\n",
      "> write.table(out,file=\"FinalSum\",sep=\"\\t\",quote=FALSE,row.names=FALSE,col.names=FALSE)\n",
      "> \n",
      "> # also write the 3 variables to a file\n",
      "> # Concatenating all three variables into a single data frame\n",
      "> result <- data.frame(\n",
      "+   Acid = names(SecondOrderIntermodularDegree_AVERAGE),\n",
      "+   SecondOrderIntermodularDegree_AVERAGE,\n",
      "+   NodeEdgeBetweennessSTRIDE_sidechain_MAX,\n",
      "+   LigandMULTIMERCENTROIDSC_MIN\n",
      "+ )\n",
      "> \n",
      "> # Writing the data frame to a file\n",
      "> write.table(result, file = \"FinalSum_Decomp\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n",
      "> \n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 588 items\n",
      "Read 588 items\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 2280 items\n",
      "Read 2280 items\n",
      "\n",
      "SBNA results for 6GGF succesfully downloaded\n",
      "\n",
      "Processing 3ZME with chain A...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:45:50 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3ZME.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain A\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3ZME.pdb\"\n",
      "    }\n",
      "    default_model = \"3ZME.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain A\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 3764 size after: 1865\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.85 seconds\n",
      "wall clock time: 1.87 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:45:53 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3ZME_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3ZME_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"3ZME_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 1865 size after: 1614\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.73 seconds\n",
      "wall clock time: 1.74 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are QC5-1291A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 3ZME_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:46:36 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 3ZME_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"3ZME_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"3ZME_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 3764 size after: 3252\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 2.11 seconds\n",
      "wall clock time: 2.13 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are QC5-1292B, QC5-1291A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 3ZME_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = data2Multimer[rownames(data1Multimer),]\n",
      "> data1MultimerZ = as.data.frame(apply(data1Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1MultimerZ) = rownames(data1Multimer)\n",
      "> data2MultimerZ = as.data.frame(apply(data2Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2MultimerZ) = rownames(data2Multimer)\n",
      "> colnames(data1MultimerZ) = paste(colnames(data1MultimerZ),\"MULTIMER\",sep=\"\")\n",
      "> colnames(data2MultimerZ) = paste(colnames(data2MultimerZ),\"MULTIMERCENTROIDSC\",sep=\"\")\n",
      "> data2MultimerZ = data2MultimerZ[rownames(data1MultimerZ),]\n",
      "> \n",
      "> #Add RSA\n",
      "> data1 = cbind(data2[,\"RSA\"],data1)\n",
      "> colnames(data1)[1]=\"RSA\"\n",
      "> dataZ = cbind(data1Z,data2Z)\n",
      "> \n",
      "> #Identify max NodeEdgeBetweennessSTRIDE_sidechain\n",
      "> acidsMonomer = c()\n",
      "> for (i in 1:length(rownames(dataZ))) {\n",
      "+     node = rownames(dataZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMonomer = c(acidsMonomer,node)\n",
      "+ }\n",
      "> \n",
      "> acidsMultimer = c()\n",
      "> for (i in 1:length(rownames(data1MultimerZ))) {\n",
      "+     node = rownames(data1MultimerZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMultimer = c(acidsMultimer,node)\n",
      "+ }\n",
      "> \n",
      "> allAcids = unique(c(acidsMonomer,acidsMultimer))\n",
      "> \n",
      "> #SecondOrderIntermodularDegree is the average of the multimer only\n",
      "> SecondOrderIntermodularDegree_ALL = (data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDE_sidechainMULTIMER\"]+data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMER\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMERCENTROIDSC\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeWALKTRAPMULTIMERCENTROIDSC\"])/4\n",
      "> SecondOrderIntermodularDegree_AVERAGE = tapply(SecondOrderIntermodularDegree_ALL,as.factor(acidsMultimer),mean)\n",
      "> SecondOrderIntermodularDegree_AVERAGE = SecondOrderIntermodularDegree_AVERAGE[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> SecondOrderIntermodularDegree_AVERAGE[missing] = (data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE_sidechain\"]+data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDECENTROIDSC\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeWALKTRAPCENTROIDSC\"])/4\n",
      "> names(SecondOrderIntermodularDegree_AVERAGE)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> \n",
      "> #NodeEdgeBetweenness is the max of the monomer/multimer\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER = (dataZ[,\"NodeEdgeBetweennessSTRIDE\"]+dataZ[,\"NodeEdgeBetweennessSTRIDE_sidechain\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER = (data1MultimerZ[,\"NodeEdgeBetweennessSTRIDEMULTIMER\"]+data1MultimerZ[,\"NodeEdgeBetweennessSTRIDE_sidechainMULTIMER\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_ALL = c(NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER,NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = tapply(NodeEdgeBetweennessSTRIDE_sidechain_ALL,as.factor(c(acidsMonomer,acidsMultimer)),max,na.rm=TRUE)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = NodeEdgeBetweennessSTRIDE_sidechain_MAX[allAcids]\n",
      "> \n",
      "> #Ligand is the min of the multimer only\n",
      "> LigandMULTIMERCENTROIDSC_ALL = data2MultimerZ[,\"LigandMULTIMERCENTROIDSC\"]\n",
      "> LigandMULTIMERCENTROIDSC_MIN = tapply(LigandMULTIMERCENTROIDSC_ALL,as.factor(acidsMultimer),min)\n",
      "> LigandMULTIMERCENTROIDSC_MIN = LigandMULTIMERCENTROIDSC_MIN[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> LigandMULTIMERCENTROIDSC_MIN[missing] = dataZ[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"LigandCENTROIDSC\"]\n",
      "> names(LigandMULTIMERCENTROIDSC_MIN)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> LigandMULTIMERCENTROIDSC_MIN[is.na(LigandMULTIMERCENTROIDSC_MIN)] = 0\n",
      "> \n",
      "> #RSA\n",
      "> RSA_ALL = c(data1[,\"RSA\"],data2Multimer[,\"RSA\"])\n",
      "> RSA_MIN = tapply(RSA_ALL,as.factor(c(acidsMonomer,acidsMultimer)),min,na.rm=TRUE)\n",
      "> RSA_MIN = RSA_MIN[allAcids]\n",
      "> \n",
      "> y = SecondOrderIntermodularDegree_AVERAGE+NodeEdgeBetweennessSTRIDE_sidechain_MAX-LigandMULTIMERCENTROIDSC_MIN\n",
      "> \n",
      "> out=cbind(names(y),y)\n",
      "> acidNumbers = sapply(out[,1],substring,4)\n",
      "> out = out[order(as.numeric(acidNumbers)),]\n",
      "> write.table(out,file=\"FinalSum\",sep=\"\\t\",quote=FALSE,row.names=FALSE,col.names=FALSE)\n",
      "> \n",
      "> # also write the 3 variables to a file\n",
      "> # Concatenating all three variables into a single data frame\n",
      "> result <- data.frame(\n",
      "+   Acid = names(SecondOrderIntermodularDegree_AVERAGE),\n",
      "+   SecondOrderIntermodularDegree_AVERAGE,\n",
      "+   NodeEdgeBetweennessSTRIDE_sidechain_MAX,\n",
      "+   LigandMULTIMERCENTROIDSC_MIN\n",
      "+ )\n",
      "> \n",
      "> # Writing the data frame to a file\n",
      "> write.table(result, file = \"FinalSum_Decomp\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n",
      "> \n",
      "\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 585 items\n",
      "Read 585 items\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H73C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H72C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H71C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H63C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H62C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H61C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H42C from QC5 will be treated as hydrogen\n",
      "WARNING: atom H41C from QC5 will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 1749 items\n",
      "Read 1749 items\n",
      "\n",
      "SBNA results for 3ZME succesfully downloaded\n",
      "\n",
      "Processing 6MQT with chain H...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:48:53 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 6MQT.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain H\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"6MQT.pdb\"\n",
      "    }\n",
      "    default_model = \"6MQT.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain H\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 23381 size after: 2847\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 3.00 seconds\n",
      "wall clock time: 3.02 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:48:57 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 6MQT_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"6MQT_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"6MQT_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2847 size after: 2764\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.83 seconds\n",
      "wall clock time: 1.84 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are GDP-201H\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 6MQT_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 20:49:31 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 6MQT_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"6MQT_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"6MQT_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 23381 size after: 22354\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 3.20 seconds\n",
      "wall clock time: 3.22 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are GDP-201E, GDP-201D, GDP-201G, GDP-201F, GDP-201A, GDP-201C, GDP-201B, GDP-201H\n",
      "Screening for atoms that are close.\n",
      "22025 atoms in total. Using slower low memory approach.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 6MQT_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = data2Multimer[rownames(data1Multimer),]\n",
      "> data1MultimerZ = as.data.frame(apply(data1Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1MultimerZ) = rownames(data1Multimer)\n",
      "> data2MultimerZ = as.data.frame(apply(data2Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2MultimerZ) = rownames(data2Multimer)\n",
      "> colnames(data1MultimerZ) = paste(colnames(data1MultimerZ),\"MULTIMER\",sep=\"\")\n",
      "> colnames(data2MultimerZ) = paste(colnames(data2MultimerZ),\"MULTIMERCENTROIDSC\",sep=\"\")\n",
      "> data2MultimerZ = data2MultimerZ[rownames(data1MultimerZ),]\n",
      "> \n",
      "> #Add RSA\n",
      "> data1 = cbind(data2[,\"RSA\"],data1)\n",
      "> colnames(data1)[1]=\"RSA\"\n",
      "> dataZ = cbind(data1Z,data2Z)\n",
      "> \n",
      "> #Identify max NodeEdgeBetweennessSTRIDE_sidechain\n",
      "> acidsMonomer = c()\n",
      "> for (i in 1:length(rownames(dataZ))) {\n",
      "+     node = rownames(dataZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMonomer = c(acidsMonomer,node)\n",
      "+ }\n",
      "> \n",
      "> acidsMultimer = c()\n",
      "> for (i in 1:length(rownames(data1MultimerZ))) {\n",
      "+     node = rownames(data1MultimerZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMultimer = c(acidsMultimer,node)\n",
      "+ }\n",
      "> \n",
      "> allAcids = unique(c(acidsMonomer,acidsMultimer))\n",
      "> \n",
      "> #SecondOrderIntermodularDegree is the average of the multimer only\n",
      "> SecondOrderIntermodularDegree_ALL = (data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDE_sidechainMULTIMER\"]+data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMER\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMERCENTROIDSC\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeWALKTRAPMULTIMERCENTROIDSC\"])/4\n",
      "> SecondOrderIntermodularDegree_AVERAGE = tapply(SecondOrderIntermodularDegree_ALL,as.factor(acidsMultimer),mean)\n",
      "> SecondOrderIntermodularDegree_AVERAGE = SecondOrderIntermodularDegree_AVERAGE[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> SecondOrderIntermodularDegree_AVERAGE[missing] = (data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE_sidechain\"]+data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDECENTROIDSC\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeWALKTRAPCENTROIDSC\"])/4\n",
      "> names(SecondOrderIntermodularDegree_AVERAGE)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> \n",
      "> #NodeEdgeBetweenness is the max of the monomer/multimer\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER = (dataZ[,\"NodeEdgeBetweennessSTRIDE\"]+dataZ[,\"NodeEdgeBetweennessSTRIDE_sidechain\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER = (data1MultimerZ[,\"NodeEdgeBetweennessSTRIDEMULTIMER\"]+data1MultimerZ[,\"NodeEdgeBetweennessSTRIDE_sidechainMULTIMER\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_ALL = c(NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER,NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = tapply(NodeEdgeBetweennessSTRIDE_sidechain_ALL,as.factor(c(acidsMonomer,acidsMultimer)),max,na.rm=TRUE)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = NodeEdgeBetweennessSTRIDE_sidechain_MAX[allAcids]\n",
      "> \n",
      "> #Ligand is the min of the multimer only\n",
      "> LigandMULTIMERCENTROIDSC_ALL = data2MultimerZ[,\"LigandMULTIMERCENTROIDSC\"]\n",
      "> LigandMULTIMERCENTROIDSC_MIN = tapply(LigandMULTIMERCENTROIDSC_ALL,as.factor(acidsMultimer),min)\n",
      "> LigandMULTIMERCENTROIDSC_MIN = LigandMULTIMERCENTROIDSC_MIN[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> LigandMULTIMERCENTROIDSC_MIN[missing] = dataZ[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"LigandCENTROIDSC\"]\n",
      "> names(LigandMULTIMERCENTROIDSC_MIN)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> LigandMULTIMERCENTROIDSC_MIN[is.na(LigandMULTIMERCENTROIDSC_MIN)] = 0\n",
      "> \n",
      "> #RSA\n",
      "> RSA_ALL = c(data1[,\"RSA\"],data2Multimer[,\"RSA\"])\n",
      "> RSA_MIN = tapply(RSA_ALL,as.factor(c(acidsMonomer,acidsMultimer)),min,na.rm=TRUE)\n",
      "> RSA_MIN = RSA_MIN[allAcids]\n",
      "> \n",
      "> y = SecondOrderIntermodularDegree_AVERAGE+NodeEdgeBetweennessSTRIDE_sidechain_MAX-LigandMULTIMERCENTROIDSC_MIN\n",
      "> \n",
      "> out=cbind(names(y),y)\n",
      "> acidNumbers = sapply(out[,1],substring,4)\n",
      "> out = out[order(as.numeric(acidNumbers)),]\n",
      "> write.table(out,file=\"FinalSum\",sep=\"\\t\",quote=FALSE,row.names=FALSE,col.names=FALSE)\n",
      "> \n",
      "> # also write the 3 variables to a file\n",
      "> # Concatenating all three variables into a single data frame\n",
      "> result <- data.frame(\n",
      "+   Acid = names(SecondOrderIntermodularDegree_AVERAGE),\n",
      "+   SecondOrderIntermodularDegree_AVERAGE,\n",
      "+   NodeEdgeBetweennessSTRIDE_sidechain_MAX,\n",
      "+   LigandMULTIMERCENTROIDSC_MIN\n",
      "+ )\n",
      "> \n",
      "> # Writing the data frame to a file\n",
      "> write.table(result, file = \"FinalSum_Decomp\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n",
      "> \n",
      "\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "Removing redundant N-terminal N-H hydrogen atom from input model.\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 498 items\n",
      "Read 498 items\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "Removing redundant N-terminal N-H hydrogen atom from input model.\n",
      "Removing redundant N-terminal N-H hydrogen atom from input model.\n",
      "Removing redundant N-terminal N-H hydrogen atom from input model.\n",
      "Removing redundant N-terminal N-H hydrogen atom from input model.\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GDP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GDP will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 12156 items\n",
      "Read 12156 items\n",
      "\n",
      "SBNA results for 6MQT succesfully downloaded\n",
      "\n",
      "Processing 821P with chain A...\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 21:23:56 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 821P.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain A\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"821P.pdb\"\n",
      "    }\n",
      "    default_model = \"821P.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain A\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2031 size after: 2031\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 3.41 seconds\n",
      "wall clock time: 4.72 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 21:23:59 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 821P_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"821P_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"821P_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2031 size after: 1677\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.72 seconds\n",
      "wall clock time: 1.75 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are GNP-167A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 821P_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Fri Apr 26 21:24:40 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 821P_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"821P_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"821P_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 2031 size after: 1677\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.76 seconds\n",
      "wall clock time: 1.78 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are GNP-167A\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 821P_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = data2Multimer[rownames(data1Multimer),]\n",
      "> data1MultimerZ = as.data.frame(apply(data1Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1MultimerZ) = rownames(data1Multimer)\n",
      "> data2MultimerZ = as.data.frame(apply(data2Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2MultimerZ) = rownames(data2Multimer)\n",
      "> colnames(data1MultimerZ) = paste(colnames(data1MultimerZ),\"MULTIMER\",sep=\"\")\n",
      "> colnames(data2MultimerZ) = paste(colnames(data2MultimerZ),\"MULTIMERCENTROIDSC\",sep=\"\")\n",
      "> data2MultimerZ = data2MultimerZ[rownames(data1MultimerZ),]\n",
      "> \n",
      "> #Add RSA\n",
      "> data1 = cbind(data2[,\"RSA\"],data1)\n",
      "> colnames(data1)[1]=\"RSA\"\n",
      "> dataZ = cbind(data1Z,data2Z)\n",
      "> \n",
      "> #Identify max NodeEdgeBetweennessSTRIDE_sidechain\n",
      "> acidsMonomer = c()\n",
      "> for (i in 1:length(rownames(dataZ))) {\n",
      "+     node = rownames(dataZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMonomer = c(acidsMonomer,node)\n",
      "+ }\n",
      "> \n",
      "> acidsMultimer = c()\n",
      "> for (i in 1:length(rownames(data1MultimerZ))) {\n",
      "+     node = rownames(data1MultimerZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMultimer = c(acidsMultimer,node)\n",
      "+ }\n",
      "> \n",
      "> allAcids = unique(c(acidsMonomer,acidsMultimer))\n",
      "> \n",
      "> #SecondOrderIntermodularDegree is the average of the multimer only\n",
      "> SecondOrderIntermodularDegree_ALL = (data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDE_sidechainMULTIMER\"]+data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMER\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMERCENTROIDSC\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeWALKTRAPMULTIMERCENTROIDSC\"])/4\n",
      "> SecondOrderIntermodularDegree_AVERAGE = tapply(SecondOrderIntermodularDegree_ALL,as.factor(acidsMultimer),mean)\n",
      "> SecondOrderIntermodularDegree_AVERAGE = SecondOrderIntermodularDegree_AVERAGE[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> SecondOrderIntermodularDegree_AVERAGE[missing] = (data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE_sidechain\"]+data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDECENTROIDSC\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeWALKTRAPCENTROIDSC\"])/4\n",
      "> names(SecondOrderIntermodularDegree_AVERAGE)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> \n",
      "> #NodeEdgeBetweenness is the max of the monomer/multimer\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER = (dataZ[,\"NodeEdgeBetweennessSTRIDE\"]+dataZ[,\"NodeEdgeBetweennessSTRIDE_sidechain\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER = (data1MultimerZ[,\"NodeEdgeBetweennessSTRIDEMULTIMER\"]+data1MultimerZ[,\"NodeEdgeBetweennessSTRIDE_sidechainMULTIMER\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_ALL = c(NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER,NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = tapply(NodeEdgeBetweennessSTRIDE_sidechain_ALL,as.factor(c(acidsMonomer,acidsMultimer)),max,na.rm=TRUE)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = NodeEdgeBetweennessSTRIDE_sidechain_MAX[allAcids]\n",
      "> \n",
      "> #Ligand is the min of the multimer only\n",
      "> LigandMULTIMERCENTROIDSC_ALL = data2MultimerZ[,\"LigandMULTIMERCENTROIDSC\"]\n",
      "> LigandMULTIMERCENTROIDSC_MIN = tapply(LigandMULTIMERCENTROIDSC_ALL,as.factor(acidsMultimer),min)\n",
      "> LigandMULTIMERCENTROIDSC_MIN = LigandMULTIMERCENTROIDSC_MIN[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> LigandMULTIMERCENTROIDSC_MIN[missing] = dataZ[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"LigandCENTROIDSC\"]\n",
      "> names(LigandMULTIMERCENTROIDSC_MIN)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> LigandMULTIMERCENTROIDSC_MIN[is.na(LigandMULTIMERCENTROIDSC_MIN)] = 0\n",
      "> \n",
      "> #RSA\n",
      "> RSA_ALL = c(data1[,\"RSA\"],data2Multimer[,\"RSA\"])\n",
      "> RSA_MIN = tapply(RSA_ALL,as.factor(c(acidsMonomer,acidsMultimer)),min,na.rm=TRUE)\n",
      "> RSA_MIN = RSA_MIN[allAcids]\n",
      "> \n",
      "> y = SecondOrderIntermodularDegree_AVERAGE+NodeEdgeBetweennessSTRIDE_sidechain_MAX-LigandMULTIMERCENTROIDSC_MIN\n",
      "> \n",
      "> out=cbind(names(y),y)\n",
      "> acidNumbers = sapply(out[,1],substring,4)\n",
      "> out = out[order(as.numeric(acidNumbers)),]\n",
      "> write.table(out,file=\"FinalSum\",sep=\"\\t\",quote=FALSE,row.names=FALSE,col.names=FALSE)\n",
      "> \n",
      "> # also write the 3 variables to a file\n",
      "> # Concatenating all three variables into a single data frame\n",
      "> result <- data.frame(\n",
      "+   Acid = names(SecondOrderIntermodularDegree_AVERAGE),\n",
      "+   SecondOrderIntermodularDegree_AVERAGE,\n",
      "+   NodeEdgeBetweennessSTRIDE_sidechain_MAX,\n",
      "+   LigandMULTIMERCENTROIDSC_MIN\n",
      "+ )\n",
      "> \n",
      "> # Writing the data frame to a file\n",
      "> write.table(result, file = \"FinalSum_Decomp\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n",
      "> \n",
      "\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 498 items\n",
      "Read 498 items\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HNB3 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN22 from GNP will be treated as hydrogen\n",
      "WARNING: atom HN21 from GNP will be treated as hydrogen\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 498 items\n",
      "Read 498 items\n",
      "\n",
      "SBNA results for 821P succesfully downloaded\n"
     ]
    }
   ],
   "source": [
    "host = \"m3-dtn.massive.org.au\"\n",
    "username = \"yliy0004\"\n",
    "with open(\"pw.txt\", \"r\") as f:\n",
    "    password = f.read()\n",
    "base_path = 'ym65_scratch/yliy0004/NetworkAnalysis'\n",
    "\n",
    "client = paramiko.client.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(host, username=username, password=password)\n",
    "\n",
    "# check if R module is loaded (uses .bashrc - not the best solution because STRUDEL cannot be used, make sure to correct this if using STRUDEL)\n",
    "stdin,stdout,stderr=client.exec_command('R --version') \n",
    "print(stdout.read().decode())\n",
    "print(stderr.read().decode())\n",
    "\n",
    "sftp_client=client.open_sftp()\n",
    "\n",
    "# ==================== SBNA ====================\n",
    "# ## multiple structures by gene\n",
    "for gene_id in top_structures:\n",
    "    for pdb_id in top_structures[gene_id]:\n",
    "\n",
    "# ## or certain genes\n",
    "# # for gene in ['HRAS']:\n",
    "#     # tmp = ast.literal_eval(cgc_data.loc[cgc_data['Gene Symbol'] == gene, 'PDB Structures'].values[0])\n",
    "#     # for pdb_id in tmp:\n",
    "#     # for pdb_id in top_structures[gene]:\n",
    "        try:\n",
    "            resolution = get_resolution(pdb_id)\n",
    "            if resolution and float(resolution) <= 3.0:\n",
    "                calculate_sbna_and_download(client, sftp_client, pdb_id, base_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {pdb_id} with error:\")\n",
    "            print(traceback.print_exc())\n",
    "            continue\n",
    "\n",
    "## or simply a few pdbs\n",
    "# for pdb_id in [\"1D5R\", \"1JM7\", \"1T29\", \"4FMQ\", \"4NIF\"]:\n",
    "#     try:\n",
    "#         calculate_sbna_and_download(client, sftp_client, pdb_id, base_path)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to process {pdb_id} with error:\")\n",
    "#         print(traceback.print_exc())\n",
    "#         continue\n",
    "\n",
    "## or one pdb\n",
    "# calculate_sbna_and_download(client, sftp_client, \"1C26\", base_path, chains=['A'])\n",
    "\n",
    "# close the connection\n",
    "client.close()\n",
    "sftp_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "sftp_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if you want to add more results to final_data\n",
    "(after having done more sbna iterations)\n",
    "* reads the pdb structures related to each gene in `cgc_data`\n",
    "* read the current `final_data.csv`\n",
    "* appends the new sbna_results to `final_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>...</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PDB Structures</th>\n",
       "      <th>n_structures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>29974.0</td>\n",
       "      <td>10:50799421-50885675</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...</td>\n",
       "      <td>['2CPD']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI1</td>\n",
       "      <td>abl-interactor 1</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>10:26746593-26860935</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>TSG, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>KMT2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...</td>\n",
       "      <td>['7LXE']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1</td>\n",
       "      <td>v-abl Abelson murine leukemia viral oncogene h...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9:130713946-130885683</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9q34.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CML, ALL, T-ALL</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T, Mis</td>\n",
       "      <td>BCR, ETV6, NUP214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...</td>\n",
       "      <td>['1AB2', '1AWO', '1BBZ', '1JU5', '1OPL', '1ZZP...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol                                               Name  \\\n",
       "0        A1CF                     APOBEC1 complementation factor   \n",
       "1        ABI1                                   abl-interactor 1   \n",
       "2        ABL1  v-abl Abelson murine leukemia viral oncogene h...   \n",
       "\n",
       "   Entrez GeneId        Genome Location  Tier Hallmark  Chr Band Somatic  \\\n",
       "0        29974.0   10:50799421-50885675     2      NaN  10q11.23     yes   \n",
       "1        10006.0   10:26746593-26860935     1      Yes   10p12.1     yes   \n",
       "2           25.0  9:130713946-130885683     1      Yes   9q34.12     yes   \n",
       "\n",
       "  Germline Tumour Types(Somatic)  ... Tissue Type Molecular Genetics  \\\n",
       "0      NaN              melanoma  ...           E                NaN   \n",
       "1      NaN                   AML  ...           L                Dom   \n",
       "2      NaN       CML, ALL, T-ALL  ...           L                Dom   \n",
       "\n",
       "     Role in Cancer Mutation Types Translocation Partner Other Germline Mut  \\\n",
       "0          oncogene            Mis                   NaN                NaN   \n",
       "1       TSG, fusion              T                 KMT2A                NaN   \n",
       "2  oncogene, fusion         T, Mis     BCR, ETV6, NUP214                NaN   \n",
       "\n",
       "  Other Syndrome                                           Synonyms  \\\n",
       "0            NaN  ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...   \n",
       "1            NaN  ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...   \n",
       "2            NaN  ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...   \n",
       "\n",
       "                                      PDB Structures n_structures  \n",
       "0                                           ['2CPD']            1  \n",
       "1                                           ['7LXE']            1  \n",
       "2  ['1AB2', '1AWO', '1BBZ', '1JU5', '1OPL', '1ZZP...           81  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgc_data = pd.read_csv('Census_all_with_pdb.csv')\n",
    "cgc_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_genes = [\"KRAS\", \"EGFR\", \"TP53\", \"HRAS\"]\n",
    "# tmp_genes = [\"KRAS\", \"TP53\", \"HRAS\"]\n",
    "# tmp_genes = [\"EGFR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = list(final_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33470\n"
     ]
    }
   ],
   "source": [
    "print(len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple residues for the same number detected for 8H1T_L\n",
      "Error in handling multiple residues for the same number, using all values.\n",
      "Multiple residues for the same number detected for 1ICF_I\n",
      "Error in handling multiple residues for the same number, using all values.\n",
      "Multiple residues for the same number detected for 4AP2_B\n",
      "Multiple residues for the same number detected for 2WUH_A\n",
      "Multiple residues for the same number detected for 6V5B_A\n",
      "Multiple residues for the same number detected for 4UIP_A\n",
      "Multiple residues for the same number detected for 7MN5_B\n",
      "Multiple residues for the same number detected for 5H8F_A\n",
      "Multiple residues for the same number detected for 5E95_A\n",
      "Multiple residues for the same number detected for 5XCO_A\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence has unexpected type NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m decomp \u001b[38;5;241m=\u001b[39m read_finalsum_decomp(pdb_id, chain)\n\u001b[0;32m     34\u001b[0m final_sum \u001b[38;5;241m=\u001b[39m final_sum\u001b[38;5;241m.\u001b[39mmerge(decomp, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres_y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcid\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m final_sum \u001b[38;5;241m=\u001b[39m align_finalsum_with_uniprot(final_sum, pdb_id, chain)                \n\u001b[0;32m     36\u001b[0m final_sum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidue_match\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_sum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniprot_res\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m final_sum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m     38\u001b[0m final_sum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdb_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pdb_id\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\OneDrive\\Documents\\MDS\\FIT5210\\code\\NetworkAnalysis\\data_prep\\..\\utils.py:479\u001b[0m, in \u001b[0;36malign_finalsum_with_uniprot\u001b[1;34m(final_sum, pdb_id, chain)\u001b[0m\n\u001b[0;32m    477\u001b[0m aligner \u001b[38;5;241m=\u001b[39m Align\u001b[38;5;241m.\u001b[39mPairwiseAligner()\n\u001b[0;32m    478\u001b[0m aligner\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 479\u001b[0m alignments \u001b[38;5;241m=\u001b[39m aligner\u001b[38;5;241m.\u001b[39malign(sbna_seq, target_sequence)\n\u001b[0;32m    481\u001b[0m sbna_aligned, pdb_aligned  \u001b[38;5;241m=\u001b[39m alignments[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], alignments[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# print(\"sbna: \", sbna_aligned)\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# print(\"pdb : \", pdb_aligned)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\envs\\sbna\\Lib\\site-packages\\Bio\\Align\\__init__.py:3926\u001b[0m, in \u001b[0;36mPairwiseAligner.align\u001b[1;34m(self, seqA, seqB, strand)\u001b[0m\n\u001b[0;32m   3924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seqB, (Seq, MutableSeq, SeqRecord)):\n\u001b[0;32m   3925\u001b[0m     sB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(sB)\n\u001b[1;32m-> 3926\u001b[0m score, paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39malign(sA, sB, strand)\n\u001b[0;32m   3927\u001b[0m alignments \u001b[38;5;241m=\u001b[39m PairwiseAlignments(seqA, seqB, score, paths)\n\u001b[0;32m   3928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alignments\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence has unexpected type NoneType"
     ]
    }
   ],
   "source": [
    "filtered_data = cgc_data[cgc_data['PDB Structures'].notna()] # pdb_structures not nan\n",
    "# filtered_data = filtered_data[filtered_data['Gene Symbol'].isin(tmp_genes)]\n",
    "\n",
    "count = filtered_data.shape[0]\n",
    "for i, row in filtered_data.iterrows():\n",
    "    print(f\"Processing {i+1} of {count}\", end='\\r')\n",
    "    gene_symbol = row['Gene Symbol']\n",
    "    pdb_structures = row['PDB Structures']\n",
    "    for pdb_id in ast.literal_eval(pdb_structures):\n",
    "        if not os.path.exists(f'../pdb_files/{pdb_id}.pdb'):\n",
    "            continue\n",
    "        else:\n",
    "            data = get_dbref_data(pdb_id)\n",
    "            resolution = get_resolution(pdb_id)\n",
    "            for i in data:\n",
    "                chain = i['chain']\n",
    "\n",
    "                # check if finalsum exists or if data is already in final_data\n",
    "                if not os.path.exists(f'../sbna_results/{pdb_id}/{chain}/{pdb_id}_monomer/FinalSum') or\\\n",
    "                      not os.path.exists(f'../sbna_results/{pdb_id}/{chain}/{pdb_id}_monomer/FinalSum_Decomp') or \\\n",
    "                    len(final_data) and len(final_data[(final_data['pdb_id']==pdb_id) & (final_data['chain']==chain)]):\n",
    "                    continue    \n",
    "                      \n",
    "                uniprot_id = i['uniprot']\n",
    "                assoc_gene = get_gene_name(uniprot_id)\n",
    "                if assoc_gene != gene_symbol:\n",
    "                    # sometimes protein chain extends multiple genes, skip if not the same\n",
    "                    # in future can link if gene is in cgc_data/tcga_data\n",
    "                    continue\n",
    "\n",
    "                # read finalSum file and add to table\n",
    "                final_sum = read_finalsum(pdb_id, chain)\n",
    "                decomp = read_finalsum_decomp(pdb_id, chain)\n",
    "                final_sum = final_sum.merge(decomp, on=['res_code', 'num']).drop(['res_x', 'res_y', 'Acid'], axis=1)\n",
    "                final_sum = align_finalsum_with_uniprot(final_sum, pdb_id, chain)                \n",
    "                final_sum['residue_match'] = final_sum['uniprot_res'] == final_sum['res_code'] \n",
    "\n",
    "                final_sum['pdb_id'] = pdb_id\n",
    "                final_sum['chain'] = chain\n",
    "                final_sum['uniprot_id'] = uniprot_id\n",
    "                final_sum['gene'] = assoc_gene\n",
    "\n",
    "                final_data = pd.concat([final_data, final_sum])\n",
    "                \n",
    "#                final_data.append([gene_symbol, pdb_id, chain, uniprot_id, assoc_gene, resolution, num, row['res_code'], \n",
    "#                                row['network_score'], row['SecondOrderIntermodularDegree_AVERAGE'], row['NodeEdgeBetweennessSTRIDE_sidechain_MAX'],\n",
    "#                                row['LigandMULTIMERCENTROIDSC_MIN'], outside_range, residue_match])\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>assoc_gene</th>\n",
       "      <th>resolution</th>\n",
       "      <th>num</th>\n",
       "      <th>res_code</th>\n",
       "      <th>uniprot_res</th>\n",
       "      <th>network_score</th>\n",
       "      <th>SecondOrderIntermodularDegree_AVERAGE</th>\n",
       "      <th>NodeEdgeBetweennessSTRIDE_sidechain_MAX</th>\n",
       "      <th>LigandMULTIMERCENTROIDSC_MIN</th>\n",
       "      <th>outside_range</th>\n",
       "      <th>residue_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>701</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-3.791355</td>\n",
       "      <td>-1.246142</td>\n",
       "      <td>-0.541346</td>\n",
       "      <td>2.003868</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>702</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>-2.634055</td>\n",
       "      <td>-1.088502</td>\n",
       "      <td>-0.455538</td>\n",
       "      <td>1.090015</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>703</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.231055</td>\n",
       "      <td>-0.643414</td>\n",
       "      <td>-0.105177</td>\n",
       "      <td>0.482465</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>704</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>0.452193</td>\n",
       "      <td>0.377611</td>\n",
       "      <td>0.205135</td>\n",
       "      <td>0.130553</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>705</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>-1.086163</td>\n",
       "      <td>0.107137</td>\n",
       "      <td>-0.523559</td>\n",
       "      <td>0.669741</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_symbol pdb_id chain uniprot_id assoc_gene resolution  num res_code  \\\n",
       "0        EGFR   3POZ     A     P00533       EGFR        1.5  701        Q   \n",
       "1        EGFR   3POZ     A     P00533       EGFR        1.5  702        A   \n",
       "2        EGFR   3POZ     A     P00533       EGFR        1.5  703        L   \n",
       "3        EGFR   3POZ     A     P00533       EGFR        1.5  704        L   \n",
       "4        EGFR   3POZ     A     P00533       EGFR        1.5  705        R   \n",
       "\n",
       "  uniprot_res  network_score SecondOrderIntermodularDegree_AVERAGE  \\\n",
       "0           Q      -3.791355                             -1.246142   \n",
       "1           A      -2.634055                             -1.088502   \n",
       "2           L      -1.231055                             -0.643414   \n",
       "3           L       0.452193                              0.377611   \n",
       "4           R      -1.086163                              0.107137   \n",
       "\n",
       "  NodeEdgeBetweennessSTRIDE_sidechain_MAX LigandMULTIMERCENTROIDSC_MIN  \\\n",
       "0                               -0.541346                     2.003868   \n",
       "1                               -0.455538                     1.090015   \n",
       "2                               -0.105177                     0.482465   \n",
       "3                                0.205135                     0.130553   \n",
       "4                               -0.523559                     0.669741   \n",
       "\n",
       "   outside_range  residue_match  \n",
       "0          False           True  \n",
       "1          False           True  \n",
       "2          False           True  \n",
       "3          False           True  \n",
       "4          False           True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.DataFrame(final_data, columns=['gene_symbol', 'pdb_id', 'chain', 'uniprot_id', 'assoc_gene', 'resolution', 'num', 'res_code', 'uniprot_res', \n",
    "                                  'network_score', 'SecondOrderIntermodularDegree_AVERAGE', 'NodeEdgeBetweennessSTRIDE_sidechain_MAX',\n",
    "                                  'LigandMULTIMERCENTROIDSC_MIN', 'outside_range', 'residue_match'])\n",
    "final_data = final_data.sort_values([\"assoc_gene\", \"pdb_id\", \"chain\", \"uniprot_id\"], ascending=True)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34998\n"
     ]
    }
   ],
   "source": [
    "print(len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('final_data_aligned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a dictionary to save uniprots, and sequences so don't have to query every time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = final_data[(final_data['pdb_id'].isin(['3POZ', \"8E7A\"])) & (final_data['chain'] == \"A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liyoa\\OneDrive\\Documents\\MDS\\FIT5210\\code\\NetworkAnalysis\\data_prep\\..\\utils.py:415: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_sum['pdb_chain'] = final_sum['pdb_id'] + \"_\" + final_sum['chain']\n",
      "c:\\Users\\liyoa\\OneDrive\\Documents\\MDS\\FIT5210\\code\\NetworkAnalysis\\data_prep\\..\\utils.py:521: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_sum['uniprot_num'] = [item for sublist in uniprot_nums for item in sublist]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>assoc_gene</th>\n",
       "      <th>resolution</th>\n",
       "      <th>num</th>\n",
       "      <th>res_code</th>\n",
       "      <th>uniprot_res</th>\n",
       "      <th>network_score</th>\n",
       "      <th>SecondOrderIntermodularDegree_AVERAGE</th>\n",
       "      <th>NodeEdgeBetweennessSTRIDE_sidechain_MAX</th>\n",
       "      <th>LigandMULTIMERCENTROIDSC_MIN</th>\n",
       "      <th>outside_range</th>\n",
       "      <th>residue_match</th>\n",
       "      <th>pdb_chain</th>\n",
       "      <th>uniprot_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>701</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-3.791355</td>\n",
       "      <td>-1.246142</td>\n",
       "      <td>-0.541346</td>\n",
       "      <td>2.003868</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3POZ_A</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>702</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>-2.634055</td>\n",
       "      <td>-1.088502</td>\n",
       "      <td>-0.455538</td>\n",
       "      <td>1.090015</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3POZ_A</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>703</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.231055</td>\n",
       "      <td>-0.643414</td>\n",
       "      <td>-0.105177</td>\n",
       "      <td>0.482465</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3POZ_A</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>704</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>0.452193</td>\n",
       "      <td>0.377611</td>\n",
       "      <td>0.205135</td>\n",
       "      <td>0.130553</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3POZ_A</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>3POZ</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.5</td>\n",
       "      <td>705</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>-1.086163</td>\n",
       "      <td>0.107137</td>\n",
       "      <td>-0.523559</td>\n",
       "      <td>0.669741</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3POZ_A</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33465</th>\n",
       "      <td>TP53</td>\n",
       "      <td>8E7A</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.3</td>\n",
       "      <td>287</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-1.837237</td>\n",
       "      <td>-1.145720</td>\n",
       "      <td>-0.691517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8E7A_A</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33466</th>\n",
       "      <td>TP53</td>\n",
       "      <td>8E7A</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.3</td>\n",
       "      <td>288</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>-1.837237</td>\n",
       "      <td>-1.145720</td>\n",
       "      <td>-0.691517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8E7A_A</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33467</th>\n",
       "      <td>TP53</td>\n",
       "      <td>8E7A</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.3</td>\n",
       "      <td>289</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.196778</td>\n",
       "      <td>-0.636678</td>\n",
       "      <td>-0.560100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8E7A_A</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33468</th>\n",
       "      <td>TP53</td>\n",
       "      <td>8E7A</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.3</td>\n",
       "      <td>290</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>-1.624046</td>\n",
       "      <td>-0.933228</td>\n",
       "      <td>-0.690818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8E7A_A</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33469</th>\n",
       "      <td>TP53</td>\n",
       "      <td>8E7A</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.3</td>\n",
       "      <td>291</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>-1.816740</td>\n",
       "      <td>-1.125223</td>\n",
       "      <td>-0.691517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8E7A_A</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene_symbol pdb_id chain uniprot_id assoc_gene  resolution  num  \\\n",
       "0            EGFR   3POZ     A     P00533       EGFR         1.5  701   \n",
       "1            EGFR   3POZ     A     P00533       EGFR         1.5  702   \n",
       "2            EGFR   3POZ     A     P00533       EGFR         1.5  703   \n",
       "3            EGFR   3POZ     A     P00533       EGFR         1.5  704   \n",
       "4            EGFR   3POZ     A     P00533       EGFR         1.5  705   \n",
       "...           ...    ...   ...        ...        ...         ...  ...   \n",
       "33465        TP53   8E7A     A     P04637       TP53         1.3  287   \n",
       "33466        TP53   8E7A     A     P04637       TP53         1.3  288   \n",
       "33467        TP53   8E7A     A     P04637       TP53         1.3  289   \n",
       "33468        TP53   8E7A     A     P04637       TP53         1.3  290   \n",
       "33469        TP53   8E7A     A     P04637       TP53         1.3  291   \n",
       "\n",
       "      res_code uniprot_res  network_score  \\\n",
       "0            Q           Q      -3.791355   \n",
       "1            A           A      -2.634055   \n",
       "2            L           L      -1.231055   \n",
       "3            L           L       0.452193   \n",
       "4            R           R      -1.086163   \n",
       "...        ...         ...            ...   \n",
       "33465        E           E      -1.837237   \n",
       "33466        N           N      -1.837237   \n",
       "33467        L           L      -1.196778   \n",
       "33468        R           R      -1.624046   \n",
       "33469        K           K      -1.816740   \n",
       "\n",
       "       SecondOrderIntermodularDegree_AVERAGE  \\\n",
       "0                                  -1.246142   \n",
       "1                                  -1.088502   \n",
       "2                                  -0.643414   \n",
       "3                                   0.377611   \n",
       "4                                   0.107137   \n",
       "...                                      ...   \n",
       "33465                              -1.145720   \n",
       "33466                              -1.145720   \n",
       "33467                              -0.636678   \n",
       "33468                              -0.933228   \n",
       "33469                              -1.125223   \n",
       "\n",
       "       NodeEdgeBetweennessSTRIDE_sidechain_MAX  LigandMULTIMERCENTROIDSC_MIN  \\\n",
       "0                                    -0.541346                      2.003868   \n",
       "1                                    -0.455538                      1.090015   \n",
       "2                                    -0.105177                      0.482465   \n",
       "3                                     0.205135                      0.130553   \n",
       "4                                    -0.523559                      0.669741   \n",
       "...                                        ...                           ...   \n",
       "33465                                -0.691517                      0.000000   \n",
       "33466                                -0.691517                      0.000000   \n",
       "33467                                -0.560100                      0.000000   \n",
       "33468                                -0.690818                      0.000000   \n",
       "33469                                -0.691517                      0.000000   \n",
       "\n",
       "       outside_range  residue_match pdb_chain  uniprot_num  \n",
       "0              False           True    3POZ_A          701  \n",
       "1              False           True    3POZ_A          702  \n",
       "2              False           True    3POZ_A          703  \n",
       "3              False           True    3POZ_A          704  \n",
       "4              False           True    3POZ_A          705  \n",
       "...              ...            ...       ...          ...  \n",
       "33465          False           True    8E7A_A          287  \n",
       "33466          False           True    8E7A_A          288  \n",
       "33467          False           True    8E7A_A          289  \n",
       "33468          False           True    8E7A_A          290  \n",
       "33469          False           True    8E7A_A          291  \n",
       "\n",
       "[490 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count = len(new)\n",
    "\n",
    "align_finalsum_with_uniprot(tmp)\n",
    "\n",
    "# for _, row in final_data.iterrows():\n",
    "#     pdb_id, chain = row['pdb_id'], row['chain']\n",
    "#     if not os.path.exists(f'../sbna_results/{pdb_id}/{chain}/{pdb_id}_monomer/FinalSum'):\n",
    "#         continue\n",
    "#     final_sum = final_data[(final_data['pdb_id'] == pdb_id) & (final_data['chain'] == chain)]\n",
    "#     new = pd.concat([new, align_finalsum_with_uniprot(final_sum, pdb_id, chain)])\n",
    "#     count += 1\n",
    "#     print(f\"Processed {count} of {len(final_data)}\", end='\\r')\n",
    "#     break\n",
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_csv('final_data_aligned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
