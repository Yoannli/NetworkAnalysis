{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import paramiko # for ssh\n",
    "import traceback #  for error handling\n",
    "import ast\n",
    "import requests\n",
    "import re\n",
    "from Bio.SeqUtils import seq1\n",
    "from six.moves.urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>Tumour Types(Germline)</th>\n",
       "      <th>Cancer Syndrome</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>29974.0</td>\n",
       "      <td>10:50799421-50885675</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI1</td>\n",
       "      <td>abl-interactor 1</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>10:26746593-26860935</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>TSG, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>KMT2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1</td>\n",
       "      <td>v-abl Abelson murine leukemia viral oncogene h...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9:130713946-130885683</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9q34.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CML, ALL, T-ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T, Mis</td>\n",
       "      <td>BCR, ETV6, NUP214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABL2</td>\n",
       "      <td>c-abl oncogene 2, non-receptor tyrosine kinase</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1:179099327-179229601</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1q25.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>ETV6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABLL,ARG,CCDS30947.1,ENSG00000143322.19,NM_007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACKR3</td>\n",
       "      <td>atypical chemokine receptor 3</td>\n",
       "      <td>57007.0</td>\n",
       "      <td>2:236569641-236582358</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2q37.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lipoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>HMGA2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCDS2516.1,CMKOR1,CXCR7,ENSG00000144476.5,GPR1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol                                               Name  \\\n",
       "0        A1CF                     APOBEC1 complementation factor   \n",
       "1        ABI1                                   abl-interactor 1   \n",
       "2        ABL1  v-abl Abelson murine leukemia viral oncogene h...   \n",
       "3        ABL2     c-abl oncogene 2, non-receptor tyrosine kinase   \n",
       "4       ACKR3                      atypical chemokine receptor 3   \n",
       "\n",
       "   Entrez GeneId        Genome Location  Tier Hallmark  Chr Band Somatic  \\\n",
       "0        29974.0   10:50799421-50885675     2      NaN  10q11.23     yes   \n",
       "1        10006.0   10:26746593-26860935     1      Yes   10p12.1     yes   \n",
       "2           25.0  9:130713946-130885683     1      Yes   9q34.12     yes   \n",
       "3           27.0  1:179099327-179229601     1      NaN    1q25.2     yes   \n",
       "4        57007.0  2:236569641-236582358     1      Yes    2q37.3     yes   \n",
       "\n",
       "  Germline Tumour Types(Somatic) Tumour Types(Germline) Cancer Syndrome  \\\n",
       "0      NaN              melanoma                    NaN             NaN   \n",
       "1      NaN                   AML                    NaN             NaN   \n",
       "2      NaN       CML, ALL, T-ALL                    NaN             NaN   \n",
       "3      NaN                   AML                    NaN             NaN   \n",
       "4      NaN                lipoma                    NaN             NaN   \n",
       "\n",
       "  Tissue Type Molecular Genetics    Role in Cancer Mutation Types  \\\n",
       "0           E                NaN          oncogene            Mis   \n",
       "1           L                Dom       TSG, fusion              T   \n",
       "2           L                Dom  oncogene, fusion         T, Mis   \n",
       "3           L                Dom  oncogene, fusion              T   \n",
       "4           M                Dom  oncogene, fusion              T   \n",
       "\n",
       "  Translocation Partner Other Germline Mut Other Syndrome  \\\n",
       "0                   NaN                NaN            NaN   \n",
       "1                 KMT2A                NaN            NaN   \n",
       "2     BCR, ETV6, NUP214                NaN            NaN   \n",
       "3                  ETV6                NaN            NaN   \n",
       "4                 HMGA2                NaN            NaN   \n",
       "\n",
       "                                            Synonyms  \n",
       "0  ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...  \n",
       "1  ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...  \n",
       "2  ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...  \n",
       "3  ABLL,ARG,CCDS30947.1,ENSG00000143322.19,NM_007...  \n",
       "4  CCDS2516.1,CMKOR1,CXCR7,ENSG00000144476.5,GPR1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgc_data = pd.read_csv('Census_allTue Apr  9 04_58_38 2024.csv')\n",
    "cgc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"https://gtexportal.org/api/v2/expression/geneExpression/gene-expression?gencodeId=ENSG00000065613.9,ENSG00000203782.5\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_pdb_ids(gene_symbol, entrez_gene_id, synonyms):\n",
    "    api_url = f\"http://mygene.info/v3/query?q={gene_symbol}&species=human&fields=entrezgene,ensembl,pdb\"\n",
    "    response = requests.get(api_url)\n",
    "    # check response\n",
    "    if response.status_code != 200:\n",
    "        return response.status_code, None\n",
    "    response = response.json()\n",
    "    for hit in response['hits']:\n",
    "        if ( str(hit['_id']) == str(int(entrez_gene_id)) ) or ( synonyms and 'ensembl' in hit and hit['ensembl']['gene'] in synonyms ): # (sometimes entrez_gene_id might not match but ensembl gene does\n",
    "            if 'pdb' in hit:\n",
    "                return 200, hit['pdb'] # status_code, pdb_ids\n",
    "            else: # no structures found \n",
    "                continue\n",
    "    return 200, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get pdb ids for ACSL3 with status code 200\n",
      "Failed to get pdb ids for ACSL6 with status code 200\n",
      "Failed to get pdb ids for AFF3 with status code 200\n",
      "Failed to get pdb ids for AKAP9 with status code 200\n",
      "Failed to get pdb ids for ARHGEF10 with status code 200\n",
      "Failed to get pdb ids for ARHGEF10L with status code 200\n",
      "Failed to get pdb ids for ASPM with status code 200\n",
      "Processing 38 of 743 (ASPSCR1)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     status, pdb \u001b[38;5;241m=\u001b[39m \u001b[43mget_pdb_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgene_symbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrez_gene_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynonyms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get pdb ids for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgene_symbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mget_pdb_ids\u001b[1;34m(gene_symbol, entrez_gene_id, synonyms)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pdb_ids\u001b[39m(gene_symbol, entrez_gene_id, synonyms):\n\u001b[0;32m      4\u001b[0m     api_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://mygene.info/v3/query?q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgene_symbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&species=human&fields=entrezgene,ensembl,pdb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# check response\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\liyoa\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# add pdb structures to cgc_data\n",
    "pdb_structures = []\n",
    "count = 1\n",
    "for _, row in cgc_data.iterrows():\n",
    "    # print curent count, replace previous line    \n",
    "    gene_symbol = row['Gene Symbol']\n",
    "    entrez_gene_id = row['Entrez GeneId']\n",
    "    synonyms = row['Synonyms']\n",
    "    print(f\"Processing {count} of {len(cgc_data)} ({gene_symbol})\", end='\\r')\n",
    "    count += 1\n",
    "\n",
    "    try:\n",
    "        status, pdb = get_pdb_ids(gene_symbol, entrez_gene_id, synonyms)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get pdb ids for {gene_symbol} with error {e}\")\n",
    "        pdb_structures.append(None)\n",
    "        continue\n",
    "\n",
    "    if not pdb:\n",
    "        print(f\"Failed to get pdb ids for {gene_symbol} with status code {status}\")\n",
    "        pdb_structures.append(None)\n",
    "    else:\n",
    "        pdb_structures.append(list(pdb))\n",
    "\n",
    "cgc_data['PDB Structures'] = pdb_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>...</th>\n",
       "      <th>Cancer Syndrome</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PDB Structures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>29974.0</td>\n",
       "      <td>10:50799421-50885675</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...</td>\n",
       "      <td>2CPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI1</td>\n",
       "      <td>abl-interactor 1</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>10:26746593-26860935</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>TSG, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>KMT2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...</td>\n",
       "      <td>7LXE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1</td>\n",
       "      <td>v-abl Abelson murine leukemia viral oncogene h...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9:130713946-130885683</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9q34.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CML, ALL, T-ALL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T, Mis</td>\n",
       "      <td>BCR, ETV6, NUP214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...</td>\n",
       "      <td>[1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol                                               Name  \\\n",
       "0        A1CF                     APOBEC1 complementation factor   \n",
       "1        ABI1                                   abl-interactor 1   \n",
       "2        ABL1  v-abl Abelson murine leukemia viral oncogene h...   \n",
       "\n",
       "   Entrez GeneId        Genome Location  Tier Hallmark  Chr Band Somatic  \\\n",
       "0        29974.0   10:50799421-50885675     2      NaN  10q11.23     yes   \n",
       "1        10006.0   10:26746593-26860935     1      Yes   10p12.1     yes   \n",
       "2           25.0  9:130713946-130885683     1      Yes   9q34.12     yes   \n",
       "\n",
       "  Germline Tumour Types(Somatic)  ... Cancer Syndrome Tissue Type  \\\n",
       "0      NaN              melanoma  ...             NaN           E   \n",
       "1      NaN                   AML  ...             NaN           L   \n",
       "2      NaN       CML, ALL, T-ALL  ...             NaN           L   \n",
       "\n",
       "  Molecular Genetics    Role in Cancer Mutation Types Translocation Partner  \\\n",
       "0                NaN          oncogene            Mis                   NaN   \n",
       "1                Dom       TSG, fusion              T                 KMT2A   \n",
       "2                Dom  oncogene, fusion         T, Mis     BCR, ETV6, NUP214   \n",
       "\n",
       "  Other Germline Mut Other Syndrome  \\\n",
       "0                NaN            NaN   \n",
       "1                NaN            NaN   \n",
       "2                NaN            NaN   \n",
       "\n",
       "                                            Synonyms  \\\n",
       "0  ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...   \n",
       "1  ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...   \n",
       "2  ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...   \n",
       "\n",
       "                                      PDB Structures  \n",
       "0                                               2CPD  \n",
       "1                                               7LXE  \n",
       "2  [1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgc_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwl_pdb_file(pdb_id):\n",
    "    base_url = 'https://files.rcsb.org/download/'\n",
    "    pdb_url = base_url + pdb_id + '.pdb'\n",
    "    response = requests.get(pdb_url)\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the PDB file to pdb_files folder\n",
    "        with open(f'pdb_files/{pdb_id}.pdb', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print(f\"Failed to download PDB file {pdb_id}. Status code:\", response.status_code)\n",
    "    return\n",
    "\n",
    "def get_resolution(pdb_id):\n",
    "    try:\n",
    "        with open(f'pdb_files/{pdb_id}.pdb', 'r') as f:\n",
    "            pdb_text = f.read()\n",
    "\n",
    "            # find line REMARK   2 RESOLUTION.\n",
    "            resolution = None\n",
    "            for line in pdb_text.split('\\n'):\n",
    "                if line.startswith('REMARK   2 RESOLUTION.'):\n",
    "                    resolution = line.split(\"REMARK   2 RESOLUTION.\")[1].strip()\n",
    "                    break\n",
    "        if \"ANGSTROM\" in resolution:\n",
    "            resolution = resolution.replace(\" ANGSTROMS.\", \"\").strip()\n",
    "        else:\n",
    "            # print(f\"Resolution not found for {pdb_id}\")\n",
    "            resolution = None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get resolution for {pdb_id} with error {e}\")\n",
    "        resolution = None\n",
    "    return resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Entrez GeneId</th>\n",
       "      <th>Genome Location</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Hallmark</th>\n",
       "      <th>Chr Band</th>\n",
       "      <th>Somatic</th>\n",
       "      <th>Germline</th>\n",
       "      <th>Tumour Types(Somatic)</th>\n",
       "      <th>...</th>\n",
       "      <th>Tissue Type</th>\n",
       "      <th>Molecular Genetics</th>\n",
       "      <th>Role in Cancer</th>\n",
       "      <th>Mutation Types</th>\n",
       "      <th>Translocation Partner</th>\n",
       "      <th>Other Germline Mut</th>\n",
       "      <th>Other Syndrome</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>PDB Structures</th>\n",
       "      <th>n_structures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>29974.0</td>\n",
       "      <td>10:50799421-50885675</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oncogene</td>\n",
       "      <td>Mis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...</td>\n",
       "      <td>2CPD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI1</td>\n",
       "      <td>abl-interactor 1</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>10:26746593-26860935</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10p12.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AML</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>TSG, fusion</td>\n",
       "      <td>T</td>\n",
       "      <td>KMT2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...</td>\n",
       "      <td>7LXE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1</td>\n",
       "      <td>v-abl Abelson murine leukemia viral oncogene h...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9:130713946-130885683</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9q34.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CML, ALL, T-ALL</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>Dom</td>\n",
       "      <td>oncogene, fusion</td>\n",
       "      <td>T, Mis</td>\n",
       "      <td>BCR, ETV6, NUP214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...</td>\n",
       "      <td>[1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol                                               Name  \\\n",
       "0        A1CF                     APOBEC1 complementation factor   \n",
       "1        ABI1                                   abl-interactor 1   \n",
       "2        ABL1  v-abl Abelson murine leukemia viral oncogene h...   \n",
       "\n",
       "   Entrez GeneId        Genome Location  Tier Hallmark  Chr Band Somatic  \\\n",
       "0        29974.0   10:50799421-50885675     2      NaN  10q11.23     yes   \n",
       "1        10006.0   10:26746593-26860935     1      Yes   10p12.1     yes   \n",
       "2           25.0  9:130713946-130885683     1      Yes   9q34.12     yes   \n",
       "\n",
       "  Germline Tumour Types(Somatic)  ... Tissue Type Molecular Genetics  \\\n",
       "0      NaN              melanoma  ...           E                NaN   \n",
       "1      NaN                   AML  ...           L                Dom   \n",
       "2      NaN       CML, ALL, T-ALL  ...           L                Dom   \n",
       "\n",
       "     Role in Cancer Mutation Types Translocation Partner Other Germline Mut  \\\n",
       "0          oncogene            Mis                   NaN                NaN   \n",
       "1       TSG, fusion              T                 KMT2A                NaN   \n",
       "2  oncogene, fusion         T, Mis     BCR, ETV6, NUP214                NaN   \n",
       "\n",
       "  Other Syndrome                                           Synonyms  \\\n",
       "0            NaN  ACF,ACF64,ACF65,APOBEC1CF,ASP,CCDS73133.1,ENSG...   \n",
       "1            NaN  ABI-1,CCDS7150.1,E3B1,ENSG00000136754.17,NM_00...   \n",
       "2            NaN  ABL,CCDS35165.1,ENSG00000097007.17,JTK7,NM_007...   \n",
       "\n",
       "                                      PDB Structures n_structures  \n",
       "0                                               2CPD            1  \n",
       "1                                               7LXE            1  \n",
       "2  [1AB2, 1AWO, 1BBZ, 1JU5, 1OPL, 1ZZP, 2ABL, 2E2...           81  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count number of elements in each pdb_structure\n",
    "lens = []\n",
    "for i in pdb_structures:\n",
    "    # if value is list\n",
    "    if isinstance(i, list):\n",
    "        lens.append(len(i))\n",
    "    elif i is not None:\n",
    "        lens.append(1)\n",
    "    else:\n",
    "        lens.append(0)\n",
    "\n",
    "cgc_data['n_structures'] = lens\n",
    "cgc_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_data.to_csv('Census_all_with_pdb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_genes = [\"KRAS\", \"EGFR\", \"TP53\", \"HRAS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pdb files\n",
    "\n",
    "resolutions = defaultdict(dict)\n",
    "\n",
    "# count number of structures for all gene\n",
    "n_total = cgc_data[cgc_data['Gene Symbol'].isin(tmp_genes)][\"n_structures\"].sum()\n",
    "\n",
    "for gene in tmp_genes:\n",
    "    pdb_structures = cgc_data[cgc_data['Gene Symbol'] == gene]['PDB Structures'].values[0]\n",
    "    if pdb_structures:\n",
    "        for pdb_id in pdb_structures:\n",
    "            n_total -= 1\n",
    "            print(f\"Downloading PDB file {pdb_id} for {gene} ({n_total} structures remaining)\", end='\\r')\n",
    "            # check if the file already exists\n",
    "            if not os.path.exists(f'pdb_files/{pdb_id}.pdb'):\n",
    "                dwl_pdb_file(pdb_id)\n",
    "            resolution = get_resolution(pdb_id)\n",
    "            resolutions[gene][pdb_id] = resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resolutions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m top_structures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m      8\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gene_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresolutions\u001b[49m:\n\u001b[0;32m     10\u001b[0m     sorted_pdb_resolutions \u001b[38;5;241m=\u001b[39m sort_pdb_ids_by_resolution(gene_id)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m structures for Gene \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgene_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resolutions' is not defined"
     ]
    }
   ],
   "source": [
    "def sort_pdb_ids_by_resolution(gene_id):\n",
    "    pdb_resolutions = resolutions[gene_id]\n",
    "    sorted_pdb_ids = sorted(pdb_resolutions, key=lambda pdb_id: float('inf') if pdb_resolutions[pdb_id] is None else float(pdb_resolutions[pdb_id]))\n",
    "    sorted_resolutions = [(pdb_id, pdb_resolutions[pdb_id]) for pdb_id in sorted_pdb_ids]\n",
    "    return sorted_resolutions\n",
    "\n",
    "top_structures = dict()\n",
    "n = 30\n",
    "for gene_id in resolutions:\n",
    "    sorted_pdb_resolutions = sort_pdb_ids_by_resolution(gene_id)\n",
    "    print(f\"\\nTop {n} structures for Gene {gene_id}:\")\n",
    "    for pdb_id, resolution in sorted_pdb_resolutions[:n]:\n",
    "        print(f\"PDB ID: {pdb_id}, Resolution: {resolution}\")\n",
    "    top_structures[gene_id] = [i[0] for i in sorted_pdb_resolutions[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_structures = {'KRAS': ['6P0Z',\n",
    "  '8ONV',\n",
    "  '8AZZ',\n",
    "  '4QL3',\n",
    "  '8AZX',\n",
    "  '8B00',\n",
    "  '8AZV',\n",
    "  '8AZY',\n",
    "  '8B78',\n",
    "  '8AFB'],\n",
    " 'EGFR': ['8A27',\n",
    "  '8A2D',\n",
    "  '5UG9',\n",
    "  '5HG8',\n",
    "  '8A2A',\n",
    "  '5UG8',\n",
    "  '3POZ',\n",
    "  '6TFV',\n",
    "  '6TG0',\n",
    "  '3VRP'],\n",
    " 'TP53': ['3D06',\n",
    "  '5MHC',\n",
    "  '6GGC',\n",
    "  '6SHZ',\n",
    "  '4MZI',\n",
    "  '6GGE',\n",
    "  '3LW1',\n",
    "  '5O1E',\n",
    "  '6RL3',\n",
    "  '8E7A'],\n",
    " 'HRAS': ['2CE2',\n",
    "  '2EVW',\n",
    "  '2CLD',\n",
    "  '2CL6',\n",
    "  '2CL7',\n",
    "  '5WDQ',\n",
    "  '1CTQ',\n",
    "  '2CLC',\n",
    "  '3K8Y',\n",
    "  '3OIW']}\n",
    "# top_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chain': 'A', 'uniprot': 'Q93009', 'start': 53, 'end': 200},\n",
       " {'chain': 'A', 'uniprot': 'P04637', 'start': 201, 'end': 209},\n",
       " {'chain': 'B', 'uniprot': 'Q93009', 'start': 53, 'end': 200},\n",
       " {'chain': 'B', 'uniprot': 'P04637', 'start': 201, 'end': 209}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stat import S_ISDIR\n",
    "\n",
    "def download_directory(sftp, remote_dir, local_dir):\n",
    "    for item in sftp.listdir_attr(remote_dir):\n",
    "        remote_path = remote_dir + '/' + item.filename\n",
    "        local_path = os.path.join(local_dir, item.filename)\n",
    "        if S_ISDIR(item.st_mode):\n",
    "            os.makedirs(local_path, exist_ok=True)\n",
    "            download_directory(sftp, remote_path, local_path)\n",
    "        else:\n",
    "            sftp.get(remote_path, local_path)\n",
    "\n",
    "# get all chains, uniprot id, and start and end in pdb file\n",
    "def get_dbref_data(pdb_id):\n",
    "    with open(f'pdb_files/{pdb_id}.pdb', 'r') as f:\n",
    "        pdb_text = f.read()\n",
    "        data = []\n",
    "        for line in pdb_text.split('\\n'):\n",
    "            # contents of a DBREF line:  https://www.wwpdb.org/documentation/file-format-content/format33/sect3.html\n",
    "            # only reading relevant contents    \n",
    "            if line.startswith('DBREF') and line[26:32].strip()==\"UNP\": # if database is UNP \n",
    "                data.append({\n",
    "                    'chain': line[12],\n",
    "                    'uniprot': line[33:41].strip(),\n",
    "                    'start': int(line[14:18]),\n",
    "                    'end': int(line[20:24])\n",
    "                })  \n",
    "    return data\n",
    "\n",
    "get_dbref_data('2F1X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dbref_line(line):\n",
    "    # contents of a DBREF line:  https://www.wwpdb.org/documentation/file-format-content/format33/sect3.html\n",
    "    # only reading relevant contents\n",
    "    chain_id = line[12]               # Chain identifier\n",
    "    seq_begin = int(line[14:18])      # Initial sequence number of the PDB sequence segment\n",
    "    seq_end = int(line[20:24])        # Ending sequence number of the PDB sequence segment\n",
    "    database = line[26:32].strip()    # Sequence database name\n",
    "    db_accession = line[33:41].strip()# Sequence database accession code\n",
    "    \n",
    "    return {\n",
    "        \"chain_id\": chain_id,\n",
    "        \"seq_begin\": seq_begin,\n",
    "        \"seq_end\": seq_end,\n",
    "        \"database\": database,\n",
    "        \"db_accession\": db_accession,\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "line = \"DBREF  6LHD A    2   149L UNP    Q07817   B2CL1_HUMAN      2    201\"\n",
    "parsed_line = parse_dbref_line(line)\n",
    "print(parsed_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sbna_and_download(client, sftp, pdb_id, base_path, chains=None):\n",
    "    # get available chains\n",
    "    if not chains: # chain not specified\n",
    "        try:\n",
    "            chains = get_dbref_data(pdb_id)\n",
    "            chains = [chain['chain'] for chain in chains]\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get chains for {pdb_id} with error {e}\")\n",
    "            return\n",
    "    \n",
    "    sftp.mkdir(f'{base_path}/{pdb_id}')\n",
    "    for chain in chains: \n",
    "        local_dir = f\"sbna_results/{pdb_id}/{chain}\"\n",
    "        if os.path.exists(f\"{local_dir}/{pdb_id}_monomer/FinalSum\"): # skip if analysis already done and downloaded\n",
    "            continue\n",
    "        try:\n",
    "            print(f\"\\nProcessing {pdb_id} with chain {chain}...\")\n",
    "\n",
    "            # remove the directory if already exists and create new one\n",
    "            client.exec_command(f\"rm -r {base_path}/{pdb_id}/{pdb_id}_monomer\")\n",
    "            client.exec_command(f\"rm -r {base_path}/{pdb_id}/{pdb_id}_multimer\") \n",
    "            \n",
    "            # upload pdb file to the remote directory\n",
    "            sftp.put(f\"pdb_files/{pdb_id}.pdb\", f'{base_path}/{pdb_id}/{pdb_id}.pdb') \n",
    "            \n",
    "            # copy the sbna.sh file to the subdirectory\n",
    "            client.exec_command(f\"cp {base_path}/sbna.sh {base_path}/{pdb_id}/sbna.sh\") \n",
    "\n",
    "            # run the sbna.sh script\n",
    "            _,stdout,stderr=client.exec_command(f'cd {base_path}/{pdb_id}; sh sbna.sh {pdb_id}.pdb \"Chain {chain}\"') \n",
    "            print(stdout.read().decode())\n",
    "            \n",
    "            # check if Final_sum file exists\n",
    "            print(stderr.read().decode('utf-8'))\n",
    "            _,stdout,stderr=client.exec_command(f\"ls {base_path}/{pdb_id}/{pdb_id}_monomer/FinalSum\")\n",
    "            # print error message if no output\n",
    "\n",
    "            # download the sbna results\n",
    "            if not stdout.read().decode():\n",
    "                print(f\"Final_sum file not found for {pdb_id}\")\n",
    "                # client.exec_command(f\"rm -rf {base_path}/{pdb_id}\") \n",
    "                continue\n",
    "            \n",
    "            # download the pdb_id directory\n",
    "            os.makedirs(local_dir, exist_ok=True) # create the directory if it doesn't exist\n",
    "            download_directory(sftp, f\"{base_path}/{pdb_id}\", local_dir)\n",
    "            print(f\"SBNA results for {pdb_id} succesfully downloaded\")\n",
    "        \n",
    "        except Exception:\n",
    "            # print full error message\n",
    "            print(f\"Failed to process {pdb_id} with error:\")\n",
    "            print(traceback.print_exc())\n",
    "\n",
    "            # remove directory\n",
    "            client.exec_command(f\"rm -r {base_path}/{pdb_id}/{pdb_id}_monomer\")\n",
    "            client.exec_command(f\"rm -r {base_path}/{pdb_id}/{pdb_id}_multimer\")\n",
    "            continue\n",
    "    \n",
    "    client.exec_command(f\"rm -rf {base_path}/{pdb_id}\") # remove the pdb_id remote directory\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under the terms of the\n",
      "GNU General Public License versions 2 or 3.\n",
      "For more information about these matters see\n",
      "https://www.gnu.org/licenses/.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing 1TSR with chain C...\n",
      "Starting phenix.pdbtools\n",
      "on Thu Apr 18 13:23:24 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 1TSR.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    keep=Chain C\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"1TSR.pdb\"\n",
      "    }\n",
      "    default_model = \"1TSR.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    keep = Chain C\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 5828 size after: 1608\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 2.66 seconds\n",
      "wall clock time: 4.79 seconds\n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Thu Apr 18 13:23:27 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 1TSR_monomer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"1TSR_monomer.pdb\"\n",
      "    }\n",
      "    default_model = \"1TSR_monomer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 1608 size after: 1530\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.68 seconds\n",
      "wall clock time: 1.70 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are \n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 1TSR_monomer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "Cleaning PDB file\n",
      "Starting phenix.pdbtools\n",
      "on Thu Apr 18 13:24:18 2024 by yliy0004\n",
      "===============================================================================\n",
      "\n",
      "Processing files:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Found model, 1TSR_multimer.pdb\n",
      "\n",
      "Processing PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  Adding command-line PHIL:\n",
      "  -------------------------\n",
      "    remove=water\n",
      "\n",
      "Final processed PHIL parameters:\n",
      "-------------------------------------------------------------------------------\n",
      "  data_manager {\n",
      "    model {\n",
      "      file = \"1TSR_multimer.pdb\"\n",
      "    }\n",
      "    default_model = \"1TSR_multimer.pdb\"\n",
      "  }\n",
      "  modify {\n",
      "    remove = water\n",
      "  }\n",
      "\n",
      "\n",
      "Starting job\n",
      "===============================================================================\n",
      "Validating inputs\n",
      "Performing manipulations\n",
      "Size before: 5828 size after: 5444\n",
      "Writing output model\n",
      "\n",
      "===============================================================================\n",
      "Job complete\n",
      "usr+sys time: 1.92 seconds\n",
      "wall clock time: 1.93 seconds\n",
      "Writing out polypeptide file...\n",
      "Adding hydrogens...\n",
      "Protonating waters...\n",
      "Making .phi file\n",
      "Running full bond calculation script\n",
      "The ligands identified in this pdb are DT-11E, DT-6F, DT-6E, DT-2F, DG-18F, DT-2E, DT-16F, DG-9F, DA-18E, DA-20F, DC-4E, DC-15E, DC-15F, DA-9E, DT-20E, DT-12E, DA-12F, DA-3F, DT-14F, DT-5F, DA-1F, DG-19F, DT-3E, DG-8F, DT-1E, DA-21E, DC-5E, DA-21F, DA-7E, DG-13F, DG-13E, DC-10F, DC-10E, DC-16E, DA-17E, DA-17F, DA-4F, DA-11F, DC-14E, DG-8E, DG-7F, DT-19E\n",
      "Screening for atoms that are close.\n",
      "Dictionaries loaded.\n",
      "Starting salt bridges.\n",
      "Starting hydrogen bonds.\n",
      "Starting pi-pi version 2.\n",
      "Running pi-cation version 2\n",
      "Starting disulfide\n",
      "Starting van der waals.\n",
      "Starting metals\n",
      "Starting DNA bonds...\n",
      "Starting Ligand centroids\n",
      "Starting residue centroids...\n",
      "Removing duplicates from BFactor file\n",
      "Making 1TSR_multimer_nowaters_net\n",
      "Removing any negative value edges\n",
      "Creating QC file\n",
      "Creating Centroid directory and moving files\n",
      "Running energetic R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##Load libraries\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> \n",
      "> ##Initialize keywords\n",
      "> # keyword is the base filename\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",paste(keyword,\"_secondaryStructure\",sep=\"\"))\n",
      "> atomCorrection=FALSE\n",
      "> baseKeyword = unlist(strsplit(keyword,\"/\"))[1]\n",
      "> runVariableSelection = TRUE\n",
      "> \n",
      "> ##Load inversal data\n",
      "> #Unique atoms file\n",
      "> terminalAtomsFile = as.matrix(read.table(\"../../terminalAtoms\",sep=\"\\t\"))\n",
      "> terminalAtoms = {}\n",
      "> for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+     terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\", \"))\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> secStructure = as.matrix(read.table(args[3]))[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> \n",
      "> #RSA\n",
      "> rsa = as.matrix(read.table(paste(keyword,\".rsa\",sep=\"\")))\n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> #Add terminal atom details\n",
      "> addTermDetails = function(data) {\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         } else {\n",
      "+             code1 = 0\n",
      "+         }\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         } else {\n",
      "+             code2 = 0\n",
      "+         }\n",
      "+     out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> collapse = function(data) {\n",
      "+     if (nrow(data)==0) {\n",
      "+         out = matrix(ncol = 8,nrow=0)\n",
      "+         colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+         results = c(); results$out = out\n",
      "+         return(results)\n",
      "+         break\n",
      "+     }\n",
      "+     #Edges should be listed bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     } else {\n",
      "+         data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6],data[,9],data[,8]))\n",
      "+     }\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     completed = c()\n",
      "+     if (dim(data)[2]==7) {\n",
      "+         out_details = c()\n",
      "+         for (i in 1:nrow(data)) {\n",
      "+             acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+             acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+             if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+                 code1 = 1\n",
      "+             } else {\n",
      "+                 code1 = 0\n",
      "+             }\n",
      "+             if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+                 code2 = 1\n",
      "+             } else {\n",
      "+                 code2 = 0\n",
      "+             }\n",
      "+             out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+         }\n",
      "+         data = out_details\n",
      "+     } else {\n",
      "+         out_details = data\n",
      "+     }\n",
      "+     colnames(out_details) = c(\"AA1\",\"AA2\",\"Type1\",\"Weight\",\"Type2\",\"Atom1\",\"Atom2\",\"influence1\",\"influence2\")\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         if (i %in% completed == FALSE) {\n",
      "+             x=which((data[,1]==data[i,1] & data[,2] == data[i,2]))\n",
      "+             subdata = matrix(data[x,],ncol=9)\n",
      "+             edgeSum = 0\n",
      "+             MCMCcount = 0\n",
      "+             MCSCcount = 0\n",
      "+             SCMCcount = 0\n",
      "+             SCSCcount = 0\n",
      "+             influence1 = sum(as.numeric(subdata[,8]))\n",
      "+             influence2 = sum(as.numeric(subdata[,9]))\n",
      "+             for (j in 1:nrow(subdata)) {\n",
      "+                 edgeSum = edgeSum + as.numeric(subdata[j,4])\n",
      "+                 if (subdata[j,3]==\"MCMC\" | subdata[j,3]==\"MCSC\") {\n",
      "+                     MCMCcount = MCMCcount+1\n",
      "+                     MCSCcount = MCSCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCMC\") {\n",
      "+                     SCMCcount = SCMCcount+1\n",
      "+                 } else if (subdata[j,3]==\"SCSC\") {\n",
      "+                     SCSCcount = SCSCcount+1\n",
      "+                 }\n",
      "+             }\n",
      "+             #Header is AA1, AA2, mixed, sum of edges, percent MC, influence1, influence2, degreeAA1\n",
      "+             out = rbind(out,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))\n",
      "+             if (any(subdata[,5]==\"PP\")==FALSE) {out_noPP = rbind(out_noPP,c(data[i,1],data[i,2],\"mixed\",edgeSum,(MCMCcount+MCSCcount)/(MCMCcount+MCSCcount+SCMCcount+SCSCcount),influence1,influence2,sum(data[,1]==data[i,1])))}\n",
      "+             completed = c(completed,x)\n",
      "+         }\n",
      "+     }\n",
      "+     out = out[out[,4]>0,]\n",
      "+     out_noPP = out_noPP[out_noPP[,4]>0,]\n",
      "+     colnames(out) = c(\"AA1\", \"AA2\", \"Type\", \"SumEdges\", \"percentMC\", \"influence1\", \"influence2\",\"degree\")\n",
      "+     results = c()\n",
      "+     results$out = out\n",
      "+     results$out_noPP = out_noPP\n",
      "+     results$influence_all = out_details[as.numeric(out_details[,4])>0 & (out_details[,8]==\"1\" | out_details[,9]==\"1\"),]\n",
      "+     out_details = out_details[as.numeric(out_details[,4])>0,]\n",
      "+     out_subtract = out_details; out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4] = (-1)*as.numeric(out_subtract[out_subtract[,8]==0 & out_subtract[,9]==0,4])\n",
      "+     out_subtract = out_subtract[out_subtract[,5]!=\"PP\",]\n",
      "+     results$out_subtract = out_subtract\n",
      "+     return(results)\n",
      "+ }\n",
      "> \n",
      "> removeRedundancy = function(dataTmp) {\n",
      "+     for (i in 1:nrow(dataTmp)) {\n",
      "+         if (order(dataTmp[i,1:2])[1]==2) {\n",
      "+             dataTmp[i,1:2] = c(dataTmp[i,2],dataTmp[i,1])\n",
      "+             dataTmp[i,3] = paste(unlist(strsplit(dataTmp[i,3],split=\"\"))[c(3,4,1,2)],collapse=\"\")\n",
      "+             dataTmp[i,c(6,7)] = c(dataTmp[i,7],dataTmp[i,6])\n",
      "+         }\n",
      "+     }\n",
      "+     dataTmp = unique(dataTmp)\n",
      "+     pairs = unique(dataTmp[,1:2])\n",
      "+     out = c()\n",
      "+     for (j in 1:nrow(pairs)) {\n",
      "+         pair = pairs[j,]\n",
      "+         subData = matrix(dataTmp[dataTmp[,1]==pair[1] & dataTmp[,2]==pair[2],],ncol=7)\n",
      "+         out = rbind(out, c(pair[1],pair[2],\"mixed\",0.5*sum(as.numeric(subData[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_directed = function(data) {\n",
      "+     pairs = unique(data[,1:2])\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> collapse_agnostic = function(data) {\n",
      "+     pairs = unique(t(apply(data[,1:2],1,function(x){return(sort(x))})))\n",
      "+     out = c()\n",
      "+     for (i in 1:nrow(pairs)) {\n",
      "+         subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),],ncol=4)\n",
      "+         out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> distributCalc = function(set,nodes,net) {\n",
      "+     #x is assumed to be a set but can also just be 1 node\n",
      "+     distanceNet = distances(net,weights=net$weight)\n",
      "+     distanceTmp = c()\n",
      "+     Dr = c()\n",
      "+     for (node in nodes) {\n",
      "+         distanceTmp = c()\n",
      "+         for (item in set) {\n",
      "+             if (item!=node) {\n",
      "+                 if(item%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 if(node%in%rownames(distanceNet)==FALSE){distanceTmp=100;next}\n",
      "+                 distanceTmp = c(distanceTmp,distanceNet[item,node])\n",
      "+             }\n",
      "+         }\n",
      "+         if (length(distanceTmp)>0) {\n",
      "+             Dr = c(Dr, 1/min(distanceTmp))\n",
      "+         }\n",
      "+     }\n",
      "+     return(sum(Dr)/length(nodes))\n",
      "+ }\n",
      "> \n",
      "> ##Read in user data\n",
      "> data_all = as.matrix(read.table(args[1]))\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> basedata = collapse(data_all)\n",
      "> basedata_noPP = removeRedundancy(basedata$out[,1:7])\n",
      "> basedata_allsidechain = collapse_agnostic(data_all[data_all[,3]!=\"MCMC\",c(1,2,3,4)])\n",
      "> influencedata_all = basedata$influence_all\n",
      "> influencedata_collapse = collapse(influencedata_all)\n",
      "> influencedata = removeRedundancy(influencedata_collapse$out[,1:7])\n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(influencedata_all[influencedata_all[,8]==1,c(1,2,3,4)])\n",
      "> influencenet_directed = graph.edgelist(influencedata_directed[,c(2,1)],directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> \n",
      "> #Write out edgelist files\n",
      "> write.table(influencedata,file=paste(keyword,\"_allEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> write.table(influencedata_directed,file=paste(keyword,\"_uniqueEdges\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=FALSE,row.names=FALSE)\n",
      "> \n",
      "> ###Deal with missing nodes\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##Begin centrality calculations\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> if(length(nodes)>200) {textsize=.25} else {textsize=.45}\n",
      "> plot(net,edge.color = edgecolors, vertex.color = nodes.color,vertex.size=4,vertex.label.cex=textsize,main=\"WALKTRAP\")\n",
      ">     \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     firstorder = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> nodes = V(net)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+         node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> nodes = V(influencenet)$name\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])])) - 1\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])])) - 1\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ### Create final dataset\n",
      "> \n",
      "> out = cbind(\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> rownames(out) = nodes\n",
      "> colnames(out) = c(\"Degree\",\"Degree_sidechain\",\"SecondOrderDegree\",\"SecondOrderDegree_sidechain\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_sidechain\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_sidechain\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_sidechain\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_sidechain\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_sidechain\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_sidechain\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out = out+1\n",
      "> \n",
      "> #Write out\n",
      "> write.table(out,file=paste(keyword,\"_scoresEnergetics\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> #Standard normalization\n",
      "> outZ = apply(out,2,function(x){return(scale(x))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresEnergeticsZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "Running centroid R script\n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> library(igraph)\n",
      "> library(stats)\n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> ##read in data\n",
      "> ## arg1: col1 and col2 are edges, col3 is weight of edge\n",
      "> ## arg2: weighted, unweighted <-- no longer using\n",
      "> ## arg3: forced module definition <-- no longer using\n",
      "> \n",
      "> # Set desired parameters\n",
      "> removeMCMC = FALSE\n",
      "> linearcutoff = 1\n",
      "> directed = FALSE\n",
      "> secondaryStructure2 = FALSE\n",
      "> sidechainMode = TRUE ##build network of just SCSC, SCMC and MCSC. Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> uniqueAtomsMode = FALSE ##build network of just unique atoms (each edge has to have at least 1). Still use unique atoms for the _uniqueAtoms directed plots\n",
      "> useDNA=TRUE\n",
      "> uniqueAtomsUnbiased=FALSE\n",
      "> uniqueAtomsGaurav=FALSE\n",
      "> uniqueAtomsOLD=FALSE\n",
      "> atomCorrection = FALSE\n",
      "> uniqueAtomsGauravPP = FALSE\n",
      "> weighted = TRUE\n",
      "> removeWaters=TRUE\n",
      "> if (tail(unlist(strsplit(getwd(),\"/\")),n=1)==\"Centroid\") {\n",
      "+     ligandCentroidMode = TRUE\n",
      "+ } else {\n",
      "+     ligandCentroidMode = FALSE\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> # Read in ligand file\n",
      "> ligandfile = scan(paste(args[1],\"_ligand\",sep=\"\"),what=\"character\")\n",
      "> if (length(ligandfile)==0){\n",
      "+     ligandmode = FALSE\n",
      "+ } else {\n",
      "+     ligandmode = TRUE\n",
      "+ }\n",
      "> \n",
      "> ligandCentroidFile = scan(paste(args[1],\"NetLigand\",sep=\"\"),what=\"character\")\n",
      "> \n",
      "> # keyword is the base filename\n",
      "> # method is \"frag\" or \"module\" or \"both\"\n",
      "> keyword = args[1]\n",
      "> args=c(paste(args[1],\"_net\",sep=\"\"),\"weighted\",dir(\"./\",\"_secondaryStructure$\"))\n",
      "> \n",
      "> ##Load data\n",
      "> #Unique atoms file\n",
      "> if(uniqueAtomsUnbiased) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsUnbiased\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsGaurav) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"/Users/vjpatel/Dropbox/Gaurav/uniqueAtomsGaurav\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else if (uniqueAtomsOLD) {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../terminalAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+     }\n",
      "+ } else {\n",
      "+     terminalAtomsFile = as.matrix(read.table(\"../../../uniqueAtoms\",sep=\"\\t\"))\n",
      "+     terminalAtoms = list()\n",
      "+     otherTA = list()\n",
      "+     for (i in 1:nrow(terminalAtomsFile)) {\n",
      "+         terminalAtoms[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,2],split=\",\"))\n",
      "+         #otherTA[[terminalAtomsFile[i,1]]] = unlist(strsplit(terminalAtomsFile[i,4],split=\",\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> #Secondary structure file\n",
      "> #Ligands are all one secondary structure\n",
      "> secStructure = as.matrix(read.table(args[3]))\n",
      "> phiAngleDB = {}\n",
      "> for (i in 1:nrow(secStructure)) {\n",
      "+     phiAngleDB[[secStructure[i,1]]] = as.numeric(secStructure[i,3])\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     liganddat = unique(liganddat[,2])\n",
      "+     for (ligand in liganddat) {\n",
      "+         secStructure = rbind(secStructure,c(sub(\"-\",\"\",ligand),\"ligand\",360))\n",
      "+         phiAngleDB[[sub(\"-\",\"\",ligand)]]=0\n",
      "+     }\n",
      "+ } else {\n",
      "+     liganddat = c()\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Define functions\n",
      "> \n",
      "> ##Collapse matrix functions\n",
      "> ##Will return redundant matrix\n",
      "> ##Input needs to be 7 columns\n",
      "> ##Second input is different if the main input is a subset of the larger data\n",
      "> addTerminalDetails = function(data,largerdata) {\n",
      "+     #List edges bi-directionally\n",
      "+     x=unlist(lapply(data[,3],function(x){if(x==\"MCSC\"){return(\"SCMC\")}else if(x==\"SCMC\"){return(\"MCSC\")} else {return(x)}}))\n",
      "+     data = rbind(data,cbind(data[,2],data[,1],x,data[,4],data[,5],data[,7],data[,6]))\n",
      "+     data = unique(data)\n",
      "+     out = c()\n",
      "+     out_noPP = c()\n",
      "+     out_details = c()\n",
      "+     for (i in 1:nrow(data)) {\n",
      "+         acid1 = paste(unlist(strsplit(data[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         acid2 = paste(unlist(strsplit(data[i,2],split=\"\"))[1:3],collapse=\"\")\n",
      "+         subdata = matrix(data[data[,1]==data[i,1]&data[,2]==data[i,2],],ncol=7)\n",
      "+         allsubdata = matrix(largerdata[largerdata[,1]==data[i,1],],ncol=7)\n",
      "+         code1=0;code2=0\n",
      "+         if (data[i,6] %in% terminalAtoms[[acid1]]) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code1 = 1\n",
      "+         }\n",
      "+         allsubdata = matrix(largerdata[largerdata[,2]==data[i,2],],ncol=7)\n",
      "+         if (data[i,7] %in% terminalAtoms[[acid2]]) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5] == \"DNA\" & useDNA==TRUE) {\n",
      "+             code2 = 1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PICATION\"|data[i,5]==\"PIPI\") {\n",
      "+             code1=1\n",
      "+             code2=1\n",
      "+         }\n",
      "+         if (data[i,5]==\"PP\") {\n",
      "+             if (uniqueAtomsGaurav) {\n",
      "+                 if((acid1) == \"GLY\") {\n",
      "+                     code1 = 1\n",
      "+                     data[i,3]==\"SCSC\"\n",
      "+                 }\n",
      "+                 if ((acid2) == \"GLY\") {\n",
      "+                     code2 = 1\n",
      "+                     data[i,3] == \"SCSC\"\n",
      "+                 }\n",
      "+             }\n",
      "+         }\n",
      "+         out_details = rbind(out_details, c(data[i,],code1,code2))\n",
      "+     }\n",
      "+     return(out_details)\n",
      "+ }\n",
      "> \n",
      "> ##Will return non-redundant matrix\n",
      "> collapse_agnostic = function(data) {\n",
      "+     if(nrow(data)==0) {\n",
      "+         return(matrix(ncol=4,nrow=0))\n",
      "+     } else if (ncol(data)==4 & data[1,3]==\"mixed\") {\n",
      "+         return(data)\n",
      "+     } else {\n",
      "+         pairs = unique(t(apply(matrix(data[,1:2],ncol=2),1,function(x){return(sort(x))})))\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[(data[,1]==pairs[i,1]&data[,2]==pairs[i,2]) | (data[,2]==pairs[i,1]&data[,1]==pairs[i,2]),1:4],ncol=4)\n",
      "+             subdat = unique(t(apply(subdat,1,function(x){a=which(x==sort(x[1:2])[1]);if(a==1){return(x)}else{return(c(x[2],x[1],paste(unlist(strsplit(x[3],\"\"))[c(3,4,1,2)],collapse=\"\"),x[4]))}})))\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+     return(out)\n",
      "+ }\n",
      "> \n",
      "> ##Will return directed collapsed matrix\n",
      "> collapse_directed = function(data) {\n",
      "+     if (length(data)==0) {\n",
      "+         return(matrix(nrow=0,ncol=4))\n",
      "+     } else {\n",
      "+         pairs = matrix(unique(data[,1:2]),ncol=2)\n",
      "+         out = c()\n",
      "+         for (i in 1:nrow(pairs)) {\n",
      "+             subdat = matrix(data[data[,1]==pairs[i,1]&data[,2]==pairs[i,2],1:4],ncol=4)\n",
      "+             if (weighted==FALSE) {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",1))\n",
      "+             } else {\n",
      "+                 out = rbind(out,c(subdat[1,1],subdat[1,2],\"mixed\",sum(as.numeric(subdat[,4]))))\n",
      "+             }\n",
      "+         }\n",
      "+         return(matrix(out,ncol=4))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> rsa = as.matrix(read.table(dir(\"./\",\".rsa$\")))\n",
      "> rownames(rsa) = rsa[,1]\n",
      "> rsa[,1] = rsa[,2]\n",
      "> \n",
      "> #add ligand as -1\n",
      "> for (ligand in liganddat) {\n",
      "+     rsa = rbind(rsa,c(-1,-1))\n",
      "+     rownames(rsa)[nrow(rsa)] = sub(\"-\",\"\",ligand)\n",
      "+ }\n",
      "> \n",
      "> #Function to get amino acid\n",
      "> getAcid = function(residue) {\n",
      "+     if(all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"A\")) == TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"G\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"C\"))==TRUE) | all((unlist(strsplit(residue,\"\"))[1:2] == c(\"D\",\"T\"))==TRUE)) {return(paste(unlist(strsplit(residue,\"\"))[1:2],collapse=\"\"))\n",
      "+     } else {\n",
      "+     return(paste(unlist(strsplit(residue,\"\"))[1:3],collapse=\"\"))\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> ##################\n",
      "> ## read in data ##\n",
      "> ##################\n",
      "> data_all = as.matrix(read.table(args[1]))[,1:7]\n",
      "> if(removeWaters) {\n",
      "+     y=c(grep(\"HOH\",data_all[,1]),grep(\"HOH\",data_all[,2]))\n",
      "+     if(length(y)>0) {\n",
      "+         data_all = data_all[-y,]\n",
      "+     }\n",
      "+ }\n",
      "> nodes = unique(c(data_all[,1:2])); sets = nodes\n",
      "> originalNodes = nodes\n",
      "> \n",
      "> data_all_original = rbind(data_all,data_all[,c(2,1,3,4,5,7,6)])\n",
      "> data_all = data_all[as.numeric(data_all[,4])>0,]\n",
      "> \n",
      "> basedata = addTerminalDetails(data_all,data_all_original)\n",
      "> basedata_noPP = collapse_agnostic(basedata[basedata[,5]!=\"PP\",])\n",
      "> sidechaindata = basedata[basedata[,3]!=\"MCMC\",1:4]\n",
      "> sidechaindata_detailed = basedata[basedata[,3]!=\"MCMC\",]\n",
      "> \n",
      "> influencedata_detailed = basedata\n",
      "> if (uniqueAtomsMode) {\n",
      "+     influencedata_detailed = basedata[basedata[,8]==1 | basedata[,9]==1,]\n",
      "+ }\n",
      "> influencedata = collapse_agnostic(influencedata_detailed)\n",
      "> influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,1]),])\n",
      "> influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "> \n",
      "> \n",
      "> influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "> influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "> \n",
      "> influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "> influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "> influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "> \n",
      "> influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "> influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "> influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "> \n",
      "> \n",
      "> if(sidechainMode) {\n",
      "+     influencedata_detailed = sidechaindata_detailed\n",
      "+     influencedata = collapse_agnostic(influencedata_detailed)\n",
      "+     influencedataGLY = rbind(influencedata[grep(\"GLY\",influencedata[,1]),],influencedata[grep(\"GLY\",influencedata[,2]),])\n",
      "+     influencedata = influencedata[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata = rbind(influencedata,influencedataGLY)\n",
      "+     }\n",
      "+     influencedata = influencedata[as.numeric(influencedata[,4])>0,]\n",
      "+     \n",
      "+     influencenet = graph.edgelist(influencedata[,1:2],directed=FALSE)\n",
      "+     influencenet$weight = 1/as.numeric(influencedata[,4])\n",
      "+     \n",
      "+     influencedata_directed = collapse_directed(matrix(influencedata_detailed[influencedata_detailed[,8]==1,1:4],ncol=4))\n",
      "+     influencedata_directedGLY = rbind(influencedata_directed[grep(\"GLY\",influencedata_directed[,1]),],influencedata_directed[grep(\"GLY\",influencedata_directed[,2]),])\n",
      "+ \n",
      "+     influencedata_directed = influencedata_directed[abs(as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,1]))-as.numeric(gsub(\"[A-Z]\",\"\",influencedata_directed[,2])))>linearcutoff,]\n",
      "+     #Add back for GLY if uniqueAtomsGaurav\n",
      "+     if(uniqueAtomsGauravPP) {\n",
      "+         influencedata_directed = rbind(influencedata_directed,influencedata_directedGLY)\n",
      "+     }\n",
      "+     influencedata_directed = matrix(influencedata_directed,ncol=4)\n",
      "+     influencenet_directed = graph.edgelist(matrix(influencedata_directed[,c(2,1)],ncol=2),directed=TRUE)\n",
      "+     influencenet_directed$weight = 1/as.numeric(influencedata_directed[,4])\n",
      "+     \n",
      "+ }\n",
      "> \n",
      "> #Replace missing nodes in the igraph net\n",
      "> nodesMissing = nodes[nodes %in% influencedata[,1]==FALSE & nodes %in% influencedata[,2]==FALSE]\n",
      "> \n",
      "> ##B-factor\n",
      "> bfactor = as.matrix(read.table(dir(\"./\",\"_Bfactor\"),row.names=1))\n",
      "> \n",
      "> #Replace missing nodes in secStructure matrix\n",
      "> if (any(nodes %in% secStructure[,1]==FALSE)) {\n",
      "+     for (node in nodes) {\n",
      "+         if (node %in% secStructure[,1]==FALSE) {\n",
      "+             secStructure = rbind(secStructure,c(node,\"xxx\",360))\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> for (node in nodes) {\n",
      "+     if (node %in% rownames(rsa) == FALSE) {\n",
      "+         rsa = rbind(rsa,c(0,0))\n",
      "+         rownames(rsa)[nrow(rsa)] = node\n",
      "+     }\n",
      "+     if (node %in% rownames(bfactor) == FALSE) {\n",
      "+         bfactor = rbind(bfactor,1)\n",
      "+         rownames(bfactor)[nrow(bfactor)] = node\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "> #Give DNA attributes\n",
      "> if (\"DNA\" %in% data_all[,5]) {\n",
      "+     for (i in 1:nrow(data_all)) {\n",
      "+         if (data_all[i,5]==\"DNA\") {\n",
      "+             phiAngleDB[[data_all[i,1]]] = 90\n",
      "+             if (data_all[i,1] %in% rownames(rsa) == FALSE) {\n",
      "+                 rsa = rbind(rsa,c(0,0))\n",
      "+                 rownames(rsa)[nrow(rsa)] = data_all[i,1]\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(secStructure) == FALSE) {\n",
      "+                 secStructure = rbind(secStructure,c(data_all[i,1],\"DNA\",360))\n",
      "+             }\n",
      "+             if (data_all[i,1] %in% rownames(bfactor) == FALSE) {\n",
      "+                 bfactor = rbind(bfactor,1)\n",
      "+                 rownames(bfactor)[nrow(bfactor)] = data_all[i,1]\n",
      "+             }\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #Betweenness\n",
      "> node_betweenness = betweenness(influencenet,weights=influencenet$weight,directed=directed)\n",
      "> node_betweenness_unique = betweenness(influencenet_directed,weights=influencenet_directed$weight,directed=directed)\n",
      "> \n",
      "> #Modular calculations\n",
      "> \n",
      "> ##WALKTRAP\n",
      "> net = graph.edgelist(basedata_noPP[,1:2],directed=FALSE)\n",
      "> net$weight = 1/as.numeric(basedata_noPP[,4])\n",
      "> net_community=walktrap.community(net,weights=net$weight); net_community_vec = net_community$membership; names(net_community_vec)=net_community$names\n",
      "> net_community_vec_wt = net_community_vec\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> nodes.color = c()\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(influencedata)) {\n",
      "+     j = which((basedata_noPP[,1]==influencedata[i,1]&basedata_noPP[,2]==influencedata[i,2])|(basedata_noPP[,1]==influencedata[i,2]&basedata_noPP[,2]==influencedata[i,1]))\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) { edgecolors[j]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP\n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WALKTRAP - WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Degree and second order degree for WALKTRAP\n",
      "> firstOrderDegree = degree(influencenet)\n",
      "> firstOrderDegree_sidechain = degree(influencenet_directed,mode=c(\"in\"))\n",
      "> \n",
      "> secondOrderDegree = c(); secondOrderDegree_sidechain=c()\n",
      "> nodes = V(influencenet)$name\n",
      "> for (node in nodes) {\n",
      "+     firstorder = neighbors(influencenet,node)\n",
      "+     secondorder = c(); for (neighbor in firstorder){secondorder = c(secondorder,names(neighbors(influencenet,neighbor)))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree = c(secondOrderDegree,length(secondorder))\n",
      "+     if(node %in% V(influencenet_directed)$name) {\n",
      "+         firstorder_sidechain = neighbors(influencenet_directed,node,mode=c(\"in\"))\n",
      "+     } else {\n",
      "+         firstorder_sidechain = c()\n",
      "+     }\n",
      "+     secondorder = c(); for (neighbor in firstorder_sidechain){secondorder = c(secondorder,names(neighbors(influencenet_directed,neighbor,mode=c(\"in\"))))}; secondorder = unique(secondorder); secondorder=secondorder[secondorder!=node]\n",
      "+     secondOrderDegree_sidechain = c(secondOrderDegree_sidechain,length(secondorder))\n",
      "+ }\n",
      "> names(secondOrderDegree) = nodes; names(secondOrderDegree_sidechain) = nodes\n",
      "> \n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> #SAVE ALL AS WALKTRAP\n",
      "> node_edge_betweenness_wt = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_wt = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_wt = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_wt = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_wt = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_wt = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> \n",
      "> ##2ARY STRUCTURE\n",
      "> secStructure = secStructure[,1:2]\n",
      "> rownames(secStructure) = secStructure[,1]\n",
      "> net_community_vec = as.numeric(as.factor(secStructure[,2]))\n",
      "> names(net_community_vec) = secStructure[,1]\n",
      "> #net_community_vec[buriednodes] = max(net_community_vec)+1\n",
      "> nodes = V(influencenet)$name\n",
      "> edgecolors = rep(\"grey90\",nrow(basedata_noPP))\n",
      "> colorPalette=rainbow(max(net_community_vec),s=.5)\n",
      "> nodes.color = c()\n",
      "> for (i in 1:length(nodes)) {\n",
      "+     nodes.color = c(nodes.color,colorPalette[net_community_vec[nodes[i]]])\n",
      "+ }\n",
      "> for (i in 1:nrow(basedata_noPP)) {\n",
      "+     if (net_community_vec[basedata_noPP[i,1]]!=net_community_vec[basedata_noPP[i,2]]) { edgecolors[i]=\"grey40\" }\n",
      "+ }\n",
      "> \n",
      "> edge_betweenness = edge.betweenness(influencenet,weights=influencenet$weight)\n",
      "> node_edge_betweenness = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         node_edge_betweenness[influencedata[i,1]] = node_edge_betweenness[influencedata[i,1]]+edge_betweenness[i]\n",
      "+         node_edge_betweenness[influencedata[i,2]] = node_edge_betweenness[influencedata[i,2]]+edge_betweenness[i]\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree) = nodes\n",
      "> node_modules = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata = matrix(influencedata[influencedata[,1]==node | influencedata[,2]==node,],ncol=4)\n",
      "+     if (nrow(subdata)==0) {node_intermodular_degree[node] = 0; next}\n",
      "+     bound = unique(c(subdata[,1:2]))\n",
      "+     bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]\n",
      "+     bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules[[node]] = bound_modules\n",
      "+     node_intermodular_degree[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> ##Weighted edge betweenness WEIGHT BY SIDE CHAIN\n",
      "> node_edge_betweenness_sidechain = rep(0,length(nodes))\n",
      "> names(node_edge_betweenness_sidechain) = nodes\n",
      "> for(i in 1:length(edge_betweenness)) {\n",
      "+     if (net_community_vec[influencedata[i,1]]!=net_community_vec[influencedata[i,2]]) {\n",
      "+         weight1 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,1]&influencedata_directed[,2]==influencedata[i,2],4]);if(length(weight1)==0){weight1=0}\n",
      "+         weight2 = as.numeric(influencedata_directed[influencedata_directed[,1]==influencedata[i,2]&influencedata_directed[,2]==influencedata[i,1],4]);if(length(weight2)==0){weight2=0}\n",
      "+         if(weight1==0 & weight2==0) {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]] + 0\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]] + 0\n",
      "+         } else {\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,1]] = node_edge_betweenness_sidechain[influencedata[i,1]]+(weight1/(weight1+weight2))*edge_betweenness[i]\n",
      "+             node_edge_betweenness_sidechain[influencedata[i,2]] = node_edge_betweenness_sidechain[influencedata[i,2]]+(weight2/(weight1+weight2))*edge_betweenness[i]\n",
      "+         }\n",
      "+     }\n",
      "+ }\n",
      "> node_intermodular_degree_sidechain = rep(0,length(nodes))\n",
      "> names(node_intermodular_degree_sidechain) = nodes\n",
      "> node_modules_sidechain = list()\n",
      "> for (node in nodes) {\n",
      "+     subdata_sidechain = matrix(influencedata_directed[influencedata_directed[,1]==node,],ncol=4)\n",
      "+     if (nrow(subdata_sidechain)==0) {node_intermodular_degree_sidechain[node] = 0; next}\n",
      "+     bound = unique(c(subdata_sidechain[,1:2])); bound = bound[bound!=node]\n",
      "+     bound_modules = net_community_vec[bound]; bound_modules = bound_modules[bound_modules!=net_community_vec[node]]\n",
      "+     node_modules_sidechain[[node]] = bound_modules\n",
      "+     node_intermodular_degree_sidechain[node] = length(bound_modules)\n",
      "+ }\n",
      "> \n",
      "> \n",
      "> ##Degree and second order degree for 2ARY STRUCTURE\n",
      "> \n",
      "> #second order intermodular degree\n",
      "> secondOrder_node_intermodular_degree = rep(0,length(node_intermodular_degree)); names(secondOrder_node_intermodular_degree) = names(node_intermodular_degree)\n",
      "> secondOrder_node_intermodular_degree_sidechain = rep(0,length(node_intermodular_degree_sidechain)); names(secondOrder_node_intermodular_degree_sidechain) = names(node_intermodular_degree_sidechain)\n",
      "> for (node in names(node_intermodular_degree)) {\n",
      "+     if (node_intermodular_degree[node]==0) {next}\n",
      "+     #secondOrder_node_intermodular_degree[node] = length(unique(unlist(node_modules[names(node_modules[[node]])])))\n",
      "+     secondOrder_node_intermodular_degree[node] = length(unlist(node_modules[names(node_modules[[node]])]))\n",
      "+     secondOrder_node_intermodular_degree_sidechain[node] = length(unlist(node_modules_sidechain[names(node_modules_sidechain[[node]])]))\n",
      "+ }\n",
      "> \n",
      "> #SAVE ALL AS STRIDE\n",
      "> node_edge_betweenness_stride = node_edge_betweenness\n",
      "> node_edge_betweenness_sidechain_stride = node_edge_betweenness_sidechain\n",
      "> node_intermodular_degree_stride = node_intermodular_degree\n",
      "> node_intermodular_degree_sidechain_stride = node_intermodular_degree_sidechain\n",
      "> secondOrder_node_intermodular_degree_stride = secondOrder_node_intermodular_degree\n",
      "> secondOrder_node_intermodular_degree_sidechain_stride = secondOrder_node_intermodular_degree_sidechain\n",
      "> \n",
      "> ### Create final dataset\n",
      "> nodes = nodes[nodes!=\"DNA1000A\"]\n",
      "> nodes = nodes[nodes %in% c(\"DA\",\"DG\",\"DC\",\"DT\") == FALSE]\n",
      "> \n",
      "> ### Remove ligand amino acids from final dataset\n",
      "> ligands = sub(\"-\",\"\",liganddat)\n",
      "> nodes = nodes[nodes %in% ligands == FALSE]\n",
      "> \n",
      "> nodes[which(nodes %in% rownames(bfactor)==FALSE)]\n",
      "character(0)\n",
      "> \n",
      "> out = cbind(\n",
      "+ rsa[nodes,1],\n",
      "+ firstOrderDegree[nodes],\n",
      "+ firstOrderDegree_sidechain[nodes],\n",
      "+ secondOrderDegree[nodes],\n",
      "+ secondOrderDegree_sidechain[nodes],\n",
      "+ node_edge_betweenness_stride[nodes],\n",
      "+ node_edge_betweenness_sidechain_stride[nodes],\n",
      "+ node_intermodular_degree_stride[nodes],\n",
      "+ node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_stride[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_stride[nodes],\n",
      "+ node_edge_betweenness_wt[nodes],\n",
      "+ node_edge_betweenness_sidechain_wt[nodes],\n",
      "+ node_intermodular_degree_wt[nodes],\n",
      "+ node_intermodular_degree_sidechain_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_wt[nodes],\n",
      "+ secondOrder_node_intermodular_degree_sidechain_wt[nodes]\n",
      "+ )\n",
      "> \n",
      "> #write column names\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\")\n",
      "> \n",
      "> \n",
      "> ## LIGANDS\n",
      "> if(ligandmode==TRUE & ligandCentroidMode==FALSE) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",\"_ligand\"),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         acid=paste(unlist(strsplit(liganddat[i,1],split=\"\"))[1:3],collapse=\"\")\n",
      "+         if (unlist(strsplit(liganddat[i,1],\"-\"))[2] %in% terminalAtoms[[acid]]) {\n",
      "+             tmp = rbind(tmp,c(unlist(strsplit(liganddat[i,1],\"-\"))[1],liganddat[i,2],liganddat[i,3]))\n",
      "+         }\n",
      "+     }\n",
      "+     \n",
      "+     #ligandvec = tapply(liganddat[,3],as.factor(liganddat[,1]),min)\n",
      "+     ligandvec = tapply(as.numeric(tmp[,3]),as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if(ligandmode==TRUE & ligandCentroidMode) {\n",
      "+     liganddat = as.matrix(read.table(dir(\"./\",paste(\"_centroidNetLigand$\",sep=\"\")),sep=\"\\t\"))\n",
      "+     \n",
      "+     tmp = c()\n",
      "+     i=1\n",
      "+     for (i in 1:nrow(liganddat)) {\n",
      "+         tmp = rbind(tmp,c(liganddat[i,1],liganddat[i,2],liganddat[i,3]))\n",
      "+     }\n",
      "+     \n",
      "+     ligandvec = tapply(tmp[,3],as.factor(tmp[,1]),min)\n",
      "+ }\n",
      "> \n",
      "> if (ligandmode==FALSE) {\n",
      "+     ligandvec = rep(0,length(nodes))\n",
      "+ }\n",
      "> \n",
      "> out = cbind(out,ligandvec[rownames(out)])\n",
      "> colnames(out) = c(\"RSA\",\"Degree\",\"Degree_uniqueAtoms\",\"SecondOrderDegree\",\"SecondOrderDegree_uniqueAtoms\",\"NodeEdgeBetweennessSTRIDE\",\"NodeEdgeBetweennessSTRIDE_unqiueAtoms\",\"IntermodularDegreeSTRIDE\",\"IntermodularDegreeSTRIDE_uniqueAtoms\",\"SecondOrderIntermodularDegreeSTRIDE\",\"SecondOrderIntermodularDegreeSTRIDE_uniqueAtoms\",\"NodeEdgeBetweennessWALKTRAP\",\"NodeEdgeBetweennessWALKTRAP_uniqueAtoms\",\"IntermodularDegreeWALKTRAP\",\"IntermodularDegreeWALKTRAP_uniqueAtoms\",\"SecondOrderIntermodularDegreeWALKTRAP\",\"SecondOrderIntermodularDegreeWALKTRAP_uniqueAtoms\",\"Ligand\")\n",
      "> \n",
      "> #add back in nodes that were not networked as zeros\n",
      "> zeroMat = matrix(0,nrow=length(which(originalNodes%in%nodes==FALSE)),ncol=ncol(out));rownames(zeroMat)=originalNodes[which(originalNodes%in%nodes==FALSE)]\n",
      "> out = rbind(out,zeroMat)\n",
      "> \n",
      "> #fix RSA and Bfactor and ligand\n",
      "> out[,\"RSA\"] = rsa[rownames(out),1]\n",
      "> out[,\"Ligand\"] = ligandvec[rownames(out)]\n",
      "> \n",
      "> #Add 1 to everything to avoid zeros, except ligand\n",
      "> out[is.na(out)]=0\n",
      "> out[out[,\"Ligand\"]==0,\"Ligand\"] = 150\n",
      "> out[1:nrow(out),2:ncol(out)] = as.numeric(out[1:nrow(out),2:ncol(out)])+1\n",
      "> \n",
      "> ##create Z score file\n",
      "> outZ = apply(out,2,function(x){return(scale(as.numeric(x)))})\n",
      "> rownames(outZ) = rownames(out)\n",
      "> colnames(outZ) = colnames(out)\n",
      "> outZ[outZ==NA]=0\n",
      "> outZ[outZ==\"NaN\"]=0\n",
      "> \n",
      "> #Write out scores and z-normed scores files\n",
      "> write.table(out,file=paste(keyword,\"_scoresCentroid\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> write.table(outZ,file=paste(keyword,\"_scoresCentroidZ\",sep=\"\"),sep=\"\\t\",quote=FALSE,col.names=TRUE,row.names=TRUE)\n",
      "> \n",
      "> \n",
      "\n",
      "R version 4.0.5 (2021-03-31) -- \"Shake and Throw\"\n",
      "Copyright (C) 2021 The R Foundation for Statistical Computing\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "\n",
      "R is free software and comes with ABSOLUTELY NO WARRANTY.\n",
      "You are welcome to redistribute it under certain conditions.\n",
      "Type 'license()' or 'licence()' for distribution details.\n",
      "\n",
      "  Natural language support but running in an English locale\n",
      "\n",
      "R is a collaborative project with many contributors.\n",
      "Type 'contributors()' for more information and\n",
      "'citation()' on how to cite R or R packages in publications.\n",
      "\n",
      "Type 'demo()' for some demos, 'help()' for on-line help, or\n",
      "'help.start()' for an HTML browser interface to help.\n",
      "Type 'q()' to quit R.\n",
      "\n",
      "> ## run from within the monomer folder\n",
      "> ## there can only be one *_scoresEnergetics and one Centroid/*_scoresCentroid in this folder\n",
      "> ## args[1] is the folder for the multimer\n",
      "> ## NOTE: results may differ slightly from publication because of missing data in the mutagenesis experiments used in teh paper\n",
      "> \n",
      "> args <- commandArgs(trailingOnly = TRUE)\n",
      "> \n",
      "> #Load monomer\n",
      "> data1 = read.table(dir(\"./\",\"_scoresEnergetics$\"),header=T,row.names=1)\n",
      "> data1Z = as.data.frame(apply(data1,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1Z) = rownames(data1)\n",
      "> data1Z[is.na(data1Z)] = 0\n",
      "> data2 = read.table(dir(\"./Centroid\",\"_scoresCentroid$\", full.names=TRUE),header=T,row.names=1)\n",
      "> data2Z = as.data.frame(apply(data2,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2Z) = rownames(data2)\n",
      "> data2Z[is.na(data2Z)] = 0\n",
      "> colnames(data2Z) = paste(colnames(data2Z),\"CENTROIDSC\",sep=\"\")\n",
      "> data2Z = data2Z[rownames(data1Z),]\n",
      "> data2 = data2[rownames(data1),]\n",
      "> \n",
      "> #Load multimer\n",
      "> data1Multimer = read.table(dir(args[1],\"_scoresEnergetics$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = read.table(dir(paste(args[1],\"Centroid\",sep=\"/\"),\"_scoresCentroid$\",full.names=TRUE),header=T,row.names=1)\n",
      "> data2Multimer = data2Multimer[rownames(data1Multimer),]\n",
      "> data1MultimerZ = as.data.frame(apply(data1Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data1MultimerZ) = rownames(data1Multimer)\n",
      "> data2MultimerZ = as.data.frame(apply(data2Multimer,2,function(x){return(scale(as.numeric(x)))}))\n",
      "> rownames(data2MultimerZ) = rownames(data2Multimer)\n",
      "> colnames(data1MultimerZ) = paste(colnames(data1MultimerZ),\"MULTIMER\",sep=\"\")\n",
      "> colnames(data2MultimerZ) = paste(colnames(data2MultimerZ),\"MULTIMERCENTROIDSC\",sep=\"\")\n",
      "> data2MultimerZ = data2MultimerZ[rownames(data1MultimerZ),]\n",
      "> \n",
      "> #Add RSA\n",
      "> data1 = cbind(data2[,\"RSA\"],data1)\n",
      "> colnames(data1)[1]=\"RSA\"\n",
      "> dataZ = cbind(data1Z,data2Z)\n",
      "> \n",
      "> #Identify max NodeEdgeBetweennessSTRIDE_sidechain\n",
      "> acidsMonomer = c()\n",
      "> for (i in 1:length(rownames(dataZ))) {\n",
      "+     node = rownames(dataZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMonomer = c(acidsMonomer,node)\n",
      "+ }\n",
      "> \n",
      "> acidsMultimer = c()\n",
      "> for (i in 1:length(rownames(data1MultimerZ))) {\n",
      "+     node = rownames(data1MultimerZ)[i]\n",
      "+     node = unlist(strsplit(node,split=\"\"))\n",
      "+     node = paste(node[1:(length(node)-1)],collapse=\"\")\n",
      "+     acidsMultimer = c(acidsMultimer,node)\n",
      "+ }\n",
      "> \n",
      "> allAcids = unique(c(acidsMonomer,acidsMultimer))\n",
      "> \n",
      "> #SecondOrderIntermodularDegree is the average of the multimer only\n",
      "> SecondOrderIntermodularDegree_ALL = (data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDE_sidechainMULTIMER\"]+data1MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMER\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeSTRIDEMULTIMERCENTROIDSC\"]+data2MultimerZ[,\"SecondOrderIntermodularDegreeWALKTRAPMULTIMERCENTROIDSC\"])/4\n",
      "> SecondOrderIntermodularDegree_AVERAGE = tapply(SecondOrderIntermodularDegree_ALL,as.factor(acidsMultimer),mean)\n",
      "> SecondOrderIntermodularDegree_AVERAGE = SecondOrderIntermodularDegree_AVERAGE[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> SecondOrderIntermodularDegree_AVERAGE[missing] = (data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE_sidechain\"]+data1Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDE\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeSTRIDECENTROIDSC\"]+data2Z[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"SecondOrderIntermodularDegreeWALKTRAPCENTROIDSC\"])/4\n",
      "> names(SecondOrderIntermodularDegree_AVERAGE)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> \n",
      "> #NodeEdgeBetweenness is the max of the monomer/multimer\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER = (dataZ[,\"NodeEdgeBetweennessSTRIDE\"]+dataZ[,\"NodeEdgeBetweennessSTRIDE_sidechain\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER = (data1MultimerZ[,\"NodeEdgeBetweennessSTRIDEMULTIMER\"]+data1MultimerZ[,\"NodeEdgeBetweennessSTRIDE_sidechainMULTIMER\"])/2\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_ALL = c(NodeEdgeBetweennessSTRIDE_AVERAGE_MONOMER,NodeEdgeBetweennessSTRIDE_AVERAGE_MULTIMER)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = tapply(NodeEdgeBetweennessSTRIDE_sidechain_ALL,as.factor(c(acidsMonomer,acidsMultimer)),max,na.rm=TRUE)\n",
      "> NodeEdgeBetweennessSTRIDE_sidechain_MAX = NodeEdgeBetweennessSTRIDE_sidechain_MAX[allAcids]\n",
      "> \n",
      "> #Ligand is the min of the multimer only\n",
      "> LigandMULTIMERCENTROIDSC_ALL = data2MultimerZ[,\"LigandMULTIMERCENTROIDSC\"]\n",
      "> LigandMULTIMERCENTROIDSC_MIN = tapply(LigandMULTIMERCENTROIDSC_ALL,as.factor(acidsMultimer),min)\n",
      "> LigandMULTIMERCENTROIDSC_MIN = LigandMULTIMERCENTROIDSC_MIN[allAcids]\n",
      "> missing = which(allAcids%in%acidsMultimer == FALSE)\n",
      "> LigandMULTIMERCENTROIDSC_MIN[missing] = dataZ[allAcids[which(allAcids%in%acidsMultimer == FALSE)],\"LigandCENTROIDSC\"]\n",
      "> names(LigandMULTIMERCENTROIDSC_MIN)[missing] = allAcids[which(allAcids%in%acidsMultimer == FALSE)]\n",
      "> LigandMULTIMERCENTROIDSC_MIN[is.na(LigandMULTIMERCENTROIDSC_MIN)] = 0\n",
      "> \n",
      "> #RSA\n",
      "> RSA_ALL = c(data1[,\"RSA\"],data2Multimer[,\"RSA\"])\n",
      "> RSA_MIN = tapply(RSA_ALL,as.factor(c(acidsMonomer,acidsMultimer)),min,na.rm=TRUE)\n",
      "> RSA_MIN = RSA_MIN[allAcids]\n",
      "> \n",
      "> y = SecondOrderIntermodularDegree_AVERAGE+NodeEdgeBetweennessSTRIDE_sidechain_MAX-LigandMULTIMERCENTROIDSC_MIN\n",
      "> \n",
      "> out=cbind(names(y),y)\n",
      "> acidNumbers = sapply(out[,1],substring,4)\n",
      "> out = out[order(as.numeric(acidNumbers)),]\n",
      "> write.table(out,file=\"FinalSum\",sep=\"\\t\",quote=FALSE,row.names=FALSE,col.names=FALSE)\n",
      "> \n",
      "\n",
      "*WARNING*: Residues SER 95  and SER 96  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues SER 95  and SER 96  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 0 items\n",
      "Read 0 items\n",
      "*WARNING*: Residues SER 95  and SER 96  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "*WARNING*: Residues SER 95  and SER 96  in chain  C appear unbonded \n",
      "            and will be treated as a chain break\n",
      "IGNORED 1TSR_multimer_nowaters.pdb E (less than 5 residues)\n",
      "IGNORED 1TSR_multimer_nowaters.pdb F (less than 5 residues)\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "There were 24 warnings (use warnings() to see them)\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Read 6558 items\n",
      "Read 6558 items\n",
      "There were 22 warnings (use warnings() to see them)\n",
      "\n",
      "SBNA results for 1TSR succesfully downloaded\n"
     ]
    }
   ],
   "source": [
    "host = \"m3-dtn.massive.org.au\"\n",
    "username = \"yliy0004\"\n",
    "with open(\"pw.txt\", \"r\") as f:\n",
    "    password = f.read()\n",
    "base_path = 'ym65_scratch/yliy0004/NetworkAnalysis'\n",
    "\n",
    "client = paramiko.client.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(host, username=username, password=password)\n",
    "\n",
    "# check if R module is loaded (uses .bashrc - not the best solution because STRUDEL cannot be used, make sure to correct this if using STRUDEL)\n",
    "stdin,stdout,stderr=client.exec_command('R --version') \n",
    "print(stdout.read().decode())\n",
    "print(stderr.read().decode())\n",
    "\n",
    "sftp_client=client.open_sftp()\n",
    "\n",
    "# ==================== SBNA ====================\n",
    "# multiple structures by gene\n",
    "# for gene_id in top_structures:\n",
    "    # for pdb_id in top_structures[gene_id]:\n",
    "\n",
    "# or certain genes\n",
    "# for gene in ['TP53', 'HRAS', 'KRAS', 'EGFR']:\n",
    "#     count = 0\n",
    "#     tmp = ast.literal_eval(cgc_data.loc[cgc_data['Gene Symbol'] == gene, 'PDB Structures'].values[0])\n",
    "#     for pdb_id in tmp:\n",
    "#         try:\n",
    "#             resolution = get_resolution(pdb_id)\n",
    "#             if resolution and float(resolution) <= 3.0:\n",
    "#                 calculate_sbna_and_download(client, sftp_client, pdb_id, base_path)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to process {pdb_id} with error:\")\n",
    "#             print(traceback.print_exc())\n",
    "#             continue\n",
    "\n",
    "# or one pdb\n",
    "calculate_sbna_and_download(client, sftp_client, \"1TSR\", base_path, chains=['C'])\n",
    "\n",
    "# close the connection\n",
    "client.close()\n",
    "sftp_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "sftp_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgc_data = pd.read_csv('Census_all_with_pdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniprot_id(pdb_id, chain):\n",
    "    # read pdb file \n",
    "    with open(f'pdb_files/{pdb_id}.pdb', 'r') as f:\n",
    "        pdb_text = f.read()\n",
    "        for line in pdb_text.split('\\n'):\n",
    "            vals = line.split()\n",
    "            if line.startswith('DBREF') and chain in vals[2] and 'UNP' in vals:\n",
    "                return vals[6] # uniprot id is the 6th value\n",
    "\n",
    "\n",
    "def fetch_sequence(uniprot_id):\n",
    "    url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        # Extract the sequence from the FASTA format\n",
    "        lines = response.text.split('\\n')\n",
    "        sequence = ''.join(lines[1:])  # Skip the header line\n",
    "        return sequence\n",
    "    else:\n",
    "        print(\"Failed to fetch sequence\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_gene_name(uniprot_id):\n",
    "    response = requests.get(f\"https://www.uniprot.org/uniprot/{uniprot_id}.fasta\")\n",
    "    response = response.text\n",
    "    match = re.search(r'GN=([^\\s]+)', response)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def read_finalsum(pdb_id, chain):\n",
    "    if os.path.exists(f'sbna_results/{pdb_id}/{chain}/{pdb_id}_monomer/FinalSum'):\n",
    "        with open(f'sbna_results/{pdb_id}/{chain}/{pdb_id}_monomer/FinalSum', 'r') as f:\n",
    "            # convert final_sum to dataframe\n",
    "            final_sum = f.readlines()\n",
    "            final_sum = [i.split() for i in final_sum]\n",
    "            rows = []\n",
    "            for row in final_sum:\n",
    "                # get letters only from row[0]\n",
    "                aa_3 = ''.join(filter(str.isalpha, row[0]))\n",
    "                if row[1] == 'NA' or len(aa_3) != 3: \n",
    "                    # skip if residue number is NA or residue code is not 3 letters\n",
    "                    continue\n",
    "                \n",
    "                aa_1 = seq1(aa_3) # convert to 1 letter code\n",
    "                res_num = ''.join(filter(str.isnumeric, row[0]))\n",
    "                score = float(row[1])\n",
    "                # print(f\"{aa_3} {aa_1} {res_num} {score}\")\n",
    "                rows.append([aa_3, aa_1, int(res_num), score])\n",
    "            final_sum = pd.DataFrame(rows, columns=['res', 'res_code', 'num', 'score'])\n",
    "        return final_sum\n",
    "    else:\n",
    "        print(f\"FinalSum file not found for {pdb_id}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_genes = [\"KRAS\", \"EGFR\", \"TP53\", \"HRAS\"]\n",
    "# tmp_genes = [\"KRAS\", \"TP53\", \"HRAS\"]\n",
    "tmp_genes = [\"EGFR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = list(final_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = cgc_data[cgc_data['PDB Structures'].notna()] # pdb_structures not nan\n",
    "filtered_data = filtered_data[filtered_data['Gene Symbol'].isin(tmp_genes)]\n",
    "\n",
    "for i, row in filtered_data.iterrows():\n",
    "    gene_symbol = row['Gene Symbol']\n",
    "    pdb_structures = row['PDB Structures']\n",
    "    for pdb_id in ast.literal_eval(pdb_structures):\n",
    "        if not os.path.exists(f'pdb_files/{pdb_id}.pdb'):\n",
    "            continue\n",
    "        else:\n",
    "            data = get_dbref_data(pdb_id)\n",
    "            resolution = get_resolution(pdb_id)\n",
    "            for i in data:\n",
    "                chain = i['chain']\n",
    "\n",
    "                # check if finalsum exists or if data is already in final_data\n",
    "                if not os.path.exists(f'sbna_results/{pdb_id}/{chain}/{pdb_id}_monomer/FinalSum') or any([pdb_id == i[1] and chain == i[2] for i in final_data]):\n",
    "                    continue    \n",
    "                      \n",
    "                uniprot_id = i['uniprot']\n",
    "                assoc_gene = get_gene_name(uniprot_id)\n",
    "                if assoc_gene != gene_symbol:\n",
    "                    # sometimes protein chain extends multiple genes, skip if not the same\n",
    "                    # in future can link if gene is in cgc_data/tcga_data\n",
    "                    continue\n",
    "\n",
    "                # read finalSum file and add to table\n",
    "                final_sum = read_finalsum(pdb_id, chain)\n",
    "\n",
    "                # check if seqeunce of final sum matches uniprot\n",
    "                uniprot_seq = fetch_sequence(uniprot_id)\n",
    "                \n",
    "                for _, row in final_sum.iterrows():\n",
    "                    num = row['num']\n",
    "                    start = i['start']\n",
    "                    end = i['end']\n",
    "                    outside_range = False\n",
    "                    residue_match = False\n",
    "                    try:\n",
    "                        # get residue from uniprot sequence\n",
    "                        uniprot_res = uniprot_seq[num-1]\n",
    "                    except:\n",
    "                        uniprot_res = None\n",
    "\n",
    "                    if num < start or num > end: # check if residue number is within range\n",
    "                        outside_range = True\n",
    "                        # print(f\"Residue {num} not in range {start} - {end}\")\n",
    "                    if row['res_code'] == uniprot_res: # check if residue code matches\n",
    "                        residue_match = True\n",
    "\n",
    "                    final_data.append([gene_symbol, pdb_id, chain, uniprot_id, assoc_gene, resolution, num, row['res_code'], uniprot_res, row['score'], outside_range, residue_match])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>assoc_gene</th>\n",
       "      <th>resolution</th>\n",
       "      <th>res_num</th>\n",
       "      <th>pdb_res</th>\n",
       "      <th>uniprot_res</th>\n",
       "      <th>score</th>\n",
       "      <th>outside_range</th>\n",
       "      <th>residue_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP53</td>\n",
       "      <td>1C26</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.70</td>\n",
       "      <td>325</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.148266</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP53</td>\n",
       "      <td>1C26</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.70</td>\n",
       "      <td>326</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>-0.982754</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TP53</td>\n",
       "      <td>1C26</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.70</td>\n",
       "      <td>327</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.164008</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TP53</td>\n",
       "      <td>1C26</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.70</td>\n",
       "      <td>328</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.577961</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TP53</td>\n",
       "      <td>1C26</td>\n",
       "      <td>A</td>\n",
       "      <td>P04637</td>\n",
       "      <td>TP53</td>\n",
       "      <td>1.70</td>\n",
       "      <td>329</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.808752</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28815</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>8A2D</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1017</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.876917</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28816</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>8A2D</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1018</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>-1.457035</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28817</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>8A2D</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1019</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>-3.161216</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28818</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>8A2D</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1020</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-2.024879</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28819</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>8A2D</td>\n",
       "      <td>A</td>\n",
       "      <td>P00533</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1021</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-3.622340</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28820 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene_symbol pdb_id chain uniprot_id assoc_gene resolution  res_num  \\\n",
       "0            TP53   1C26     A     P04637       TP53       1.70      325   \n",
       "1            TP53   1C26     A     P04637       TP53       1.70      326   \n",
       "2            TP53   1C26     A     P04637       TP53       1.70      327   \n",
       "3            TP53   1C26     A     P04637       TP53       1.70      328   \n",
       "4            TP53   1C26     A     P04637       TP53       1.70      329   \n",
       "...           ...    ...   ...        ...        ...        ...      ...   \n",
       "28815        EGFR   8A2D     A     P00533       EGFR       1.11     1017   \n",
       "28816        EGFR   8A2D     A     P00533       EGFR       1.11     1018   \n",
       "28817        EGFR   8A2D     A     P00533       EGFR       1.11     1019   \n",
       "28818        EGFR   8A2D     A     P00533       EGFR       1.11     1020   \n",
       "28819        EGFR   8A2D     A     P00533       EGFR       1.11     1021   \n",
       "\n",
       "      pdb_res uniprot_res     score  outside_range  residue_match  \n",
       "0           G           G -0.148266          False           True  \n",
       "1           E           E -0.982754          False           True  \n",
       "2           Y           Y  0.164008          False           True  \n",
       "3           F           F -0.577961          False           True  \n",
       "4           T           T -0.808752          False           True  \n",
       "...       ...         ...       ...            ...            ...  \n",
       "28815       L           L -0.876917          False           True  \n",
       "28816       I           I -1.457035          False           True  \n",
       "28817       P           P -3.161216          False           True  \n",
       "28818       Q           Q -2.024879          False           True  \n",
       "28819       Q           Q -3.622340          False           True  \n",
       "\n",
       "[28820 rows x 12 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.DataFrame(final_data, columns=['gene_symbol', 'pdb_id', 'chain', 'uniprot_id', 'assoc_gene', 'resolution', 'res_num', 'pdb_res', 'uniprot_res', 'network_score', 'outside_range', 'residue_match'])\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('final_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
